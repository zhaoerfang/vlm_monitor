请你首先仔细分析整个仓库的功能，我也会给你介绍下目前整个仓库的功能，但你也要仔细分析。

整个仓库的功能：
是一个基于多模态VLM的智能监控系统，他具有以下功能：
1. 基于 @config.json 从监控TCP视频流每一秒里抽取每一帧图像，送去 @async_video_processor.py和 @vlm_client.py进行推理。
2. 推理目标为 @config.json里的 system_prompt, 即做图像理解，目标检测和回答用户问题等。
3. 还可以使用MCP，基于 @prompt.py 自动地控制摄像头云台行动，这被我们称为哨兵模式（可在前端文件夹 frontend里找到相关内容）

以上是整个仓库大概的实现的功能，尽管我提供了大概的功能描述，你也要全力去理解整个仓库的内容，充分了解它的架构和功能。

现在的问题：
1. 问题1 
## 描述
由于我们是每一秒都会抽一帧图像送入 VLM 服务进行推理，由于推理有延迟，并发量太大之后，推理服务肯定会限流，因此尽管我们在 @async_video_processor.py和 @vlm_client.py里使用了异步的推理，但还是会很慢。
 - 比如我 第i秒的图像，会在30秒之后才有相应。
 - 比如用户针对 第i秒的图像进行了提问，如“穿蓝色衣服的人在干什么”，它会在 第i+30秒才回复，如果没有那么多的并发量，推理服务可能会在3秒内返回，但由于并发太大，被限流，所以很慢。
 
## 我的想法
**针对" “非哨兵模式” 和 “哨兵模式” 进行更改** 我们不要每一帧都去进行推理，我们只有当第i帧有 “图像理解” 和 “mcp” 控制返回了，即在 tmp/session_*/frame_*/这个log文件夹里生成 inference_result和mcp_result之后，我们才进行下一次推理。

这里有几个地方要注意：
1. 目前就类似于从之前的异步多帧推理，改为了同步推理，其中进行下一次推理的帧，不是第i+1帧，而是当前接受到实时帧。
2. 希望通过最小的架构改动来实现这功能，目前我想的，由于在 @vlm_client.py里和 @async_video_processor.py里全部都是些的异步推理，因此在推理这一层改为同步会有困难，但我们是否可以控制 @async_video_processor.py里的 add_frame这一函数，因为只有当帧通过这一函数加入队列之后，才能被推理消费。这样子做是不是最小的架构改动？
3. 由于用户可能会有输入，即user_quesiton, 那在有用户输入的情况下，尽管可能第i帧的推理还没处理完，但我们也要将其送入推理，即回答用户的输入的优先级是最高的，有抢占模式。