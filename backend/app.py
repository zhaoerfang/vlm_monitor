#!/usr/bin/env python3
"""
FastAPIåç«¯æœåŠ¡å™¨
æä¾›WebSocketè§†é¢‘æµå’ŒREST APIæ¥å£
ä½œä¸ºå”¯ä¸€çš„TCPå®¢æˆ·ç«¯ï¼Œå†…éƒ¨åˆ†å‘è§†é¢‘æµç»™æ¨ç†æœåŠ¡
"""

import os
import sys
import json
import time
import asyncio
import base64
import cv2
import numpy as np
from pathlib import Path
from typing import Optional, Dict, Any, List, Callable
from datetime import datetime
import logging
import queue
import threading
import io

from fastapi import FastAPI, WebSocket, WebSocketDisconnect, HTTPException, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import FileResponse, JSONResponse, StreamingResponse
from fastapi.staticfiles import StaticFiles
from pydantic import BaseModel

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(str(Path(__file__).parent.parent))

from monitor.tcp.tcp_client import TCPVideoClient
from monitor.core.config import load_config

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def safe_relative_path(path: Path, base: Optional[Path] = None) -> str:
    """
    å®‰å…¨åœ°è®¡ç®—ç›¸å¯¹è·¯å¾„ï¼Œå¦‚æœæ— æ³•è®¡ç®—åˆ™è¿”å›ç»å¯¹è·¯å¾„
    
    Args:
        path: è¦è®¡ç®—ç›¸å¯¹è·¯å¾„çš„è·¯å¾„
        base: åŸºå‡†è·¯å¾„ï¼Œé»˜è®¤ä¸ºå½“å‰å·¥ä½œç›®å½•
        
    Returns:
        ç›¸å¯¹è·¯å¾„å­—ç¬¦ä¸²ï¼Œå¦‚æœæ— æ³•è®¡ç®—åˆ™è¿”å›ç»å¯¹è·¯å¾„å­—ç¬¦ä¸²
    """
    if base is None:
        base = Path.cwd()
    
    try:
        # å°è¯•è®¡ç®—ç›¸å¯¹è·¯å¾„
        return str(path.relative_to(base))
    except ValueError:
        # å¦‚æœæ— æ³•è®¡ç®—ç›¸å¯¹è·¯å¾„ï¼Œè¿”å›ç»å¯¹è·¯å¾„
        logger.warning(f"æ— æ³•è®¡ç®—ç›¸å¯¹è·¯å¾„: {path} ç›¸å¯¹äº {base}ï¼Œä½¿ç”¨ç»å¯¹è·¯å¾„")
        return str(path.resolve())

# åˆ›å»ºFastAPIåº”ç”¨
app = FastAPI(
    title="VLMç›‘æ§ç³»ç»ŸAPI",
    description="åŸºäºå¤§æ¨¡å‹çš„è§†é¢‘ç›‘æ§ç³»ç»Ÿåç«¯API",
    version="1.0.0"
)

# é…ç½®CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:5173"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Pydanticæ¨¡å‹
class ApiResponse(BaseModel):
    success: bool
    data: Optional[Any] = None
    error: Optional[str] = None
    timestamp: float

class VideoFrame(BaseModel):
    data: str  # base64ç¼–ç çš„å›¾åƒæ•°æ®
    timestamp: float
    frame_number: int

class SystemStatus(BaseModel):
    streaming: bool
    connected_clients: int
    frame_count: int
    has_experiment_log: bool
    temp_dir: Optional[str]

# å†…éƒ¨è§†é¢‘æµåˆ†å‘å™¨ - ç®€åŒ–ç‰ˆæœ¬ï¼ˆå›åˆ°æ­£å¸¸å·¥ä½œçš„æ¶æ„ï¼‰
class SimpleVideoDistributor:
    def __init__(self):
        # è®¢é˜…è€…ç®¡ç†
        self.subscribers = []
        self.subscribers_lock = threading.Lock()
        
        # æ€§èƒ½ç»Ÿè®¡
        self.total_frames = 0
        self.display_frames = 0
        self.inference_frames = 0
        
        # æœ€æ–°å¸§ç¼“å­˜
        self.latest_frame = None
        self.latest_frame_timestamp = None
        self.latest_frame_lock = threading.Lock()
        
        # WebSocketè§†é¢‘å¸§é˜Ÿåˆ—
        self.websocket_frame_queue = queue.Queue(maxsize=5)  # é™åˆ¶é˜Ÿåˆ—å¤§å°é¿å…å†…å­˜å ç”¨è¿‡å¤š
        
        logger.info("ç®€åŒ–è§†é¢‘åˆ†å‘å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def distribute_frame(self, frame: np.ndarray, timestamp: float):
        """ç›´æ¥åˆ†å‘å¸§ - ç®€å•é«˜æ•ˆ"""
        self.total_frames += 1
        
        # æ›´æ–°æœ€æ–°å¸§ç¼“å­˜
        with self.latest_frame_lock:
            self.latest_frame = frame
            self.latest_frame_timestamp = timestamp
        
        # ç«‹å³ç¼–ç ä¸ºJPEGï¼ˆåœ¨ä¸»çº¿ç¨‹ä¸­ï¼Œé¿å…å»¶è¿Ÿï¼‰
        try:
            encode_params = [
                cv2.IMWRITE_JPEG_QUALITY, 85,
                cv2.IMWRITE_JPEG_OPTIMIZE, 0,
                cv2.IMWRITE_JPEG_PROGRESSIVE, 0,
            ]
            
            _, buffer = cv2.imencode('.jpg', frame, encode_params)
            jpeg_data = buffer.tobytes()
            
            # ç›´æ¥æ›´æ–°æœ€æ–°JPEGå¸§ï¼ˆåŸå­æ“ä½œï¼‰
            state.latest_jpeg_frame = jpeg_data
            self.display_frames += 1
            
            # å°†è§†é¢‘å¸§æ•°æ®æ”¾å…¥é˜Ÿåˆ—ï¼Œä¾›WebSocketå¤„ç†
            try:
                frame_data = {
                    'jpeg_data': jpeg_data,
                    'timestamp': timestamp,
                    'frame_number': self.total_frames
                }
                self.websocket_frame_queue.put_nowait(frame_data)
            except queue.Full:
                # é˜Ÿåˆ—æ»¡äº†ï¼Œä¸¢å¼ƒæœ€è€çš„å¸§
                try:
                    self.websocket_frame_queue.get_nowait()
                    self.websocket_frame_queue.put_nowait(frame_data)
                except queue.Empty:
                    pass
            
        except Exception as e:
            logger.error(f"JPEGç¼–ç å¤±è´¥: {e}")
        
        # æ¨ç†å¤„ç†ï¼ˆè·³å¸§ï¼‰
        if self.total_frames % 8 == 0:  # æ¯8å¸§å¤„ç†ä¸€æ¬¡æ¨ç†
            try:
                with self.subscribers_lock:
                    for subscriber in self.subscribers[:]:
                        if subscriber.get('active', True):
                            try:
                                should_continue = subscriber['callback'](frame.copy(), timestamp)
                                if not should_continue:
                                    subscriber['active'] = False
                            except Exception as e:
                                logger.error(f"æ¨ç†è®¢é˜…è€…é”™è¯¯: {e}")
                                subscriber['active'] = False
                
                self.inference_frames += 1
                
            except Exception as e:
                logger.error(f"æ¨ç†å¤„ç†é”™è¯¯: {e}")
    
    def get_websocket_frame(self):
        """è·å–å¾…å‘é€çš„WebSocketå¸§æ•°æ®"""
        try:
            return self.websocket_frame_queue.get_nowait()
        except queue.Empty:
            return None
    
    def subscribe(self, callback: Callable[[np.ndarray, float], bool]) -> str:
        """è®¢é˜…æ¨ç†æµ"""
        subscriber_id = f"subscriber_{int(time.time() * 1000)}_{len(self.subscribers)}"
        subscriber = {
            'id': subscriber_id,
            'callback': callback,
            'active': True
        }
        
        with self.subscribers_lock:
            self.subscribers.append(subscriber)
        
        logger.info(f"æ–°æ¨ç†è®¢é˜…è€…: {subscriber_id}")
        return subscriber_id
    
    def unsubscribe(self, subscriber_id: str):
        """å–æ¶ˆè®¢é˜…"""
        with self.subscribers_lock:
            self.subscribers = [s for s in self.subscribers if s['id'] != subscriber_id]
        logger.info(f"å–æ¶ˆè®¢é˜…: {subscriber_id}")
    
    def get_subscriber_count(self) -> int:
        """è·å–è®¢é˜…è€…æ•°é‡"""
        with self.subscribers_lock:
            return len([s for s in self.subscribers if s.get('active', True)])
    
    def get_stats(self) -> Dict[str, Any]:
        """è·å–æ€§èƒ½ç»Ÿè®¡"""
        return {
            'total_frames': self.total_frames,
            'display_frames': self.display_frames,
            'inference_frames': self.inference_frames,
            'drop_rate': 0,  # ç®€åŒ–ç‰ˆæœ¬ä¸è®¡ç®—ä¸¢å¸§ç‡
        }
    
    def get_latest_frame(self) -> Optional[tuple]:
        """è·å–æœ€æ–°å¸§"""
        with self.latest_frame_lock:
            if self.latest_frame is not None:
                return (self.latest_frame, self.latest_frame_timestamp)
            return None

# å…¨å±€çŠ¶æ€ç®¡ç†
class AppState:
    def __init__(self):
        self.config = load_config()
        self.tcp_client: Optional[TCPVideoClient] = None
        self.streaming = False
        self.connected_clients: List[WebSocket] = []
        self.frame_count = 0
        self.last_frame: Optional[Dict] = None
        self.experiment_log_path: Optional[Path] = None
        self.temp_dir: Optional[Path] = None
        self.latest_session_dir: Optional[Path] = None
        
        # è§†é¢‘å¸§é˜Ÿåˆ—ï¼ˆä¿ç•™å…¼å®¹æ€§ï¼‰
        self.frame_queue = queue.Queue(maxsize=10)
        self.queue_processor_task: Optional[asyncio.Task] = None
        
        # ç®€åŒ–è§†é¢‘æµåˆ†å‘å™¨
        self.video_distributor = SimpleVideoDistributor()
        
        # æŸ¥æ‰¾æœ€æ–°çš„å®éªŒç›®å½•
        self._find_latest_session_dir()
        
        # HTTPæµåª’ä½“ç›¸å…³
        self.mjpeg_clients = []
        self.mjpeg_clients_lock = threading.Lock()
        self.latest_jpeg_frame: Optional[bytes] = None
        
        # å“¨å…µæ¨¡å¼çŠ¶æ€ç®¡ç†
        self.sentry_mode_enabled = True  # é»˜è®¤å¯ç”¨å“¨å…µæ¨¡å¼
        self._sentry_mode_lock = threading.Lock()  # çº¿ç¨‹å®‰å…¨é”
    
    def set_sentry_mode(self, enabled: bool):
        """
        è®¾ç½®å“¨å…µæ¨¡å¼çŠ¶æ€
        
        Args:
            enabled: Trueå¯ç”¨å“¨å…µæ¨¡å¼ï¼ŒFalseç¦ç”¨å“¨å…µæ¨¡å¼
        """
        with self._sentry_mode_lock:
            old_state = self.sentry_mode_enabled
            self.sentry_mode_enabled = enabled
            
            if old_state != enabled:
                mode_text = "å¯ç”¨" if enabled else "ç¦ç”¨"
                logger.info(f"ğŸ›¡ï¸ å“¨å…µæ¨¡å¼å·²{mode_text}")
    
    def get_sentry_mode(self) -> bool:
        """
        è·å–å½“å‰å“¨å…µæ¨¡å¼çŠ¶æ€
        
        Returns:
            bool: Trueè¡¨ç¤ºå¯ç”¨ï¼ŒFalseè¡¨ç¤ºç¦ç”¨
        """
        with self._sentry_mode_lock:
            return self.sentry_mode_enabled
    
    def toggle_sentry_mode(self) -> bool:
        """
        åˆ‡æ¢å“¨å…µæ¨¡å¼çŠ¶æ€
        
        Returns:
            bool: åˆ‡æ¢åçš„çŠ¶æ€
        """
        with self._sentry_mode_lock:
            self.sentry_mode_enabled = not self.sentry_mode_enabled
            mode_text = "å¯ç”¨" if self.sentry_mode_enabled else "ç¦ç”¨"
            logger.info(f"ğŸ›¡ï¸ å“¨å…µæ¨¡å¼å·²åˆ‡æ¢ä¸º{mode_text}")
            return self.sentry_mode_enabled
    
    def _find_latest_session_dir(self):
        """æŸ¥æ‰¾æœ€æ–°çš„å®éªŒä¼šè¯ç›®å½•"""
        tmp_dir = Path('tmp')
        if tmp_dir.exists():
            # æŸ¥æ‰¾æœ€æ–°çš„sessionç›®å½•
            session_dirs = [d for d in tmp_dir.iterdir() if d.is_dir() and d.name.startswith('session_')]
            if session_dirs:
                latest_session = max(session_dirs, key=lambda x: x.stat().st_mtime)
                self.latest_session_dir = latest_session
                self.temp_dir = latest_session
                logger.info(f"æ‰¾åˆ°æœ€æ–°å®éªŒç›®å½•: {latest_session}")
                
                # æ£€æŸ¥æ˜¯å¦æœ‰experiment_log.json
                experiment_log = latest_session / 'experiment_log.json'
                if experiment_log.exists():
                    self.experiment_log_path = experiment_log
                    logger.info(f"æ‰¾åˆ°å®éªŒæ—¥å¿—: {experiment_log}")
                else:
                    logger.info("å®éªŒæ—¥å¿—æ–‡ä»¶å°šæœªç”Ÿæˆï¼Œå°†ä»sampled_videoç›®å½•è¯»å–æ¨ç†ç»“æœ")
    
    def get_latest_inference_results(self, limit: int = 10):
        """ä»sampled_videoç›®å½•è·å–æœ€æ–°çš„æ¨ç†ç»“æœ"""
        # æ¯æ¬¡è°ƒç”¨æ—¶éƒ½åˆ·æ–°æœ€æ–°çš„sessionç›®å½•
        self._find_latest_session_dir()
        
        if not self.latest_session_dir or not self.latest_session_dir.exists():
            logger.warning(f"æœ€æ–°sessionç›®å½•ä¸å­˜åœ¨: {self.latest_session_dir}")
            return []
        
        inference_results = []
        
        # æŸ¥æ‰¾æ‰€æœ‰sampled_videoç›®å½•
        sampled_dirs = [d for d in self.latest_session_dir.iterdir() 
                       if d.is_dir() and d.name.startswith('sampled_video_') and d.name.endswith('_details')]
        
        logger.info(f"æ‰¾åˆ° {len(sampled_dirs)} ä¸ªæ¨ç†ç»“æœç›®å½•")
        
        # æŒ‰æ—¶é—´æˆ³æ’åºï¼ˆä»ç›®å½•åä¸­æå–æ—¶é—´æˆ³ï¼‰
        sampled_dirs.sort(key=lambda x: int(x.name.split('_')[2]), reverse=True)
        
        # åˆ†åˆ«æ”¶é›†æœ‰AIç»“æœå’Œæ²¡æœ‰AIç»“æœçš„æ¨ç†
        results_with_ai = []
        results_without_ai = []
        
        # è·å–æ¨ç†ç»“æœ
        for i, sampled_dir in enumerate(sampled_dirs):
            try:
                video_details_file = sampled_dir / 'video_details.json'
                inference_result_file = sampled_dir / 'inference_result.json'
                
                if not video_details_file.exists():
                    continue
                
                with open(video_details_file, 'r', encoding='utf-8') as f:
                    video_details = json.load(f)
                
                # æ„é€ åŸºç¡€æ¨ç†ç»“æœæ ¼å¼
                inference_result = {
                    "timestamp": video_details.get("creation_timestamp"),
                    "creation_timestamp": video_details.get("creation_timestamp"),
                    "video_path": video_details.get("video_path"),
                    "total_frames": video_details.get("total_frames"),
                    "frames_per_second": video_details.get("frames_per_second"),
                    "target_duration": video_details.get("target_duration"),
                    "sampled_frames": video_details.get("sampled_frames", []),
                    "creation_time": video_details.get("creation_time"),
                    "session_dir": str(state.latest_session_dir.relative_to(Path.cwd())) if state.latest_session_dir else None,
                    "video_id": sampled_dir.name.replace('_details', ''),
                    "has_inference_result": False
                }
                
                # å¦‚æœå­˜åœ¨inference_result.jsonï¼Œè¯»å–è¯¦ç»†æ¨ç†ç»“æœ
                if inference_result_file.exists():
                    try:
                        with open(inference_result_file, 'r', encoding='utf-8') as f:
                            inference_data = json.load(f)
                        
                        # æ·»åŠ æ¨ç†ç»“æœæ•°æ®
                        inference_result.update({
                            "has_inference_result": True,
                            "inference_start_time": inference_data.get("inference_start_time"),
                            "inference_end_time": inference_data.get("inference_end_time"),
                            "inference_duration": inference_data.get("inference_duration"),
                            "result_received_at": inference_data.get("result_received_at"),
                            "raw_result": inference_data.get("raw_result"),
                            "parsed_result": inference_data.get("parsed_result"),
                            "people_count": inference_data.get("parsed_result", {}).get("people_count", 0),
                            "vehicle_count": inference_data.get("parsed_result", {}).get("vehicle_count", 0),
                            "people": inference_data.get("parsed_result", {}).get("people", []),
                            "vehicles": inference_data.get("parsed_result", {}).get("vehicles", []),
                            "summary": inference_data.get("parsed_result", {}).get("summary", ""),
                            "user_question": inference_data.get("user_question"),  # ç”¨æˆ·é—®é¢˜
                            "response": inference_data.get("parsed_result", {}).get("response") or inference_data.get("parsed_result", {}).get("answer")  # AIå›ç­”
                        })
                        
                        # æ·»åŠ åˆ°æœ‰AIç»“æœçš„åˆ—è¡¨
                        results_with_ai.append(inference_result)
                        logger.debug(f"æ¨ç†ç»“æœ(æœ‰AI): {inference_result['video_id']}, æ—¶é—´: {inference_result['creation_timestamp']}")
                    
                    except Exception as e:
                        logger.warning(f"è¯»å–æ¨ç†ç»“æœæ–‡ä»¶å¤±è´¥ {inference_result_file}: {e}")
                        # å³ä½¿è¯»å–å¤±è´¥ï¼Œä¹Ÿæ·»åŠ åˆ°æ²¡æœ‰AIç»“æœçš„åˆ—è¡¨
                        results_without_ai.append(inference_result)
                else:
                    # æ·»åŠ åˆ°æ²¡æœ‰AIç»“æœçš„åˆ—è¡¨
                    results_without_ai.append(inference_result)
                    logger.debug(f"æ¨ç†ç»“æœ(æ— AI): {inference_result['video_id']}, æ—¶é—´: {inference_result['creation_timestamp']}")
                    
            except Exception as e:
                logger.warning(f"è¯»å–æ¨ç†ç»“æœå¤±è´¥ {sampled_dir}: {e}")
                continue
        
        # ä¼˜å…ˆè¿”å›æœ‰AIç»“æœçš„æ¨ç†ï¼Œç„¶åæ˜¯æ²¡æœ‰AIç»“æœçš„æ¨ç†
        # æ¯ä¸ªåˆ—è¡¨å†…éƒ¨æŒ‰æ—¶é—´æˆ³å€’åºæ’åˆ—ï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
        inference_results = results_with_ai + results_without_ai
        
        # é™åˆ¶è¿”å›æ•°é‡
        inference_results = inference_results[:limit]
        
        # è®°å½•æœ€æ–°çš„æ¨ç†ç»“æœä¿¡æ¯
        if inference_results:
            latest = inference_results[0]
            logger.info(f"æœ€æ–°æ¨ç†ç»“æœ: {latest['video_id']}, æ—¶é—´: {latest['creation_timestamp']}, æœ‰AIç»“æœ: {latest['has_inference_result']}")
            logger.info(f"æ€»è®¡: æœ‰AIç»“æœ={len(results_with_ai)}, æ— AIç»“æœ={len(results_without_ai)}, è¿”å›={len(inference_results)}")
        
        logger.info(f"æˆåŠŸè·å– {len(inference_results)} ä¸ªæ¨ç†ç»“æœ")
        return inference_results

    async def add_client(self, websocket: WebSocket):
        """æ·»åŠ WebSocketå®¢æˆ·ç«¯"""
        self.connected_clients.append(websocket)
        logger.info(f"å®¢æˆ·ç«¯è¿æ¥ï¼Œå½“å‰è¿æ¥æ•°: {len(self.connected_clients)}")
        
        # å¯åŠ¨é˜Ÿåˆ—å¤„ç†å™¨ï¼ˆå¦‚æœè¿˜æ²¡æœ‰å¯åŠ¨ï¼‰
        if self.queue_processor_task is None or self.queue_processor_task.done():
            self.queue_processor_task = asyncio.create_task(self._process_frame_queue())

    async def remove_client(self, websocket: WebSocket):
        """ç§»é™¤WebSocketå®¢æˆ·ç«¯"""
        if websocket in self.connected_clients:
            self.connected_clients.remove(websocket)
        logger.info(f"å®¢æˆ·ç«¯æ–­å¼€ï¼Œå½“å‰è¿æ¥æ•°: {len(self.connected_clients)}")

    async def broadcast_message(self, message_type: str, data: Any):
        """å¹¿æ’­æ¶ˆæ¯ç»™æ‰€æœ‰è¿æ¥çš„å®¢æˆ·ç«¯"""
        message = {
            "type": message_type,
            "data": data,
            "timestamp": time.time()
        }
        
        # ç§»é™¤å·²æ–­å¼€çš„è¿æ¥
        disconnected = []
        for client in self.connected_clients:
            try:
                await client.send_json(message)
            except Exception as e:
                logger.warning(f"å‘é€æ¶ˆæ¯å¤±è´¥: {e}")
                disconnected.append(client)
        
        # æ¸…ç†æ–­å¼€çš„è¿æ¥
        for client in disconnected:
            await self.remove_client(client)
    
    def add_frame_to_queue(self, frame_data: Dict):
        """æ·»åŠ å¸§æ•°æ®åˆ°é˜Ÿåˆ—"""
        try:
            self.frame_queue.put_nowait(frame_data)
        except queue.Full:
            # é˜Ÿåˆ—æ»¡äº†ï¼Œä¸¢å¼ƒæœ€è€çš„å¸§
            try:
                self.frame_queue.get_nowait()
                self.frame_queue.put_nowait(frame_data)
            except queue.Empty:
                pass
    
    async def _process_frame_queue(self):
        """å¤„ç†å¸§é˜Ÿåˆ—ï¼ˆç°åœ¨ä¸»è¦ç”¨äºçŠ¶æ€æ›´æ–°å’ŒWebSocketè§†é¢‘å¸§å‘é€ï¼‰"""
        logger.info("å¯åŠ¨çŠ¶æ€é˜Ÿåˆ—å¤„ç†å™¨")
        while True:
            try:
                # æ£€æŸ¥æ˜¯å¦æœ‰çŠ¶æ€æ•°æ®
                if not self.frame_queue.empty():
                    status_data = self.frame_queue.get_nowait()
                    if len(self.connected_clients) > 0:
                        await self.broadcast_message("stream_status", status_data)
                        logger.debug(f"å¹¿æ’­çŠ¶æ€æ›´æ–° #{status_data.get('frame_number', 0)}")
                
                # å¤„ç†WebSocketè§†é¢‘å¸§å‘é€
                if self.video_distributor and len(self.connected_clients) > 0:
                    frame_data = self.video_distributor.get_websocket_frame()
                    if frame_data:
                        try:
                            # å°†JPEGæ•°æ®ç¼–ç ä¸ºbase64
                            frame_base64 = base64.b64encode(frame_data['jpeg_data']).decode('utf-8')
                            
                            # æ„é€ è§†é¢‘å¸§æ¶ˆæ¯
                            video_frame_data = {
                                "data": frame_base64,
                                "timestamp": frame_data['timestamp'],
                                "frame_number": frame_data['frame_number']
                            }
                            
                            # å‘é€ç»™æ‰€æœ‰è¿æ¥çš„WebSocketå®¢æˆ·ç«¯
                            await self.broadcast_message("video_frame", video_frame_data)
                            
                        except Exception as e:
                            logger.error(f"WebSocketå‘é€è§†é¢‘å¸§å¤±è´¥: {e}")
                
                # çŸ­æš‚ä¼‘çœ é¿å…CPUå ç”¨è¿‡é«˜
                await asyncio.sleep(0.01)  # æé«˜é¢‘ç‡æ¥å¤„ç†è§†é¢‘å¸§ï¼Œ100fpsçš„ç†è®ºä¸Šé™
                
            except Exception as e:
                logger.error(f"å¤„ç†çŠ¶æ€é˜Ÿåˆ—å¼‚å¸¸: {e}")
                await asyncio.sleep(0.1)

# åˆ›å»ºå…¨å±€çŠ¶æ€å®ä¾‹
state = AppState()

# WebSocketå¤„ç†
@app.websocket("/ws")
async def websocket_endpoint(websocket: WebSocket):
    await websocket.accept()
    await state.add_client(websocket)
    
    try:
        # å‘é€è¿æ¥æˆåŠŸæ¶ˆæ¯
        await websocket.send_json({
            "type": "status_update",
            "data": {
                "message": "WebSocketè¿æ¥æˆåŠŸ",
                "connected": True
            },
            "timestamp": time.time()
        })
        
        # ä¿æŒè¿æ¥å¹¶å¤„ç†æ¶ˆæ¯
        while True:
            message = await websocket.receive_json()
            await handle_websocket_message(websocket, message)
            
    except WebSocketDisconnect:
        await state.remove_client(websocket)
    except Exception as e:
        logger.error(f"WebSocketé”™è¯¯: {e}")
        await state.remove_client(websocket)

async def handle_websocket_message(websocket: WebSocket, message: Dict):
    """å¤„ç†WebSocketæ¶ˆæ¯"""
    message_type = message.get("type")
    
    if message_type == "start_stream":
        await start_video_stream(websocket)
    elif message_type == "stop_stream":
        await stop_video_stream(websocket)
    elif message_type == "get_latest_inference":
        await send_latest_inference(websocket)
    else:
        await websocket.send_json({
            "type": "error",
            "data": f"æœªçŸ¥æ¶ˆæ¯ç±»å‹: {message_type}",
            "timestamp": time.time()
        })

async def start_video_stream(websocket: WebSocket):
    """å¯åŠ¨è§†é¢‘æµ"""
    logger.info("æ”¶åˆ°å¯åŠ¨è§†é¢‘æµè¯·æ±‚")
    
    if state.streaming:
        logger.warning("è§†é¢‘æµå·²åœ¨è¿è¡Œä¸­")
        await websocket.send_json({
            "type": "error",
            "data": "è§†é¢‘æµå·²åœ¨è¿è¡Œä¸­",
            "timestamp": time.time()
        })
        return
    
    try:
        # åˆ›å»ºTCPå®¢æˆ·ç«¯ - ä½¿ç”¨ä¼˜åŒ–å‚æ•°
        tcp_config = state.config['stream']['tcp']
        logger.info(f"åˆ›å»ºTCPå®¢æˆ·ç«¯: {tcp_config['host']}:{tcp_config['port']}")
        
        state.tcp_client = TCPVideoClient(
            host=tcp_config['host'],
            port=tcp_config['port'],
            frame_rate=60,  # è®¾ç½®é«˜å¸§ç‡ï¼Œç¡®ä¿ä¸é™åˆ¶æ¥æ”¶
            timeout=tcp_config.get('connection_timeout', 10),
            buffer_size=2000  # è¿›ä¸€æ­¥å¢åŠ ç¼“å†²åŒº
        )
        
        # å¯åŠ¨è§†é¢‘æµä»»åŠ¡
        logger.info("å¯åŠ¨è§†é¢‘æµä»»åŠ¡...")
        task = asyncio.create_task(run_video_stream())
        
        # ç­‰å¾…ä¸€å°æ®µæ—¶é—´ç¡®ä¿ä»»åŠ¡å¯åŠ¨
        await asyncio.sleep(0.1)
        
        logger.info("è§†é¢‘æµä»»åŠ¡å·²å¯åŠ¨")
        await websocket.send_json({
            "type": "status_update",
            "data": {
                "message": "è§†é¢‘æµå·²å¯åŠ¨",
                "streaming": True
            },
            "timestamp": time.time()
        })
        
    except Exception as e:
        logger.error(f"å¯åŠ¨è§†é¢‘æµå¤±è´¥: {str(e)}", exc_info=True)
        await websocket.send_json({
            "type": "error",
            "data": f"å¯åŠ¨è§†é¢‘æµå¤±è´¥: {str(e)}",
            "timestamp": time.time()
        })

async def stop_video_stream(websocket: WebSocket):
    """åœæ­¢è§†é¢‘æµ"""
    state.streaming = False
    if state.tcp_client:
        state.tcp_client.disconnect()
        state.tcp_client = None
    
    await websocket.send_json({
        "type": "status_update",
        "data": {
            "message": "è§†é¢‘æµå·²åœæ­¢",
            "streaming": False
        },
        "timestamp": time.time()
    })

async def send_latest_inference(websocket: WebSocket):
    """å‘é€æœ€æ–°æ¨ç†ç»“æœ"""
    try:
        # åˆ·æ–°æœ€æ–°çš„å®éªŒç›®å½•
        state._find_latest_session_dir()
        
        # è·å–æœ€æ–°æ¨ç†ç»“æœ
        inference_results = state.get_latest_inference_results(limit=1)
        if inference_results:
            latest_inference = inference_results[0]
            await websocket.send_json({
                "type": "inference_result",
                "data": latest_inference,
                "timestamp": time.time()
            })
            logger.info(f"å‘é€æœ€æ–°æ¨ç†ç»“æœ: {latest_inference.get('video_id', 'unknown')}")
        else:
            await websocket.send_json({
                "type": "inference_result",
                "data": None,
                "error": "æ²¡æœ‰æ‰¾åˆ°æ¨ç†ç»“æœ",
                "timestamp": time.time()
            })
            logger.debug("æ²¡æœ‰æ‰¾åˆ°æ¨ç†ç»“æœ")
            
    except Exception as e:
        logger.error(f"å‘é€æ¨ç†ç»“æœå¤±è´¥: {e}")
        await websocket.send_json({
            "type": "error",
            "data": {"message": f"è·å–æ¨ç†ç»“æœå¤±è´¥: {str(e)}"},
            "timestamp": time.time()
        })

async def run_video_stream():
    """è¿è¡Œè§†é¢‘æµï¼ˆå¼‚æ­¥ç‰ˆæœ¬ï¼‰- é›¶å»¶è¿Ÿå¤šç®¡é“æ¶æ„"""
    logger.info("å¼€å§‹è¿è¡Œè§†é¢‘æµ - é›¶å»¶è¿Ÿå¤šç®¡é“æ¶æ„")
    state.streaming = True
    state.frame_count = 0
    
    # ç®€åŒ–ç‰ˆæœ¬ä¸éœ€è¦å¯åŠ¨åˆ†å‘å™¨
    
    def frame_callback(frame):
        """è¶…ç®€åŒ–çš„å¸§å›è°ƒ - åªè´Ÿè´£å¿«é€Ÿåˆ†å‘"""
        if not state.streaming:
            return False
        
        try:
            current_timestamp = time.time()
            state.frame_count += 1
            
            # é›¶å»¶è¿Ÿåˆ†å‘åˆ°å„ä¸ªç®¡é“
            state.video_distributor.distribute_frame(frame, current_timestamp)
            
            # ç®€å•çš„æ€§èƒ½ç›‘æ§
            if state.frame_count % 1000 == 0:
                stats = state.video_distributor.get_stats()
                logger.info(f"æ€§èƒ½ç»Ÿè®¡ - æ€»å¸§: {stats['total_frames']}, "
                          f"æ˜¾ç¤º: {stats['display_frames']}, æ¨ç†: {stats['inference_frames']}, "
                          f"ä¸¢å¸§ç‡: {stats['drop_rate']:.1f}%")
            
            return True
            
        except Exception as e:
            logger.error(f"å¸§åˆ†å‘å¤±è´¥: {str(e)}")
            return False
    
    try:
        if state.tcp_client:
            logger.info("å¼€å§‹è¿æ¥TCPå®¢æˆ·ç«¯...")
            # åœ¨çº¿ç¨‹æ± ä¸­è¿è¡ŒåŒæ­¥çš„TCPå®¢æˆ·ç«¯
            import concurrent.futures
            with concurrent.futures.ThreadPoolExecutor() as executor:
                logger.info("åœ¨çº¿ç¨‹æ± ä¸­è¿è¡ŒTCPå®¢æˆ·ç«¯")
                result = await asyncio.get_event_loop().run_in_executor(
                    executor, 
                    lambda: state.tcp_client.run(frame_callback) if state.tcp_client else None
                )
                logger.info(f"TCPå®¢æˆ·ç«¯è¿è¡Œç»“æœ: {result}")
        else:
            logger.error("TCPå®¢æˆ·ç«¯æœªåˆå§‹åŒ–")
    except Exception as e:
        logger.error(f"è§†é¢‘æµè¿è¡Œå¼‚å¸¸: {str(e)}", exc_info=True)
        await state.broadcast_message("error", f"è§†é¢‘æµå¼‚å¸¸: {str(e)}")
    finally:
        state.streaming = False
        # ç®€åŒ–ç‰ˆæœ¬ä¸éœ€è¦åœæ­¢åˆ†å‘å™¨
        logger.info("è§†é¢‘æµå·²åœæ­¢")

# REST APIè·¯ç”±
@app.get("/api/status", response_model=ApiResponse)
async def get_system_status():
    """è·å–ç³»ç»ŸçŠ¶æ€"""
    status = SystemStatus(
        streaming=state.streaming,
        connected_clients=len(state.connected_clients),
        frame_count=state.frame_count,
        has_experiment_log=state.experiment_log_path is not None,
        temp_dir=str(state.temp_dir) if state.temp_dir else None
    )
    
    return ApiResponse(
        success=True,
        data=status.dict(),
        timestamp=time.time()
    )

@app.get("/api/experiment-log", response_model=ApiResponse)
async def get_experiment_log():
    """è·å–å®éªŒæ—¥å¿—"""
    try:
        # é¦–å…ˆå°è¯•ä»experiment_log.jsonè¯»å–
        if state.experiment_log_path and state.experiment_log_path.exists():
            with open(state.experiment_log_path, 'r', encoding='utf-8') as f:
                experiment_log = json.load(f)
            
            return ApiResponse(
                success=True,
                data=experiment_log,
                timestamp=time.time()
            )
        
        # å¦‚æœæ²¡æœ‰experiment_log.jsonï¼Œä»sampled_videoç›®å½•æ„é€ å®éªŒæ—¥å¿—
        inference_results = state.get_latest_inference_results(limit=50)
        if not inference_results:
            return ApiResponse(
                success=False,
                error="å®éªŒæ—¥å¿—æ–‡ä»¶ä¸å­˜åœ¨ä¸”æ²¡æœ‰æ‰¾åˆ°æ¨ç†ç»“æœ",
                timestamp=time.time()
            )
        
        # æ„é€ å®éªŒæ—¥å¿—æ ¼å¼
        experiment_log = {
            "session_id": state.latest_session_dir.name if state.latest_session_dir else "unknown",
            "start_time": inference_results[-1]["timestamp"] if inference_results else None,
            "inference_log": inference_results,
            "total_inferences": len(inference_results),
            "status": "running"
        }
        
        return ApiResponse(
            success=True,
            data=experiment_log,
            timestamp=time.time()
        )
        
    except Exception as e:
        return ApiResponse(
            success=False,
            error=f"è¯»å–å®éªŒæ—¥å¿—å¤±è´¥: {str(e)}",
            timestamp=time.time()
        )

@app.get("/api/inference-history", response_model=ApiResponse)
async def get_inference_history(limit: int = 50):
    """è·å–æ¨ç†å†å²"""
    try:
        # é¦–å…ˆå°è¯•ä»experiment_log.jsonè¯»å–
        if state.experiment_log_path and state.experiment_log_path.exists():
            with open(state.experiment_log_path, 'r', encoding='utf-8') as f:
                experiment_log = json.load(f)
            
            inference_log = experiment_log.get('inference_log', [])
            recent_inferences = inference_log[-limit:] if limit > 0 else inference_log
            
            return ApiResponse(
                success=True,
                data=recent_inferences,
                timestamp=time.time()
            )
        
        # å¦‚æœæ²¡æœ‰experiment_log.jsonï¼Œä»sampled_videoç›®å½•è¯»å–
        inference_results = state.get_latest_inference_results(limit=limit)
        
        return ApiResponse(
            success=True,
            data=inference_results,
            timestamp=time.time()
        )
        
    except Exception as e:
        return ApiResponse(
            success=False,
            error=f"è·å–æ¨ç†å†å²å¤±è´¥: {str(e)}",
            timestamp=time.time()
        )

@app.get("/api/latest-inference", response_model=ApiResponse)
async def get_latest_inference():
    """è·å–æœ€æ–°æ¨ç†ç»“æœ"""
    try:
        # é¦–å…ˆå°è¯•ä»experiment_log.jsonè¯»å–
        if state.experiment_log_path and state.experiment_log_path.exists():
            with open(state.experiment_log_path, 'r', encoding='utf-8') as f:
                experiment_log = json.load(f)
            
            inference_log = experiment_log.get('inference_log', [])
            if not inference_log:
                return ApiResponse(
                    success=False,
                    error="æ²¡æœ‰æ¨ç†ç»“æœ",
                    timestamp=time.time()
                )
            
            latest_inference = inference_log[-1]
            
            return ApiResponse(
                success=True,
                data=latest_inference,
                timestamp=time.time()
            )
        
        # å¦‚æœæ²¡æœ‰experiment_log.jsonï¼Œä»sampled_videoç›®å½•è¯»å–æœ€æ–°ç»“æœ
        inference_results = state.get_latest_inference_results(limit=1)
        if not inference_results:
            return ApiResponse(
                success=False,
                error="æ²¡æœ‰æ‰¾åˆ°æ¨ç†ç»“æœ",
                timestamp=time.time()
            )
        
        latest_inference = inference_results[0]
        
        return ApiResponse(
            success=True,
            data=latest_inference,
            timestamp=time.time()
        )
        
    except Exception as e:
        return ApiResponse(
            success=False,
            error=f"è·å–æœ€æ–°æ¨ç†ç»“æœå¤±è´¥: {str(e)}",
            timestamp=time.time()
        )

@app.get("/api/latest-inference-with-ai", response_model=ApiResponse)
async def get_latest_inference_with_ai():
    """è·å–æœ€æ–°çš„å·²å®ŒæˆAIåˆ†æä¸”æœ‰MCPç»“æœçš„æ¨ç†ç»“æœ"""
    try:
        # è·å–åª’ä½“å†å²è®°å½•ï¼ˆåŒ…å«å›¾åƒå’Œè§†é¢‘ï¼‰
        media_response = await get_media_history(limit=50)
        if not media_response.success or not media_response.data:
            return ApiResponse(
                success=False,
                error="æ²¡æœ‰æ‰¾åˆ°åª’ä½“å†å²è®°å½•",
                timestamp=time.time()
            )
        
        media_items = media_response.data.get('media_items', [])
        
        # ç­›é€‰å‡ºåŒæ—¶æœ‰AIåˆ†æç»“æœå’ŒMCPç»“æœçš„æ¨ç†
        complete_results = [
            item for item in media_items 
            if item.get('has_inference_result', False) and item.get('has_mcp_result', False)
        ]
        
        if not complete_results:
            return ApiResponse(
                success=False,
                error="æ²¡æœ‰æ‰¾åˆ°åŒæ—¶å…·æœ‰AIåˆ†æå’ŒMCPç»“æœçš„æ¨ç†ç»“æœ",
                timestamp=time.time()
            )
        
        # è¿”å›æœ€æ–°çš„å®Œæ•´æ¨ç†ç»“æœ
        latest_complete_result = complete_results[0]
        
        return ApiResponse(
            success=True,
            data=latest_complete_result,
            timestamp=time.time()
        )
        
    except Exception as e:
        return ApiResponse(
            success=False,
            error=f"è·å–æœ€æ–°å®Œæ•´æ¨ç†ç»“æœå¤±è´¥: {str(e)}",
            timestamp=time.time()
        )

@app.get("/api/videos/{filename}")
@app.head("/api/videos/{filename}")
async def serve_video(filename: str, request: Request):
    """æä¾›è§†é¢‘æ–‡ä»¶"""
    try:
        logger.info(f"è¯·æ±‚è§†é¢‘æ–‡ä»¶: {filename}")
        
        # åˆ·æ–°æœ€æ–°çš„sessionç›®å½•
        state._find_latest_session_dir()
        
        if not state.latest_session_dir:
            raise HTTPException(status_code=404, detail="ä¸´æ—¶ç›®å½•ä¸å­˜åœ¨")
        
        video_file = None
        
        # åœ¨å½“å‰sessionç›®å½•ä¸‹æŸ¥æ‰¾è§†é¢‘æ–‡ä»¶
        for item in state.latest_session_dir.iterdir():
            if item.is_dir() and item.name.endswith('_details'):
                # æŸ¥æ‰¾åŒ¹é…çš„è§†é¢‘æ–‡ä»¶
                for video_path in item.glob('*.mp4'):
                    if video_path.name == filename:
                        video_file = video_path
                        logger.info(f"æ‰¾åˆ°è§†é¢‘æ–‡ä»¶: {video_file}")
                        break
                if video_file:
                    break
        
        if not video_file:
            logger.error(f"è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {filename}")
            logger.info(f"å½“å‰sessionç›®å½•: {state.latest_session_dir}")
            
            # åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„è§†é¢‘æ–‡ä»¶ç”¨äºè°ƒè¯•
            available_videos = []
            if state.latest_session_dir:
                for item in state.latest_session_dir.iterdir():
                    if item.is_dir() and item.name.endswith('_details'):
                        for video in item.glob('*.mp4'):
                            available_videos.append(video.name)
            logger.info(f"å¯ç”¨çš„è§†é¢‘æ–‡ä»¶: {available_videos}")
            raise HTTPException(status_code=404, detail=f"è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {filename}")
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦çœŸçš„å­˜åœ¨ä¸”å¯è¯»
        if not video_file.exists():
            raise HTTPException(status_code=404, detail=f"è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_file}")
        
        if not video_file.is_file():
            raise HTTPException(status_code=404, detail=f"è·¯å¾„ä¸æ˜¯æ–‡ä»¶: {video_file}")
        
        file_size = video_file.stat().st_size
        logger.info(f"è¿”å›è§†é¢‘æ–‡ä»¶: {video_file}, å¤§å°: {file_size} bytes")
        
        # å¤„ç†Rangeè¯·æ±‚
        range_header = request.headers.get('range')
        if range_header:
            logger.info(f"å¤„ç†Rangeè¯·æ±‚: {range_header}")
            # è§£æRangeå¤´
            range_match = range_header.replace('bytes=', '').split('-')
            start = int(range_match[0]) if range_match[0] else 0
            end = int(range_match[1]) if range_match[1] else file_size - 1
            
            # ç¡®ä¿èŒƒå›´æœ‰æ•ˆ
            start = max(0, start)
            end = min(file_size - 1, end)
            content_length = end - start + 1
            
            def iter_file():
                with open(video_file, 'rb') as f:
                    f.seek(start)
                    remaining = content_length
                    while remaining > 0:
                        chunk_size = min(8192, remaining)
                        chunk = f.read(chunk_size)
                        if not chunk:
                            break
                        remaining -= len(chunk)
                        yield chunk
            
            return StreamingResponse(
                iter_file(),
                status_code=206,
                headers={
                    "Content-Range": f"bytes {start}-{end}/{file_size}",
                    "Accept-Ranges": "bytes",
                    "Content-Length": str(content_length),
                    "Content-Type": "video/mp4",
                    "Cache-Control": "no-cache"
                }
            )
        
        # æ™®é€šè¯·æ±‚ï¼Œè¿”å›æ•´ä¸ªæ–‡ä»¶
        return FileResponse(
            str(video_file), 
            media_type='video/mp4',
            headers={
                "Cache-Control": "no-cache",
                "Accept-Ranges": "bytes",
                "Content-Type": "video/mp4",
                "Content-Length": str(file_size)
            }
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"è·å–è§†é¢‘æ–‡ä»¶å¤±è´¥: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"è·å–è§†é¢‘æ–‡ä»¶å¤±è´¥: {str(e)}")

@app.get("/api/videos", response_model=ApiResponse)
async def list_videos():
    """åˆ—å‡ºæ‰€æœ‰è§†é¢‘æ–‡ä»¶"""
    try:
        if not state.temp_dir:
            return ApiResponse(
                success=True,
                data=[],
                timestamp=time.time()
            )
        
        videos = []
        for item in state.temp_dir.iterdir():
            if item.is_dir() and item.name.endswith('_details'):
                for video_file in item.glob('*.mp4'):
                    videos.append(video_file.name)
        
        return ApiResponse(
            success=True,
            data=videos,
            timestamp=time.time()
        )
        
    except Exception as e:
        return ApiResponse(
            success=False,
            error=f"åˆ—å‡ºè§†é¢‘æ–‡ä»¶å¤±è´¥: {str(e)}",
            timestamp=time.time()
        )

@app.post("/api/stream/start", response_model=ApiResponse)
async def start_stream_api():
    """é€šè¿‡APIå¯åŠ¨è§†é¢‘æµ"""
    # åˆ›å»ºä¸€ä¸ªè™šæ‹ŸWebSocketæ¥å¤ç”¨ç°æœ‰é€»è¾‘
    class DummyWebSocket:
        async def send_json(self, data):
            pass
    
    dummy_ws = DummyWebSocket()
    # ç›´æ¥è°ƒç”¨å¯åŠ¨é€»è¾‘è€Œä¸æ˜¯é€šè¿‡WebSocketå‡½æ•°
    try:
        if state.streaming:
            return ApiResponse(
                success=False,
                error="è§†é¢‘æµå·²åœ¨è¿è¡Œä¸­",
                timestamp=time.time()
            )
        
        # åˆ›å»ºTCPå®¢æˆ·ç«¯ - ä½¿ç”¨ä¼˜åŒ–å‚æ•°
        tcp_config = state.config['stream']['tcp']
        logger.info(f"åˆ›å»ºTCPå®¢æˆ·ç«¯: {tcp_config['host']}:{tcp_config['port']}")
        
        state.tcp_client = TCPVideoClient(
            host=tcp_config['host'],
            port=tcp_config['port'],
            frame_rate=60,  # æé«˜åˆ°60fps
            timeout=tcp_config['connection_timeout'],
            buffer_size=1000  # å¢åŠ ç¼“å†²åŒº
        )
        
        # å¯åŠ¨è§†é¢‘æµä»»åŠ¡
        logger.info("å¯åŠ¨è§†é¢‘æµä»»åŠ¡...")
        asyncio.create_task(run_video_stream())
        
        return ApiResponse(
            success=True,
            data={"message": "è§†é¢‘æµå¯åŠ¨è¯·æ±‚å·²å‘é€"},
            timestamp=time.time()
        )
        
    except Exception as e:
        logger.error(f"å¯åŠ¨è§†é¢‘æµå¤±è´¥: {str(e)}")
        return ApiResponse(
            success=False,
            error=f"å¯åŠ¨è§†é¢‘æµå¤±è´¥: {str(e)}",
            timestamp=time.time()
        )

@app.post("/api/stream/stop", response_model=ApiResponse)
async def stop_stream_api():
    """é€šè¿‡APIåœæ­¢è§†é¢‘æµ"""
    try:
        state.streaming = False
        if state.tcp_client:
            state.tcp_client.disconnect()
            state.tcp_client = None
        
        return ApiResponse(
            success=True,
            data={"message": "è§†é¢‘æµåœæ­¢è¯·æ±‚å·²å‘é€"},
            timestamp=time.time()
        )
        
    except Exception as e:
        logger.error(f"åœæ­¢è§†é¢‘æµå¤±è´¥: {str(e)}")
        return ApiResponse(
            success=False,
            error=f"åœæ­¢è§†é¢‘æµå¤±è´¥: {str(e)}",
            timestamp=time.time()
        )

@app.get("/api/stream/status", response_model=ApiResponse)
async def get_stream_status():
    """è·å–è§†é¢‘æµçŠ¶æ€"""
    return ApiResponse(
        success=True,
        data={
            "streaming": state.streaming,
            "frame_count": state.frame_count,
            "has_client": state.tcp_client is not None
        },
        timestamp=time.time()
    )

@app.delete("/api/history", response_model=ApiResponse)
async def clear_history():
    """æ¸…ç©ºå†å²æ•°æ®"""
    try:
        # è¿™é‡Œåªæ˜¯æ¨¡æ‹Ÿæ¸…ç©ºï¼Œå®é™…å¯èƒ½éœ€è¦åˆ é™¤æ–‡ä»¶æˆ–é‡ç½®çŠ¶æ€
        state.frame_count = 0
        
        return ApiResponse(
            success=True,
            data={"message": "å†å²æ•°æ®å·²æ¸…ç©º"},
            timestamp=time.time()
        )
        
    except Exception as e:
        return ApiResponse(
            success=False,
            error=f"æ¸…ç©ºå†å²æ•°æ®å¤±è´¥: {str(e)}",
            timestamp=time.time()
        )

@app.get("/api/refresh-session", response_model=ApiResponse)
async def refresh_session():
    """åˆ·æ–°å®éªŒä¼šè¯ç›®å½•"""
    try:
        old_session = state.latest_session_dir.name if state.latest_session_dir else "none"
        state._find_latest_session_dir()
        new_session = state.latest_session_dir.name if state.latest_session_dir else "none"
        
        return ApiResponse(
            success=True,
            data={
                "old_session": old_session,
                "new_session": new_session,
                "changed": old_session != new_session
            },
            timestamp=time.time()
        )
        
    except Exception as e:
        return ApiResponse(
            success=False,
            error=f"åˆ·æ–°ä¼šè¯ç›®å½•å¤±è´¥: {str(e)}",
            timestamp=time.time()
        )

@app.get("/api/inference-count", response_model=ApiResponse)
async def get_inference_count():
    """è·å–æ¨ç†ç»“æœæ•°é‡"""
    try:
        # åˆ·æ–°æœ€æ–°çš„å®éªŒç›®å½•
        state._find_latest_session_dir()
        
        inference_results = state.get_latest_inference_results(limit=1000)  # è·å–æ‰€æœ‰ç»“æœæ¥è®¡æ•°
        
        return ApiResponse(
            success=True,
            data={
                "count": len(inference_results),
                "session_dir": safe_relative_path(state.latest_session_dir) if state.latest_session_dir else None,
                "has_experiment_log": state.experiment_log_path is not None and state.experiment_log_path.exists()
            },
            timestamp=time.time()
        )
        
    except Exception as e:
        return ApiResponse(
            success=False,
            error=f"è·å–æ¨ç†æ•°é‡å¤±è´¥: {str(e)}",
            timestamp=time.time()
        )

@app.get("/api/debug/videos", response_model=ApiResponse)
async def debug_videos():
    """è°ƒè¯•è§†é¢‘æ–‡ä»¶ä¿¡æ¯"""
    try:
        state._find_latest_session_dir()
        
        debug_info = {
            "latest_session_dir": str(state.latest_session_dir) if state.latest_session_dir else None,
            "session_exists": state.latest_session_dir.exists() if state.latest_session_dir else False,
            "current_working_dir": str(Path.cwd()),
            "videos": []
        }
        
        if state.latest_session_dir and state.latest_session_dir.exists():
            for item in state.latest_session_dir.iterdir():
                if item.is_dir() and item.name.endswith('_details'):
                    for video_path in item.glob('*.mp4'):
                        try:
                            # å®‰å…¨åœ°è®¡ç®—ç›¸å¯¹è·¯å¾„
                            try:
                                relative_path = str(video_path.relative_to(Path.cwd()))
                            except ValueError:
                                # å¦‚æœæ— æ³•è®¡ç®—ç›¸å¯¹è·¯å¾„ï¼Œä½¿ç”¨ç»å¯¹è·¯å¾„
                                relative_path = str(video_path.resolve())
                            
                            video_info = {
                                "filename": video_path.name,
                                "full_path": str(video_path.resolve()),
                                "relative_path": relative_path,
                                "exists": video_path.exists(),
                                "is_file": video_path.is_file(),
                                "size": video_path.stat().st_size if video_path.exists() else 0,
                                "parent_dir": video_path.parent.name
                            }
                            debug_info["videos"].append(video_info)
                        except Exception as e:
                            logger.warning(f"å¤„ç†è§†é¢‘æ–‡ä»¶ä¿¡æ¯å¤±è´¥ {video_path}: {e}")
                            # æ·»åŠ åŸºæœ¬ä¿¡æ¯å³ä½¿å‡ºé”™
                            video_info = {
                                "filename": video_path.name,
                                "full_path": str(video_path),
                                "relative_path": str(video_path),
                                "exists": video_path.exists(),
                                "is_file": video_path.is_file(),
                                "size": 0,
                                "parent_dir": video_path.parent.name,
                                "error": str(e)
                            }
                            debug_info["videos"].append(video_info)
        
        return ApiResponse(
            success=True,
            data=debug_info,
            timestamp=time.time()
        )
        
    except Exception as e:
        logger.error(f"è°ƒè¯•è§†é¢‘ä¿¡æ¯å¤±è´¥: {str(e)}", exc_info=True)
        return ApiResponse(
            success=False,
            error=f"è°ƒè¯•è§†é¢‘ä¿¡æ¯å¤±è´¥: {str(e)}",
            timestamp=time.time()
        )

@app.get("/api/media-history", response_model=ApiResponse)
async def get_media_history(limit: int = 50):
    """è·å–åª’ä½“å†å²è®°å½•ï¼ˆå›¾åƒå’Œè§†é¢‘ï¼‰"""
    try:
        # åˆ·æ–°æœ€æ–°çš„sessionç›®å½•
        state._find_latest_session_dir()
        
        if not state.latest_session_dir or not state.latest_session_dir.exists():
            return ApiResponse(
                success=False,
                error="æ²¡æœ‰æ‰¾åˆ°sessionç›®å½•",
                timestamp=time.time()
            )
        
        media_items = []
        
        # éå†sessionç›®å½•ä¸‹çš„æ‰€æœ‰detailsæ–‡ä»¶å¤¹
        for item in state.latest_session_dir.iterdir():
            if item.is_dir() and item.name.endswith('_details'):
                try:
                    # æ£€æŸ¥æ˜¯å¦æ˜¯å›¾åƒæ¨¡å¼ï¼ˆframe_xxx_detailsï¼‰
                    if item.name.startswith('frame_'):
                        # å›¾åƒæ¨¡å¼
                        image_details_file = item / 'image_details.json'
                        inference_result_file = item / 'inference_result.json'
                        mcp_result_file = item / 'mcp_result.json'
                        
                        if image_details_file.exists():
                            with open(image_details_file, 'r', encoding='utf-8') as f:
                                image_details = json.load(f)
                            
                            # æŸ¥æ‰¾å›¾åƒæ–‡ä»¶
                            image_files = list(item.glob('*.jpg')) + list(item.glob('*.png'))
                            if image_files:
                                image_file = image_files[0]
                                
                                # æ£€æŸ¥æ˜¯å¦åŒæ—¶æœ‰inference_result.jsonå’Œmcp_result.json
                                has_inference_result = inference_result_file.exists()
                                has_mcp_result = mcp_result_file.exists()
                                
                                # ğŸ†• æ£€æŸ¥æ˜¯å¦æœ‰ç”¨æˆ·é—®é¢˜ç»“æœ
                                user_question_file = item / 'user_question.json'
                                has_user_question_result = user_question_file.exists()
                                
                                media_item = {
                                    'type': 'image',
                                    'media_path': safe_relative_path(image_file),
                                    'filename': image_file.name,
                                    'frame_number': image_details.get('frame_number'),
                                    'timestamp': image_details.get('timestamp'),
                                    'timestamp_iso': image_details.get('timestamp_iso'),
                                    'relative_timestamp': image_details.get('relative_timestamp'),
                                    'creation_time': image_details.get('creation_time'),
                                    'has_inference_result': has_inference_result,
                                    'has_mcp_result': has_mcp_result,
                                    'has_user_question_result': has_user_question_result,  # ğŸ†• æ–°å¢å­—æ®µ
                                    'details_dir': safe_relative_path(item),
                                    'image_dimensions': image_details.get('image_dimensions', {})
                                }
                                
                                # ğŸ†• ä¼˜å…ˆå¤„ç†ç”¨æˆ·é—®é¢˜ç»“æœ
                                if has_user_question_result:
                                    with open(user_question_file, 'r', encoding='utf-8') as f:
                                        user_question_result = json.load(f)
                                    
                                    media_item.update({
                                        'user_question': user_question_result.get('user_question', ''),  # ç”¨æˆ·é—®é¢˜
                                        'response': user_question_result.get('response', ''),  # ç”¨æˆ·é—®é¢˜å›ç­”
                                        'user_question_timestamp': user_question_result.get('timestamp_iso', ''),  # ç”¨æˆ·é—®é¢˜æ—¶é—´æˆ³
                                        'analysis_type': 'user_question'  # æ ‡è®°ä¸ºç”¨æˆ·é—®é¢˜ç±»å‹
                                    })
                                
                                # å¦‚æœæœ‰æ¨ç†ç»“æœï¼Œæ·»åŠ æ¨ç†ä¿¡æ¯
                                if has_inference_result:
                                    with open(inference_result_file, 'r', encoding='utf-8') as f:
                                        inference_result = json.load(f)
                                    
                                    parsed_result = inference_result.get('parsed_result', {})
                                    media_item.update({
                                        'people_count': parsed_result.get('people_count', 0),
                                        'vehicle_count': parsed_result.get('vehicle_count', 0),
                                        'people': parsed_result.get('people', []),
                                        'vehicles': parsed_result.get('vehicles', []),
                                        'summary': parsed_result.get('summary', ''),
                                        'inference_duration': inference_result.get('inference_duration'),
                                        'inference_start_timestamp': inference_result.get('inference_start_timestamp'),
                                        'inference_end_timestamp': inference_result.get('inference_end_timestamp'),
                                        'raw_result': inference_result.get('raw_result')  # åŸå§‹ç»“æœ
                                    })
                                    
                                    # ğŸ”„ å¦‚æœæ²¡æœ‰ç”¨æˆ·é—®é¢˜ç»“æœï¼Œä½¿ç”¨æ¨ç†ç»“æœä¸­çš„responseå­—æ®µ
                                    if not has_user_question_result:
                                        media_item.update({
                                            'user_question': inference_result.get('user_question'),  # ç”¨æˆ·é—®é¢˜
                                            'response': parsed_result.get('response') or parsed_result.get('answer'),  # AIå›ç­”
                                            'analysis_type': 'vlm_inference'  # æ ‡è®°ä¸ºVLMæ¨ç†ç±»å‹
                                        })
                                
                                # å¦‚æœæœ‰MCPç»“æœï¼Œæ·»åŠ æ€è€ƒä¸è¡ŒåŠ¨ä¿¡æ¯
                                if has_mcp_result:
                                    with open(mcp_result_file, 'r', encoding='utf-8') as f:
                                        mcp_result = json.load(f)
                                    
                                    mcp_data = mcp_result.get('mcp_response_data', {}).get('data', {})
                                    control_result = mcp_data.get('control_result', {})
                                    
                                    media_item.update({
                                        'mcp_reason': control_result.get('reason', ''),  # æ€è€ƒåŸå› 
                                        'mcp_result': control_result.get('result', ''),  # æ‰§è¡Œç»“æœ
                                        'mcp_tool_name': control_result.get('tool_name', ''),  # å·¥å…·åç§°
                                        'mcp_arguments': control_result.get('arguments', {}),  # å·¥å…·å‚æ•°
                                        'mcp_success': control_result.get('success', False),  # æ‰§è¡Œæ˜¯å¦æˆåŠŸ
                                        'mcp_duration': mcp_result.get('mcp_duration', 0),  # MCPæ‰§è¡Œæ—¶é•¿
                                        'mcp_start_timestamp': mcp_result.get('mcp_start_timestamp', ''),  # MCPå¼€å§‹æ—¶é—´
                                        'mcp_end_timestamp': mcp_result.get('mcp_end_timestamp', '')  # MCPç»“æŸæ—¶é—´
                                    })
                                
                                media_items.append(media_item)
                    
                    else:
                        # è§†é¢‘æ¨¡å¼ï¼ˆsampled_video_xxx_detailsï¼‰
                        video_details_file = item / 'video_details.json'
                        inference_result_file = item / 'inference_result.json'
                        mcp_result_file = item / 'mcp_result.json'
                        
                        if video_details_file.exists():
                            with open(video_details_file, 'r', encoding='utf-8') as f:
                                video_details = json.load(f)
                            
                            # æŸ¥æ‰¾è§†é¢‘æ–‡ä»¶
                            video_files = list(item.glob('*.mp4'))
                            if video_files:
                                video_file = video_files[0]
                                
                                # æ£€æŸ¥æ˜¯å¦åŒæ—¶æœ‰inference_result.jsonå’Œmcp_result.json
                                has_inference_result = inference_result_file.exists()
                                has_mcp_result = mcp_result_file.exists()
                                
                                # ğŸ†• æ£€æŸ¥æ˜¯å¦æœ‰ç”¨æˆ·é—®é¢˜ç»“æœ
                                user_question_file = item / 'user_question.json'
                                has_user_question_result = user_question_file.exists()
                                
                                media_item = {
                                    'type': 'video',
                                    'media_path': safe_relative_path(video_file),
                                    'filename': video_file.name,
                                    'total_frames': video_details.get('total_frames'),
                                    'frames_per_second': video_details.get('frames_per_second'),
                                    'target_duration': video_details.get('target_duration'),
                                    'creation_time': video_details.get('creation_time'),
                                    'creation_timestamp': video_details.get('creation_timestamp'),
                                    'sampled_frames': video_details.get('sampled_frames', []),
                                    'has_inference_result': has_inference_result,
                                    'has_mcp_result': has_mcp_result,
                                    'has_user_question_result': has_user_question_result,  # ğŸ†• æ–°å¢å­—æ®µ
                                    'details_dir': safe_relative_path(item)
                                }
                                
                                # è®¡ç®—è§†é¢‘çš„æ—¶é—´èŒƒå›´
                                sampled_frames = video_details.get('sampled_frames', [])
                                if sampled_frames:
                                    media_item.update({
                                        'start_timestamp': sampled_frames[0].get('timestamp'),
                                        'end_timestamp': sampled_frames[-1].get('timestamp'),
                                        'start_relative_timestamp': sampled_frames[0].get('relative_timestamp'),
                                        'end_relative_timestamp': sampled_frames[-1].get('relative_timestamp'),
                                        'original_frame_range': [
                                            sampled_frames[0].get('original_frame_number'),
                                            sampled_frames[-1].get('original_frame_number')
                                        ]
                                    })
                                
                                # ğŸ†• ä¼˜å…ˆå¤„ç†ç”¨æˆ·é—®é¢˜ç»“æœ
                                if has_user_question_result:
                                    with open(user_question_file, 'r', encoding='utf-8') as f:
                                        user_question_result = json.load(f)
                                    
                                    media_item.update({
                                        'user_question': user_question_result.get('user_question', ''),  # ç”¨æˆ·é—®é¢˜
                                        'response': user_question_result.get('response', ''),  # ç”¨æˆ·é—®é¢˜å›ç­”
                                        'user_question_timestamp': user_question_result.get('timestamp_iso', ''),  # ç”¨æˆ·é—®é¢˜æ—¶é—´æˆ³
                                        'analysis_type': 'user_question'  # æ ‡è®°ä¸ºç”¨æˆ·é—®é¢˜ç±»å‹
                                    })
                                
                                # å¦‚æœæœ‰æ¨ç†ç»“æœï¼Œæ·»åŠ æ¨ç†ä¿¡æ¯
                                if has_inference_result:
                                    with open(inference_result_file, 'r', encoding='utf-8') as f:
                                        inference_result = json.load(f)
                                    
                                    parsed_result = inference_result.get('parsed_result', {})
                                    media_item.update({
                                        'people_count': parsed_result.get('people_count', 0),
                                        'vehicle_count': parsed_result.get('vehicle_count', 0),
                                        'people': parsed_result.get('people', []),
                                        'vehicles': parsed_result.get('vehicles', []),
                                        'summary': parsed_result.get('summary', ''),
                                        'inference_duration': inference_result.get('inference_duration'),
                                        'inference_start_timestamp': inference_result.get('inference_start_timestamp'),
                                        'inference_end_timestamp': inference_result.get('inference_end_timestamp'),
                                        'raw_result': inference_result.get('raw_result')  # åŸå§‹ç»“æœ
                                    })
                                    
                                    # ğŸ”„ å¦‚æœæ²¡æœ‰ç”¨æˆ·é—®é¢˜ç»“æœï¼Œä½¿ç”¨æ¨ç†ç»“æœä¸­çš„responseå­—æ®µ
                                    if not has_user_question_result:
                                        media_item.update({
                                            'user_question': inference_result.get('user_question'),  # ç”¨æˆ·é—®é¢˜
                                            'response': parsed_result.get('response') or parsed_result.get('answer'),  # AIå›ç­”
                                            'analysis_type': 'vlm_inference'  # æ ‡è®°ä¸ºVLMæ¨ç†ç±»å‹
                                        })
                                
                                # å¦‚æœæœ‰MCPç»“æœï¼Œæ·»åŠ æ€è€ƒä¸è¡ŒåŠ¨ä¿¡æ¯
                                if has_mcp_result:
                                    with open(mcp_result_file, 'r', encoding='utf-8') as f:
                                        mcp_result = json.load(f)
                                    
                                    mcp_data = mcp_result.get('mcp_response_data', {}).get('data', {})
                                    control_result = mcp_data.get('control_result', {})
                                    
                                    media_item.update({
                                        'mcp_reason': control_result.get('reason', ''),  # æ€è€ƒåŸå› 
                                        'mcp_result': control_result.get('result', ''),  # æ‰§è¡Œç»“æœ
                                        'mcp_tool_name': control_result.get('tool_name', ''),  # å·¥å…·åç§°
                                        'mcp_arguments': control_result.get('arguments', {}),  # å·¥å…·å‚æ•°
                                        'mcp_success': control_result.get('success', False),  # æ‰§è¡Œæ˜¯å¦æˆåŠŸ
                                        'mcp_duration': mcp_result.get('mcp_duration', 0),  # MCPæ‰§è¡Œæ—¶é•¿
                                        'mcp_start_timestamp': mcp_result.get('mcp_start_timestamp', ''),  # MCPå¼€å§‹æ—¶é—´
                                        'mcp_end_timestamp': mcp_result.get('mcp_end_timestamp', '')  # MCPç»“æŸæ—¶é—´
                                    })
                                
                                media_items.append(media_item)
                
                except Exception as e:
                    logger.warning(f"å¤„ç†åª’ä½“é¡¹ç›®å¤±è´¥ {item}: {e}")
                    continue
        
        # æŒ‰æ—¶é—´æˆ³æ’åºï¼ˆæœ€æ–°çš„åœ¨å‰ï¼‰
        media_items.sort(key=lambda x: x.get('timestamp', 0) or x.get('creation_timestamp', ''), reverse=True)
        
        # é™åˆ¶è¿”å›æ•°é‡
        if limit > 0:
            media_items = media_items[:limit]
        
        return ApiResponse(
            success=True,
            data={
                'media_items': media_items,
                'total_count': len(media_items),
                'session_dir': safe_relative_path(state.latest_session_dir) if state.latest_session_dir else None
            },
            timestamp=time.time()
        )
        
    except Exception as e:
        logger.error(f"è·å–åª’ä½“å†å²è®°å½•å¤±è´¥: {e}")
        return ApiResponse(
            success=False,
            error=f"è·å–åª’ä½“å†å²è®°å½•å¤±è´¥: {str(e)}",
            timestamp=time.time()
        )

@app.get("/api/media/{filename}")
@app.head("/api/media/{filename}")
async def serve_media(filename: str, request: Request):
    """æä¾›åª’ä½“æ–‡ä»¶ï¼ˆå›¾åƒæˆ–è§†é¢‘ï¼‰"""
    try:
        logger.info(f"è¯·æ±‚åª’ä½“æ–‡ä»¶: {filename}")
        
        # åˆ·æ–°æœ€æ–°çš„sessionç›®å½•
        state._find_latest_session_dir()
        
        if not state.latest_session_dir:
            raise HTTPException(status_code=404, detail="ä¸´æ—¶ç›®å½•ä¸å­˜åœ¨")
        
        media_file = None
        
        # åœ¨å½“å‰sessionç›®å½•ä¸‹æŸ¥æ‰¾åª’ä½“æ–‡ä»¶
        for item in state.latest_session_dir.iterdir():
            if item.is_dir() and item.name.endswith('_details'):
                # æŸ¥æ‰¾åŒ¹é…çš„åª’ä½“æ–‡ä»¶ï¼ˆè§†é¢‘æˆ–å›¾åƒï¼‰
                for media_path in item.glob('*'):
                    if media_path.is_file() and media_path.name == filename:
                        # æ£€æŸ¥æ˜¯å¦æ˜¯æ”¯æŒçš„åª’ä½“æ ¼å¼
                        if media_path.suffix.lower() in ['.mp4', '.jpg', '.jpeg', '.png']:
                            media_file = media_path
                            logger.info(f"æ‰¾åˆ°åª’ä½“æ–‡ä»¶: {media_file}")
                            break
                if media_file:
                    break
        
        if not media_file:
            logger.error(f"åª’ä½“æ–‡ä»¶ä¸å­˜åœ¨: {filename}")
            logger.info(f"å½“å‰sessionç›®å½•: {state.latest_session_dir}")
            
            # åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„åª’ä½“æ–‡ä»¶ç”¨äºè°ƒè¯•
            available_media = []
            if state.latest_session_dir:
                for item in state.latest_session_dir.iterdir():
                    if item.is_dir() and item.name.endswith('_details'):
                        for media in item.glob('*'):
                            if media.is_file() and media.suffix.lower() in ['.mp4', '.jpg', '.jpeg', '.png']:
                                available_media.append(media.name)
            logger.info(f"å¯ç”¨çš„åª’ä½“æ–‡ä»¶: {available_media}")
            raise HTTPException(status_code=404, detail=f"åª’ä½“æ–‡ä»¶ä¸å­˜åœ¨: {filename}")
        
        # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦çœŸçš„å­˜åœ¨ä¸”å¯è¯»
        if not media_file.exists():
            raise HTTPException(status_code=404, detail=f"åª’ä½“æ–‡ä»¶ä¸å­˜åœ¨: {media_file}")
        
        if not media_file.is_file():
            raise HTTPException(status_code=404, detail=f"è·¯å¾„ä¸æ˜¯æ–‡ä»¶: {media_file}")
        
        file_size = media_file.stat().st_size
        logger.info(f"è¿”å›åª’ä½“æ–‡ä»¶: {media_file}, å¤§å°: {file_size} bytes")
        
        # æ ¹æ®æ–‡ä»¶ç±»å‹è®¾ç½®Content-Type
        content_type = "application/octet-stream"
        if media_file.suffix.lower() == '.mp4':
            content_type = "video/mp4"
        elif media_file.suffix.lower() in ['.jpg', '.jpeg']:
            content_type = "image/jpeg"
        elif media_file.suffix.lower() == '.png':
            content_type = "image/png"
        
        # å¯¹äºå›¾åƒæ–‡ä»¶ï¼Œç›´æ¥è¿”å›
        if media_file.suffix.lower() in ['.jpg', '.jpeg', '.png']:
            return FileResponse(
                path=str(media_file),
                media_type=content_type,
                filename=media_file.name
            )
        
        # å¯¹äºè§†é¢‘æ–‡ä»¶ï¼Œå¤„ç†Rangeè¯·æ±‚
        range_header = request.headers.get('range')
        if range_header:
            logger.info(f"å¤„ç†Rangeè¯·æ±‚: {range_header}")
            # è§£æRangeå¤´
            range_match = range_header.replace('bytes=', '').split('-')
            start = int(range_match[0]) if range_match[0] else 0
            end = int(range_match[1]) if range_match[1] else file_size - 1
            
            # ç¡®ä¿èŒƒå›´æœ‰æ•ˆ
            start = max(0, start)
            end = min(file_size - 1, end)
            content_length = end - start + 1
            
            def iter_file():
                with open(media_file, 'rb') as f:
                    f.seek(start)
                    remaining = content_length
                    while remaining > 0:
                        chunk_size = min(8192, remaining)
                        chunk = f.read(chunk_size)
                        if not chunk:
                            break
                        remaining -= len(chunk)
                        yield chunk
            
            return StreamingResponse(
                iter_file(),
                status_code=206,
                headers={
                    'Content-Range': f'bytes {start}-{end}/{file_size}',
                    'Accept-Ranges': 'bytes',
                    'Content-Length': str(content_length),
                    'Content-Type': content_type,
                },
                media_type=content_type
            )
        else:
            # å®Œæ•´æ–‡ä»¶å“åº”
            return FileResponse(
                path=str(media_file),
                media_type=content_type,
                filename=media_file.name
            )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"æä¾›åª’ä½“æ–‡ä»¶å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"æœåŠ¡å™¨å†…éƒ¨é”™è¯¯: {str(e)}")

# å¥åº·æ£€æŸ¥ç«¯ç‚¹
@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥"""
    return {"status": "healthy", "timestamp": time.time()}

# å†…éƒ¨è§†é¢‘æµAPI - ä¾›æ¨ç†æœåŠ¡ä½¿ç”¨
@app.post("/internal/video/subscribe", response_model=ApiResponse)
async def subscribe_to_video_stream(request: Request):
    """å†…éƒ¨APIï¼šè®¢é˜…è§†é¢‘æµ"""
    try:
        # è¿™é‡Œæˆ‘ä»¬è¿”å›ä¸€ä¸ªè®¢é˜…IDï¼Œå®é™…çš„å›è°ƒéœ€è¦é€šè¿‡å…¶ä»–æ–¹å¼è®¾ç½®
        # åœ¨å®é™…å®ç°ä¸­ï¼Œæ¨ç†æœåŠ¡ä¼šé€šè¿‡å…¶ä»–æ–¹å¼æ³¨å†Œå›è°ƒ
        subscriber_id = f"internal_{int(time.time() * 1000)}"
        
        return ApiResponse(
            success=True,
            data={
                "subscriber_id": subscriber_id,
                "message": "è®¢é˜…æˆåŠŸï¼Œè¯·é€šè¿‡å†…éƒ¨æ¥å£è®¾ç½®å›è°ƒ"
            },
            timestamp=time.time()
        )
    except Exception as e:
        return ApiResponse(
            success=False,
            error=f"è®¢é˜…è§†é¢‘æµå¤±è´¥: {str(e)}",
            timestamp=time.time()
        )

@app.get("/internal/video/latest-frame")
async def get_latest_frame():
    """å†…éƒ¨APIï¼šè·å–æœ€æ–°å¸§"""
    try:
        latest_frame = state.video_distributor.get_latest_frame()
        if latest_frame is None:
            return JSONResponse(
                status_code=404,
                content={"error": "æ²¡æœ‰å¯ç”¨çš„è§†é¢‘å¸§"}
            )
        
        frame, timestamp = latest_frame
        
        # å°†å¸§ç¼–ç ä¸ºJPEGå¹¶è½¬æ¢ä¸ºbase64
        _, buffer = cv2.imencode('.jpg', frame, [cv2.IMWRITE_JPEG_QUALITY, 80])
        frame_base64 = base64.b64encode(buffer.tobytes()).decode('utf-8')
        
        return {
            "frame_data": frame_base64,
            "timestamp": timestamp,
            "frame_number": state.frame_count
        }
        
    except Exception as e:
        return JSONResponse(
            status_code=500,
            content={"error": f"è·å–æœ€æ–°å¸§å¤±è´¥: {str(e)}"}
        )

@app.get("/internal/video/status")
async def get_internal_video_status():
    """å†…éƒ¨APIï¼šè·å–è§†é¢‘æµçŠ¶æ€"""
    return {
        "streaming": state.streaming,
        "subscriber_count": state.video_distributor.get_subscriber_count(),
        "frame_count": state.frame_count,
        "has_latest_frame": state.video_distributor.get_latest_frame() is not None
    }

# æä¾›ç»™æ¨ç†æœåŠ¡çš„ç›´æ¥æ¥å£
def register_inference_callback(callback: Callable[[np.ndarray, float], bool]) -> str:
    """
    ä¸ºæ¨ç†æœåŠ¡æ³¨å†Œè§†é¢‘å¸§å›è°ƒ
    è¿™ä¸ªå‡½æ•°ä¼šè¢«æ¨ç†æœåŠ¡ç›´æ¥è°ƒç”¨
    
    Args:
        callback: å¸§å¤„ç†å›è°ƒå‡½æ•°
        
    Returns:
        è®¢é˜…ID
    """
    return state.video_distributor.subscribe(callback)

def unregister_inference_callback(subscriber_id: str):
    """å–æ¶ˆæ¨ç†æœåŠ¡çš„è§†é¢‘å¸§è®¢é˜…"""
    state.video_distributor.unsubscribe(subscriber_id)

# æ·»åŠ æ–°çš„HTTPæµåª’ä½“ç«¯ç‚¹
@app.get("/api/video-stream")
async def video_stream():
    """æä¾›MJPEGè§†é¢‘æµ - æè‡´æ€§èƒ½ç‰ˆæœ¬"""
    
    def generate_mjpeg_stream():
        """ç”ŸæˆMJPEGæµ - æè‡´æ€§èƒ½ä¼˜åŒ–ç‰ˆæœ¬"""
        boundary = "frame"
        frame_count = 0
        last_frame_time = time.time()
        last_fps_log = time.time()
        
        # é¢„åˆ†é…ç©ºç™½å¸§ï¼Œé¿å…é‡å¤åˆ›å»º
        blank_frame = np.zeros((360, 640, 3), dtype=np.uint8)
        _, blank_jpeg = cv2.imencode('.jpg', blank_frame, [cv2.IMWRITE_JPEG_QUALITY, 30])
        blank_jpeg_data = blank_jpeg.tobytes()
        
        # æ€§èƒ½ä¼˜åŒ–å˜é‡
        consecutive_same_frames = 0
        last_frame_data = None
        no_frame_count = 0
        
        # é¢„è®¡ç®—å›ºå®šçš„è¾¹ç•Œå­—ç¬¦ä¸²
        boundary_bytes = boundary.encode()
        content_type_header = b'Content-Type: image/jpeg\r\n'
        
        logger.info("MJPEGæµç”Ÿæˆå™¨å¯åŠ¨")
        
        while True:
            current_time = time.time()
            
            # è·å–æœ€æ–°çš„JPEGå¸§ï¼ˆåŸå­æ“ä½œï¼Œæ— é”ï¼‰
            jpeg_data = state.latest_jpeg_frame
            if jpeg_data is None:
                no_frame_count += 1
                if no_frame_count % 100 == 1:  # æ¯100æ¬¡è®°å½•ä¸€æ¬¡
                    logger.warning(f"æ²¡æœ‰å¯ç”¨çš„è§†é¢‘å¸§ï¼Œä½¿ç”¨ç©ºç™½å¸§ (ç¬¬{no_frame_count}æ¬¡)")
                jpeg_data = blank_jpeg_data
            else:
                if no_frame_count > 0:
                    logger.info(f"æ¢å¤è§†é¢‘å¸§ï¼Œä¹‹å‰ç¼ºå¤±{no_frame_count}æ¬¡")
                    no_frame_count = 0
            
            # æ£€æµ‹é‡å¤å¸§ï¼Œé¿å…å‘é€ç›¸åŒæ•°æ®
            if jpeg_data == last_frame_data:
                consecutive_same_frames += 1
                # å¦‚æœè¿ç»­ç›¸åŒå¸§è¶…è¿‡5å¸§ï¼Œç¨å¾®å»¶è¿Ÿä»¥é¿å…æµªè´¹å¸¦å®½
                if consecutive_same_frames > 5:
                    time.sleep(0.008)  # 8mså»¶è¿Ÿ
                    continue
            else:
                consecutive_same_frames = 0
                last_frame_data = jpeg_data
            
            # é¢„è®¡ç®—å¸§å¤´ï¼Œå‡å°‘å­—ç¬¦ä¸²æ“ä½œ
            content_length = str(len(jpeg_data)).encode()
            frame_header = (
                b'--' + boundary_bytes + b'\r\n' +
                content_type_header +
                b'Content-Length: ' + content_length + b'\r\n\r\n'
            )
            
            # ä¸€æ¬¡æ€§å‘é€å®Œæ•´å¸§ï¼ˆå‡å°‘ç³»ç»Ÿè°ƒç”¨ï¼‰
            yield frame_header + jpeg_data + b'\r\n'
            
            frame_count += 1
            
            # åŠ¨æ€å¸§ç‡æ§åˆ¶ - æ ¹æ®æ˜¯å¦æœ‰æ–°å¸§è°ƒæ•´
            if state.latest_jpeg_frame is not None:
                # æœ‰æ–°å¸§æ—¶ï¼Œé«˜é€Ÿå‘é€
                time.sleep(0.008)  # ~125fps
            else:
                # æ²¡æœ‰æ–°å¸§æ—¶ï¼Œé™ä½å‘é€é¢‘ç‡
                time.sleep(0.033)  # ~30fps
            
            # æ€§èƒ½ç›‘æ§ï¼ˆæ¯10ç§’è®°å½•ä¸€æ¬¡ï¼‰
            if current_time - last_fps_log > 10.0:
                elapsed = current_time - last_frame_time
                if elapsed > 0:
                    fps = (frame_count - (frame_count - 200 if frame_count > 200 else 0)) / elapsed
                    logger.info(f"MJPEGæµæ€§èƒ½: {fps:.1f}fps, å¸§å¤§å°: {len(jpeg_data)/1024:.1f}KB, é‡å¤å¸§: {consecutive_same_frames}, ç¼ºå¤±å¸§: {no_frame_count}")
                last_fps_log = current_time
                if frame_count > 200:
                    last_frame_time = current_time
                    frame_count = 200  # é‡ç½®è®¡æ•°å™¨
    
    return StreamingResponse(generate_mjpeg_stream(), media_type="multipart/x-mixed-replace; boundary=frame")

# å“¨å…µæ¨¡å¼ç›¸å…³APIç«¯ç‚¹
@app.get("/api/sentry-mode", response_model=ApiResponse)
async def get_sentry_mode():
    """è·å–å“¨å…µæ¨¡å¼çŠ¶æ€"""
    try:
        enabled = state.get_sentry_mode()
        return ApiResponse(
            success=True,
            data={
                "enabled": enabled,
                "status": "å¯ç”¨" if enabled else "ç¦ç”¨"
            },
            timestamp=time.time()
        )
    except Exception as e:
        logger.error(f"è·å–å“¨å…µæ¨¡å¼çŠ¶æ€å¤±è´¥: {str(e)}")
        return ApiResponse(
            success=False,
            error=f"è·å–å“¨å…µæ¨¡å¼çŠ¶æ€å¤±è´¥: {str(e)}",
            timestamp=time.time()
        )

@app.post("/api/sentry-mode", response_model=ApiResponse)
async def set_sentry_mode(request: Request):
    """è®¾ç½®å“¨å…µæ¨¡å¼çŠ¶æ€"""
    try:
        data = await request.json()
        enabled = data.get("enabled", True)
        
        if not isinstance(enabled, bool):
            return ApiResponse(
                success=False,
                error="enabledå‚æ•°å¿…é¡»æ˜¯å¸ƒå°”å€¼",
                timestamp=time.time()
            )
        
        state.set_sentry_mode(enabled)
        mode_text = "å¯ç”¨" if enabled else "ç¦ç”¨"
        
        return ApiResponse(
            success=True,
            data={
                "enabled": enabled,
                "status": mode_text,
                "message": f"å“¨å…µæ¨¡å¼å·²{mode_text}"
            },
            timestamp=time.time()
        )
    except Exception as e:
        logger.error(f"è®¾ç½®å“¨å…µæ¨¡å¼å¤±è´¥: {str(e)}")
        return ApiResponse(
            success=False,
            error=f"è®¾ç½®å“¨å…µæ¨¡å¼å¤±è´¥: {str(e)}",
            timestamp=time.time()
        )

@app.post("/api/sentry-mode/toggle", response_model=ApiResponse)
async def toggle_sentry_mode():
    """åˆ‡æ¢å“¨å…µæ¨¡å¼çŠ¶æ€"""
    try:
        new_state = state.toggle_sentry_mode()
        mode_text = "å¯ç”¨" if new_state else "ç¦ç”¨"
        
        return ApiResponse(
            success=True,
            data={
                "enabled": new_state,
                "status": mode_text,
                "message": f"å“¨å…µæ¨¡å¼å·²åˆ‡æ¢ä¸º{mode_text}"
            },
            timestamp=time.time()
        )
    except Exception as e:
        logger.error(f"åˆ‡æ¢å“¨å…µæ¨¡å¼å¤±è´¥: {str(e)}")
        return ApiResponse(
            success=False,
            error=f"åˆ‡æ¢å“¨å…µæ¨¡å¼å¤±è´¥: {str(e)}",
            timestamp=time.time()
        )

if __name__ == "__main__":
    import uvicorn
    
    logger.info("ğŸš€ å¯åŠ¨FastAPIåç«¯æœåŠ¡å™¨...")
    logger.info(f"ğŸ“Š å®éªŒæ—¥å¿—è·¯å¾„: {state.experiment_log_path}")
    logger.info(f"ğŸ“ ä¸´æ—¶ç›®å½•: {state.temp_dir}")
    logger.info("ğŸŒ æœåŠ¡åœ°å€: http://localhost:8080")
    logger.info("ğŸ”Œ WebSocket: ws://localhost:8080/ws")
    logger.info("ğŸ“š APIæ–‡æ¡£: http://localhost:8080/docs")
    
    uvicorn.run(
        "app:app",
        host="0.0.0.0",
        port=8080,
        reload=True,
        log_level="info"
    ) 