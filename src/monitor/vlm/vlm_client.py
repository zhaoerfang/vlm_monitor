#!/usr/bin/env python3
"""
VLMå®¢æˆ·ç«¯æ¨¡å—
æä¾›è§†é¢‘å’Œå›¾åƒåˆ†æåŠŸèƒ½ï¼Œæ”¯æŒåŒæ­¥å’Œå¼‚æ­¥è°ƒç”¨
"""

import os
import base64
import asyncio
import logging
import math
import time
from datetime import datetime
from typing import Optional, Dict, List, Any, Tuple
from openai import AsyncOpenAI
from pathlib import Path
from PIL import Image
import requests
import json as json_module

# å¯¼å…¥é…ç½®ç®¡ç†æ¨¡å—
from ..core.config import load_config

logger = logging.getLogger(__name__)

class DashScopeVLMClient:
    def __init__(self, api_key: Optional[str] = None, model: Optional[str] = None, 
                 base_url: Optional[str] = None):
        """
        åˆå§‹åŒ–DashScope VLMå®¢æˆ·ç«¯
        
        Args:
            api_key: APIå¯†é’¥ï¼Œå¦‚æœä¸ºNoneåˆ™ä»é…ç½®æ–‡ä»¶è¯»å–
            model: æ¨¡å‹åç§°ï¼Œå¦‚æœä¸ºNoneåˆ™ä»é…ç½®æ–‡ä»¶è¯»å–
            base_url: APIåŸºç¡€URLï¼Œå¦‚æœä¸ºNoneåˆ™ä»é…ç½®æ–‡ä»¶è¯»å–
        """
        # åŠ è½½é…ç½®
        config = load_config()
        vlm_config = config.get('vlm', {})
        
        # è®¾ç½®APIå‚æ•°
        self.api_key = api_key or vlm_config.get('api_key')
        self.model = model or vlm_config.get('model', 'qwen-vl-max')
        self.base_url = base_url or vlm_config.get('base_url')
        
        if not self.api_key:
            raise ValueError("APIå¯†é’¥æœªè®¾ç½®ï¼Œè¯·åœ¨é…ç½®æ–‡ä»¶ä¸­è®¾ç½®vlm.api_keyæˆ–ä¼ å…¥api_keyå‚æ•°")
        
        # æ–‡ä»¶å¤§å°é™åˆ¶
        self.max_video_size_mb = vlm_config.get('max_video_size_mb', 100)
        self.max_base64_size_mb = vlm_config.get('max_base64_size_mb', 10)
        
        # æç¤ºè¯é…ç½®
        self.default_prompt = vlm_config.get('default_prompt', {})
        self.user_question_prompt = vlm_config.get('user_question_prompt', {})
        
        self.system_prompt = self.default_prompt.get('system', 
            "You are a helpful assistant that analyzes videos and returns structured JSON responses.")
        self.user_prompt_template = self.default_prompt.get('user_template', 
            "è¯·åˆ†æè¿™æ®µè§†é¢‘å†…å®¹")
        
        # ç”¨æˆ·é—®é¢˜ä¸“ç”¨æç¤ºè¯
        self.user_question_system_prompt = self.user_question_prompt.get('system',
            "ä½ æ˜¯ä¸€ä¸ªå›¾åƒåˆ†æåŠ©æ‰‹ï¼Œè¯·æ ¹æ®å›¾åƒå†…å®¹å›ç­”ç”¨æˆ·é—®é¢˜ã€‚")
        self.user_question_template = self.user_question_prompt.get('user_template',
            "è¯·æ ¹æ®è¿™å¼ å›¾åƒå›ç­”ç”¨æˆ·çš„é—®é¢˜ï¼š{user_question}")
        
        # åˆ›å»ºå¼‚æ­¥OpenAIå®¢æˆ·ç«¯
        self.async_client = AsyncOpenAI(
            api_key=self.api_key,
            base_url=self.base_url,
        )
        
        # æ”¯æŒçš„æ–‡ä»¶æ ¼å¼
        self.video_extensions = {'.mp4', '.avi', '.mov', '.mkv', '.wmv', '.flv', '.webm'}
        self.image_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.gif', '.tiff', '.webp'}
        
        logger.info(f"âœ… VLMå®¢æˆ·ç«¯åˆå§‹åŒ–å®Œæˆ:")
        logger.info(f"  - æ¨¡å‹: {self.model}")
        logger.info(f"  - åŸºç¡€URL: {self.base_url}")
        logger.info(f"  - æœ€å¤§è§†é¢‘å¤§å°: {self.max_video_size_mb}MB")
        logger.info(f"  - æœ€å¤§Base64å¤§å°: {self.max_base64_size_mb}MB")
        logger.info(f"  - ç”¨æˆ·é—®é¢˜ä¸“ç”¨æç¤ºè¯å·²é…ç½®: {'æ˜¯' if self.user_question_prompt else 'å¦'}")
        
    def _is_video_file(self, file_path: str) -> bool:
        """åˆ¤æ–­æ–‡ä»¶æ˜¯å¦ä¸ºè§†é¢‘æ–‡ä»¶"""
        return Path(file_path).suffix.lower() in self.video_extensions
    
    def _is_image_file(self, file_path: str) -> bool:
        """åˆ¤æ–­æ–‡ä»¶æ˜¯å¦ä¸ºå›¾åƒæ–‡ä»¶"""
        return Path(file_path).suffix.lower() in self.image_extensions
        
    def encode_video(self, video_path: str) -> str:
        """å°†è§†é¢‘æ–‡ä»¶ç¼–ç ä¸ºbase64æ ¼å¼"""
        try:
            # æ£€æŸ¥åŸå§‹æ–‡ä»¶å¤§å°
            file_size_mb = os.path.getsize(video_path) / (1024 * 1024)
            logger.info(f"åŸå§‹è§†é¢‘æ–‡ä»¶å¤§å°: {file_size_mb:.2f}MB")
            
            if file_size_mb > self.max_video_size_mb:
                raise ValueError(f"è§†é¢‘æ–‡ä»¶è¿‡å¤§: {file_size_mb:.2f}MB > {self.max_video_size_mb}MBé™åˆ¶")
            
            with open(video_path, "rb") as video_file:
                video_data = video_file.read()
                base64_data = base64.b64encode(video_data).decode("utf-8")
                
                # æ£€æŸ¥Base64ç¼–ç åçš„å¤§å°
                base64_size_mb = len(base64_data.encode('utf-8')) / (1024 * 1024)
                logger.info(f"Base64ç¼–ç åå¤§å°: {base64_size_mb:.2f}MB")
                
                # æ ¡éªŒBase64å¤§å°é™åˆ¶
                if base64_size_mb > self.max_base64_size_mb:
                    raise ValueError(f"Base64ç¼–ç åçš„è§†é¢‘è¿‡å¤§: {base64_size_mb:.2f}MB > {self.max_base64_size_mb}MBé™åˆ¶")
                
                return base64_data
        except Exception as e:
            logger.error(f"è§†é¢‘ç¼–ç å¤±è´¥: {str(e)}")
            raise
    
    def encode_image(self, image_path: str) -> str:
        """å°†å›¾åƒæ–‡ä»¶ç¼–ç ä¸ºbase64æ ¼å¼"""
        try:
            # æ£€æŸ¥åŸå§‹æ–‡ä»¶å¤§å°
            file_size_mb = os.path.getsize(image_path) / (1024 * 1024)
            logger.info(f"åŸå§‹å›¾åƒæ–‡ä»¶å¤§å°: {file_size_mb:.2f}MB")
            
            if file_size_mb > self.max_base64_size_mb:
                raise ValueError(f"å›¾åƒæ–‡ä»¶è¿‡å¤§: {file_size_mb:.2f}MB > {self.max_base64_size_mb}MBé™åˆ¶")
            
            with open(image_path, "rb") as image_file:
                image_data = image_file.read()
                base64_data = base64.b64encode(image_data).decode("utf-8")
                
                # æ£€æŸ¥Base64ç¼–ç åçš„å¤§å°
                base64_size_mb = len(base64_data.encode('utf-8')) / (1024 * 1024)
                logger.info(f"Base64ç¼–ç åå¤§å°: {base64_size_mb:.2f}MB")
                
                return base64_data
        except Exception as e:
            logger.error(f"å›¾åƒç¼–ç å¤±è´¥: {str(e)}")
            raise
        
    def analyze_video(self, video_path: str, prompt: Optional[str] = None, fps: int = 2) -> Optional[str]:
        """
        åŒæ­¥åˆ†æè§†é¢‘å†…å®¹ï¼ˆå…¼å®¹æ€§æ–¹æ³•ï¼‰
        
        Args:
            video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
            prompt: åˆ†ææç¤ºè¯ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„é»˜è®¤æç¤ºè¯
            fps: è§†é¢‘å¸§ç‡ï¼ˆç”¨äºæ§åˆ¶åˆ†æçš„å¸§æ•°ï¼‰
            
        Returns:
            åˆ†æç»“æœæ–‡æœ¬ï¼Œå¦‚æœå¤±è´¥è¿”å›None
        """
        try:
            # ä½¿ç”¨asyncioè¿è¡Œå¼‚æ­¥æ–¹æ³•
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            try:
                result = loop.run_until_complete(self.analyze_video_async(video_path, prompt, fps))
                return result
            finally:
                loop.close()
        except Exception as e:
            logger.error(f"åŒæ­¥è§†é¢‘åˆ†æå¤±è´¥: {str(e)}")
            return None
    
    def analyze_image(self, image_path: str, prompt: Optional[str] = None, 
                     user_question: Optional[str] = None, 
                     enable_camera_control: bool = True) -> Optional[str]:
        """
        åŒæ­¥åˆ†æå›¾åƒå†…å®¹
        
        Args:
            image_path: å›¾åƒæ–‡ä»¶è·¯å¾„
            prompt: åˆ†ææç¤ºè¯ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„é»˜è®¤æç¤ºè¯
            user_question: ç”¨æˆ·é—®é¢˜ï¼Œå¦‚æœæœ‰åˆ™ä¼šæ·»åŠ åˆ°æç¤ºè¯ä¸­
            enable_camera_control: æ˜¯å¦å¯ç”¨æ‘„åƒå¤´æ§åˆ¶åŠŸèƒ½ï¼ˆå“¨å…µæ¨¡å¼ï¼‰
            
        Returns:
            åˆ†æç»“æœæ–‡æœ¬ï¼Œå¦‚æœå¤±è´¥è¿”å›None
        """
        try:
            # ä½¿ç”¨asyncioè¿è¡Œå¼‚æ­¥æ–¹æ³•
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            try:
                result = loop.run_until_complete(
                    self.analyze_image_async(image_path, prompt, user_question, enable_camera_control)
                )
                return result
            finally:
                loop.close()
        except Exception as e:
            logger.error(f"åŒæ­¥å›¾åƒåˆ†æå¤±è´¥: {str(e)}")
            return None
    
    def analyze_media(self, media_path: str, prompt: Optional[str] = None, fps: int = 2, 
                     user_question: Optional[str] = None, 
                     enable_camera_control: bool = True) -> Optional[str]:
        """
        è‡ªåŠ¨è¯†åˆ«å¹¶åˆ†æåª’ä½“æ–‡ä»¶ï¼ˆè§†é¢‘æˆ–å›¾åƒï¼‰
        
        Args:
            media_path: åª’ä½“æ–‡ä»¶è·¯å¾„
            prompt: åˆ†ææç¤ºè¯ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„é»˜è®¤æç¤ºè¯
            fps: è§†é¢‘å¸§ç‡ï¼ˆä»…å¯¹è§†é¢‘æœ‰æ•ˆï¼‰
            user_question: ç”¨æˆ·é—®é¢˜ï¼Œå¦‚æœæœ‰åˆ™ä¼šæ·»åŠ åˆ°æç¤ºè¯ä¸­
            enable_camera_control: æ˜¯å¦å¯ç”¨æ‘„åƒå¤´æ§åˆ¶åŠŸèƒ½ï¼ˆå“¨å…µæ¨¡å¼ï¼‰
            
        Returns:
            åˆ†æç»“æœæ–‡æœ¬ï¼Œå¦‚æœå¤±è´¥è¿”å›None
        """
        if self._is_video_file(media_path):
            logger.info(f"æ£€æµ‹åˆ°è§†é¢‘æ–‡ä»¶: {media_path}")
            return self.analyze_video(media_path, prompt, fps)
        elif self._is_image_file(media_path):
            logger.info(f"æ£€æµ‹åˆ°å›¾åƒæ–‡ä»¶: {media_path}")
            return self.analyze_image(media_path, prompt, user_question, enable_camera_control)
        else:
            logger.error(f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {media_path}")
            return None
    
    async def analyze_video_async(self, video_path: str, prompt: Optional[str] = None, fps: int = 2) -> Optional[str]:
        """
        å¼‚æ­¥åˆ†æè§†é¢‘å†…å®¹
        
        Args:
            video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
            prompt: åˆ†ææç¤ºè¯ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„é»˜è®¤æç¤ºè¯
            fps: è§†é¢‘å¸§ç‡ï¼ˆç”¨äºæ§åˆ¶åˆ†æçš„å¸§æ•°ï¼‰
            
        Returns:
            åˆ†æç»“æœæ–‡æœ¬ï¼Œå¦‚æœå¤±è´¥è¿”å›None
        """
        try:
            # æ£€æŸ¥æ–‡ä»¶å¤§å°
            file_size_mb = os.path.getsize(video_path) / (1024 * 1024)
            if file_size_mb > self.max_video_size_mb:
                logger.error(f"è§†é¢‘æ–‡ä»¶è¿‡å¤§: {file_size_mb:.2f}MBï¼Œè¶…è¿‡{self.max_video_size_mb}MBé™åˆ¶")
                return None
                
            logger.info(f"å¼€å§‹å¼‚æ­¥åˆ†æè§†é¢‘: {video_path} ({file_size_mb:.2f}MB)")
            
            # ç¼–ç è§†é¢‘ä¸ºbase64
            base64_video = self.encode_video(video_path)
            
            # ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„é»˜è®¤æç¤ºè¯
            if prompt is None:
                prompt = self.user_prompt_template
            
            # æ„å»ºæ¶ˆæ¯ - è§†é¢‘æ ¼å¼
            messages: List[Dict[str, Any]] = [
                {
                    "role": "system",
                    "content": self.system_prompt
                },
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "video_url",
                            "video_url": {"url": f"data:video/mp4;base64,{base64_video}"},
                        },
                        {"type": "text", "text": prompt},
                    ],
                }
            ]
            
            # å¼‚æ­¥è°ƒç”¨API
            completion = await self.async_client.chat.completions.create(
                model=self.model,
                messages=messages  # type: ignore
            )
            
            # å¤„ç†å“åº”
            if completion.choices and len(completion.choices) > 0:
                result = completion.choices[0].message.content
                if result is not None:
                    logger.info(f"å¼‚æ­¥è§†é¢‘åˆ†æå®Œæˆï¼Œç»“æœé•¿åº¦: {len(result)} å­—ç¬¦")
                    return result
                else:
                    logger.error("APIè¿”å›ç»“æœä¸ºç©º")
                    return None
            else:
                logger.error(f"APIå“åº”æ ¼å¼å¼‚å¸¸: {completion}")
                return None
                
        except Exception as e:
            logger.error(f"å¼‚æ­¥è§†é¢‘åˆ†æå¤±è´¥: {str(e)}")
            return None
    
    async def analyze_image_async(self, image_path: str, prompt: Optional[str] = None, 
                                 user_question: Optional[str] = None, 
                                 enable_camera_control: bool = True) -> Optional[str]:
        """
        å¼‚æ­¥åˆ†æå›¾åƒå†…å®¹
        
        Args:
            image_path: å›¾åƒæ–‡ä»¶è·¯å¾„
            prompt: åˆ†ææç¤ºè¯ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„é»˜è®¤æç¤ºè¯
            user_question: ç”¨æˆ·é—®é¢˜ï¼Œå¦‚æœæœ‰åˆ™ä¼šå¯åŠ¨å¹¶è¡Œæ¨ç†
            enable_camera_control: æ˜¯å¦å¯ç”¨æ‘„åƒå¤´æ§åˆ¶åŠŸèƒ½
            
        Returns:
            åˆ†æç»“æœæ–‡æœ¬ï¼Œå¦‚æœå¤±è´¥è¿”å›None
        """
        try:
            # æ£€æŸ¥æ–‡ä»¶å¤§å°
            file_size_mb = os.path.getsize(image_path) / (1024 * 1024)
            if file_size_mb > self.max_base64_size_mb:
                logger.error(f"å›¾åƒæ–‡ä»¶è¿‡å¤§: {file_size_mb:.2f}MBï¼Œè¶…è¿‡{self.max_base64_size_mb}MBé™åˆ¶")
                return None
                
            logger.info(f"å¼€å§‹å¼‚æ­¥åˆ†æå›¾åƒ: {image_path} ({file_size_mb:.2f}MB)")

            if user_question:
                logger.info(f"ç”¨æˆ·é—®é¢˜: {user_question}")
            if enable_camera_control:
                logger.info("å¯ç”¨æ‘„åƒå¤´æ§åˆ¶åŠŸèƒ½")
            
            # ğŸš€ å¯åŠ¨VLMå›¾åƒåˆ†æä»»åŠ¡ï¼ˆæ€»æ˜¯æ‰§è¡Œï¼Œè¿™æ˜¯ä¸»è¦ä»»åŠ¡ï¼‰
            vlm_task = asyncio.create_task(self._perform_vlm_analysis(image_path, prompt, None))  # ä¸ä¼ é€’ç”¨æˆ·é—®é¢˜
            logger.info("ğŸš€ VLMå›¾åƒåˆ†æä»»åŠ¡å·²å¯åŠ¨")
            
            # æ”¶é›†æ‰€æœ‰éœ€è¦ç­‰å¾…çš„ä»»åŠ¡
            all_tasks = [vlm_task]
            
            # ğŸš€ å¯åŠ¨ç”¨æˆ·é—®é¢˜å›ç­”ä»»åŠ¡ï¼ˆå¦‚æœæœ‰ç”¨æˆ·é—®é¢˜ï¼Œç‹¬ç«‹æ‰§è¡Œå¹¶ç«‹å³ä¿å­˜ï¼‰
            if user_question:
                user_question_task = asyncio.create_task(
                    self._perform_and_save_user_question_analysis(image_path, user_question)
                )
                all_tasks.append(user_question_task)
                logger.info("ğŸš€ ç”¨æˆ·é—®é¢˜å›ç­”ä»»åŠ¡å·²å¯åŠ¨ï¼ˆç‹¬ç«‹æ‰§è¡Œï¼‰")
            
            # ğŸš€ å¯åŠ¨MCPæ‘„åƒå¤´æ§åˆ¶ä»»åŠ¡ï¼ˆå¦‚æœå¯ç”¨ä¸”æ²¡æœ‰ç”¨æˆ·é—®é¢˜ï¼Œç‹¬ç«‹æ‰§è¡Œï¼‰
            if enable_camera_control and not user_question:
                mcp_task = asyncio.create_task(
                    self._perform_and_save_mcp_control(image_path, user_question)
                )
                all_tasks.append(mcp_task)
                logger.info("ğŸš€ MCPæ‘„åƒå¤´æ§åˆ¶ä»»åŠ¡å·²å¯åŠ¨ï¼ˆç‹¬ç«‹æ‰§è¡Œï¼‰")
            
            # âš¡ ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆï¼Œç¡®ä¿ release_question æ—¶æœºæ­£ç¡®
            logger.info(f"âš¡ ç­‰å¾… {len(all_tasks)} ä¸ªä»»åŠ¡å…¨éƒ¨å®Œæˆ...")
            results = await asyncio.gather(*all_tasks, return_exceptions=True)
            
            # å¤„ç†VLMåˆ†æç»“æœï¼ˆç¬¬ä¸€ä¸ªä»»åŠ¡ï¼‰
            vlm_result = results[0]
            if isinstance(vlm_result, Exception):
                logger.error(f"VLMåˆ†æå¤±è´¥: {vlm_result}")
                vlm_result = None
            
            # æ£€æŸ¥å…¶ä»–ä»»åŠ¡çš„æ‰§è¡ŒçŠ¶æ€ï¼ˆç”¨äºæ—¥å¿—è®°å½•ï¼‰
            if len(results) > 1:
                for i, result in enumerate(results[1:], 1):
                    task_name = "ç”¨æˆ·é—®é¢˜å›ç­”" if user_question else "MCPæ§åˆ¶"
                    if isinstance(result, Exception):
                        logger.error(f"{task_name}ä»»åŠ¡å¤±è´¥: {result}")
                    else:
                        logger.info(f"âœ… {task_name}ä»»åŠ¡å·²å®Œæˆ")
            
            # ç¡®ä¿vlm_resultæ˜¯å­—ç¬¦ä¸²æˆ–None
            if vlm_result is not None and not isinstance(vlm_result, str):
                logger.warning(f"VLMåˆ†æè¿”å›äº†æ„å¤–çš„ç»“æœç±»å‹: {type(vlm_result)}")
                vlm_result = None
            
            logger.info(f"âœ… VLMå›¾åƒåˆ†æå®Œæˆï¼Œç»“æœé•¿åº¦: {len(vlm_result) if vlm_result else 0} å­—ç¬¦")
            if user_question:
                logger.info("ğŸ¤” ç”¨æˆ·é—®é¢˜å›ç­”ä»»åŠ¡æ­£åœ¨åå°ç‹¬ç«‹æ‰§è¡Œ...")
            
            return vlm_result
                
        except Exception as e:
            logger.error(f"å¼‚æ­¥å›¾åƒåˆ†æå¤±è´¥: {str(e)}")
            return None

    async def _perform_vlm_analysis(self, image_path: str, prompt: Optional[str] = None, 
                                   user_question: Optional[str] = None) -> Optional[str]:
        """
        æ‰§è¡ŒVLMå›¾åƒåˆ†æ
        
        Args:
            image_path: å›¾åƒæ–‡ä»¶è·¯å¾„
            prompt: åˆ†ææç¤ºè¯
            user_question: ç”¨æˆ·é—®é¢˜
            
        Returns:
            åˆ†æç»“æœæ–‡æœ¬
        """
        try:
            logger.info("ğŸ” å¼€å§‹VLMå›¾åƒåˆ†æ...")
            vlm_start_time = time.time()
            
            # ç¼–ç å›¾åƒä¸ºbase64
            base64_image = self.encode_image(image_path)
            
            # è·å–å›¾åƒæ–‡ä»¶æ‰©å±•åï¼Œç”¨äºç¡®å®šMIMEç±»å‹
            ext = Path(image_path).suffix.lower()
            mime_type = {
                '.jpg': 'image/jpeg', '.jpeg': 'image/jpeg',
                '.png': 'image/png', '.bmp': 'image/bmp',
                '.gif': 'image/gif', '.tiff': 'image/tiff',
                '.webp': 'image/webp'
            }.get(ext, 'image/jpeg')
            
            # ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„é»˜è®¤æç¤ºè¯
            if prompt is None:
                prompt = self.user_prompt_template
            
            # å¦‚æœæœ‰ç”¨æˆ·é—®é¢˜ï¼Œæ·»åŠ åˆ°æç¤ºè¯ä¸­
            if user_question:
                prompt = f"{prompt}\n\nç”¨æˆ·é—®é¢˜: {user_question}"
            
            # æ„å»ºæ¶ˆæ¯ - å›¾åƒæ ¼å¼
            messages: List[Dict[str, Any]] = [
                {
                    "role": "system",
                    "content": self.system_prompt
                },
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "image_url",
                            "image_url": {"url": f"data:{mime_type};base64,{base64_image}"},
                        },
                        {"type": "text", "text": prompt},
                    ],
                }
            ]
            
            # å¼‚æ­¥è°ƒç”¨API
            completion = await self.async_client.chat.completions.create(
                model=self.model,
                messages=messages  # type: ignore
            )
            
            # å¤„ç†å“åº”
            if completion.choices and len(completion.choices) > 0:
                result = completion.choices[0].message.content
                if result is not None:
                    vlm_duration = time.time() - vlm_start_time
                    logger.info(f"âœ… VLMå›¾åƒåˆ†æå®Œæˆï¼Œè€—æ—¶: {vlm_duration:.2f}sï¼Œç»“æœé•¿åº¦: {len(result)} å­—ç¬¦")
                    return result
                else:
                    logger.error("VLM APIè¿”å›ç»“æœä¸ºç©º")
                    return None
            else:
                logger.error(f"VLM APIå“åº”æ ¼å¼å¼‚å¸¸: {completion}")
                return None
                
        except Exception as e:
            logger.error(f"VLMå›¾åƒåˆ†æå¤±è´¥: {str(e)}")
            return None

    async def _perform_user_question_analysis(self, image_path: str, user_question: str) -> Optional[str]:
        """
        æ‰§è¡Œç”¨æˆ·é—®é¢˜ä¸“ç”¨çš„å›¾åƒåˆ†æ
        
        Args:
            image_path: å›¾åƒæ–‡ä»¶è·¯å¾„
            user_question: ç”¨æˆ·é—®é¢˜
            
        Returns:
            ç”¨æˆ·é—®é¢˜å›ç­”ç»“æœ
        """
        try:
            logger.info("ğŸ¤” å¼€å§‹ç”¨æˆ·é—®é¢˜åˆ†æ...")
            user_question_start_time = time.time()
            
            # ç¼–ç å›¾åƒä¸ºbase64
            base64_image = self.encode_image(image_path)
            
            # è·å–å›¾åƒæ–‡ä»¶æ‰©å±•åï¼Œç”¨äºç¡®å®šMIMEç±»å‹
            ext = Path(image_path).suffix.lower()
            mime_type = {
                '.jpg': 'image/jpeg', '.jpeg': 'image/jpeg',
                '.png': 'image/png', '.bmp': 'image/bmp',
                '.gif': 'image/gif', '.tiff': 'image/tiff',
                '.webp': 'image/webp'
            }.get(ext, 'image/jpeg')
            
            # ä½¿ç”¨ç”¨æˆ·é—®é¢˜ä¸“ç”¨çš„æç¤ºè¯
            user_prompt = self.user_question_template.format(user_question=user_question)
            
            # æ„å»ºæ¶ˆæ¯ - å›¾åƒæ ¼å¼
            messages: List[Dict[str, Any]] = [
                {
                    "role": "system",
                    "content": self.user_question_system_prompt
                },
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "image_url",
                            "image_url": {"url": f"data:{mime_type};base64,{base64_image}"},
                        },
                        {"type": "text", "text": user_prompt},
                    ],
                }
            ]
            
            # å¼‚æ­¥è°ƒç”¨API
            completion = await self.async_client.chat.completions.create(
                model=self.model,
                messages=messages  # type: ignore
            )
            
            # å¤„ç†å“åº”
            if completion.choices and len(completion.choices) > 0:
                result = completion.choices[0].message.content
                if result is not None:
                    user_question_duration = time.time() - user_question_start_time
                    logger.info(f"âœ… ç”¨æˆ·é—®é¢˜åˆ†æå®Œæˆï¼Œè€—æ—¶: {user_question_duration:.2f}sï¼Œç»“æœé•¿åº¦: {len(result)} å­—ç¬¦")
                    return result
                else:
                    logger.error("ç”¨æˆ·é—®é¢˜åˆ†æAPIè¿”å›ç»“æœä¸ºç©º")
                    return None
            else:
                logger.error(f"ç”¨æˆ·é—®é¢˜åˆ†æAPIå“åº”æ ¼å¼å¼‚å¸¸: {completion}")
                return None
                
        except Exception as e:
            logger.error(f"ç”¨æˆ·é—®é¢˜åˆ†æå¤±è´¥: {str(e)}")
            return None

    async def _perform_mcp_control(self, image_path: str, user_question: Optional[str] = None) -> Optional[Dict]:
        """
        æ‰§è¡ŒMCPæ‘„åƒå¤´æ§åˆ¶
        
        Args:
            image_path: å›¾åƒæ–‡ä»¶è·¯å¾„
            user_question: ç”¨æˆ·é—®é¢˜
            
        Returns:
            MCPè°ƒç”¨ç»“æœæ•°æ®
        """
        try:
            logger.info("ğŸ¯ å¼€å§‹MCPæ‘„åƒå¤´æ§åˆ¶...")
            
            # é€šè¿‡ HTTP è¯·æ±‚ MCP æ¨ç†æœåŠ¡
            import requests
            
            # ä»é…ç½®æ–‡ä»¶è¯»å–æ¨ç†æœåŠ¡åœ°å€
            config = load_config()
            inference_config = config.get('camera_inference_service', {})
            host = inference_config.get('host', 'localhost')
            port = inference_config.get('port', 8082)
            inference_url = f"http://localhost:{port}/analyze"
            
            logger.info(f"ğŸŒ å‘é€è¯·æ±‚åˆ° MCP æ¨ç†æœåŠ¡: {inference_url}")
            
            # è®°å½•MCPè°ƒç”¨å¼€å§‹æ—¶é—´
            mcp_start_time = time.time()
            mcp_start_timestamp = datetime.now().isoformat()
            
            # æ„å»ºè¯·æ±‚æ•°æ®
            request_data = {
                "image_path": image_path,
            }
            
            # ä½¿ç”¨asyncioåœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡ŒåŒæ­¥çš„HTTPè¯·æ±‚
            loop = asyncio.get_event_loop()
            response = await loop.run_in_executor(
                None, 
                lambda: requests.post(
                    inference_url,
                    json=request_data,
                    timeout=30
                )
            )
            
            # è®°å½•MCPè°ƒç”¨ç»“æŸæ—¶é—´
            mcp_end_time = time.time()
            mcp_end_timestamp = datetime.now().isoformat()
            mcp_duration = mcp_end_time - mcp_start_time
            
            if response.status_code == 200:
                camera_result = response.json()
                logger.info(f"âœ… MCPæ‘„åƒå¤´æ§åˆ¶å®Œæˆï¼Œè€—æ—¶: {mcp_duration:.2f}s")
                
                # æ„å»ºMCPç»“æœæ•°æ®
                mcp_result = {
                    'image_path': image_path,
                    'mcp_start_time': mcp_start_time,
                    'mcp_end_time': mcp_end_time,
                    'mcp_start_timestamp': mcp_start_timestamp,
                    'mcp_end_timestamp': mcp_end_timestamp,
                    'mcp_duration': mcp_duration,
                    'mcp_request_data': request_data,
                    'mcp_response_status': response.status_code,
                    'mcp_response_data': camera_result,
                    'mcp_success': camera_result.get('success', False)
                }
                
                # è®°å½•è¯¦ç»†çš„æ§åˆ¶ç»“æœ
                if camera_result.get('success') and camera_result.get('data'):
                    data = camera_result['data']
                    control_result = data.get('control_result')
                    
                    if control_result:
                        if isinstance(control_result, dict):
                            if control_result.get('success'):
                                logger.info(f"ğŸ® æ‘„åƒå¤´æ§åˆ¶æ‰§è¡ŒæˆåŠŸ - å·¥å…·: {control_result.get('tool_name')}, å‚æ•°: {control_result.get('arguments')}")
                                logger.info(f"ğŸ“‹ æ§åˆ¶åŸå› : {control_result.get('reason')}")
                                logger.info(f"ğŸ“ æ‰§è¡Œç»“æœ: {control_result.get('result')}")
                            else:
                                logger.warning(f"âš ï¸ æ‘„åƒå¤´æ§åˆ¶æ‰§è¡Œå¤±è´¥: {control_result.get('result')}")
                        else:
                            logger.info("ğŸ“ æ‘„åƒå¤´æ¨ç†æœåŠ¡æœªè¿”å›æ§åˆ¶ç»“æœ")
                    else:
                        logger.info("ğŸ“ æ‘„åƒå¤´æ¨ç†æœåŠ¡æœªè¿”å›æ§åˆ¶ç»“æœ")
                else:
                    logger.warning("âš ï¸ æ‘„åƒå¤´æ¨ç†æœåŠ¡è¿”å›å¤±è´¥æˆ–æ— æ•°æ®")
                
                return mcp_result
            else:
                logger.error(f"âŒ MCPæ‘„åƒå¤´æ§åˆ¶å¤±è´¥: {response.status_code} - {response.text}")
                
                # å³ä½¿å¤±è´¥ä¹Ÿè®°å½•MCPç»“æœ
                mcp_result = {
                    'image_path': image_path,
                    'mcp_start_time': mcp_start_time,
                    'mcp_end_time': mcp_end_time,
                    'mcp_start_timestamp': mcp_start_timestamp,
                    'mcp_end_timestamp': mcp_end_timestamp,
                    'mcp_duration': mcp_duration,
                    'mcp_request_data': request_data,
                    'mcp_response_status': response.status_code,
                    'mcp_response_text': response.text,
                    'mcp_success': False,
                    'mcp_error': f"HTTP {response.status_code}: {response.text}"
                }
                return mcp_result
                
        except Exception as camera_error:
            logger.error(f"âŒ MCPæ‘„åƒå¤´æ§åˆ¶å¼‚å¸¸: {camera_error}")
            
            # è®°å½•å¼‚å¸¸æƒ…å†µçš„MCPç»“æœ
            mcp_result = {
                'image_path': image_path,
                'mcp_start_time': mcp_start_time if 'mcp_start_time' in locals() else time.time(),
                'mcp_end_time': time.time(),
                'mcp_start_timestamp': mcp_start_timestamp if 'mcp_start_timestamp' in locals() else datetime.now().isoformat(),
                'mcp_end_timestamp': datetime.now().isoformat(),
                'mcp_duration': time.time() - (mcp_start_time if 'mcp_start_time' in locals() else time.time()),
                'mcp_request_data': request_data if 'request_data' in locals() else None,
                'mcp_success': False,
                'mcp_error': str(camera_error),
                'mcp_exception': True
            }
            return mcp_result

    async def _perform_and_save_user_question_analysis(self, image_path: str, user_question: str) -> None:
        """
        æ‰§è¡Œç”¨æˆ·é—®é¢˜åˆ†æå¹¶ç«‹å³ä¿å­˜ç»“æœï¼ˆç‹¬ç«‹ä»»åŠ¡ï¼‰
        
        Args:
            image_path: å›¾åƒæ–‡ä»¶è·¯å¾„
            user_question: ç”¨æˆ·é—®é¢˜
        """
        try:
            logger.info("ğŸ¤” å¼€å§‹ç‹¬ç«‹æ‰§è¡Œç”¨æˆ·é—®é¢˜åˆ†æ...")
            
            # æ‰§è¡Œç”¨æˆ·é—®é¢˜åˆ†æ
            user_answer = await self._perform_user_question_analysis(image_path, user_question)
            
            if user_answer and isinstance(user_answer, str):
                # ç«‹å³ä¿å­˜ç”¨æˆ·é—®é¢˜ç»“æœ
                self._save_user_question_result_to_details(image_path, user_question, user_answer)
                logger.info("âœ… ç”¨æˆ·é—®é¢˜åˆ†æå®Œæˆå¹¶å·²ä¿å­˜")
            else:
                logger.error("âŒ ç”¨æˆ·é—®é¢˜åˆ†æå¤±è´¥æˆ–è¿”å›ç©ºç»“æœ")
                
        except Exception as e:
            logger.error(f"âŒ ç‹¬ç«‹ç”¨æˆ·é—®é¢˜åˆ†æä»»åŠ¡å¤±è´¥: {str(e)}")

    async def _perform_and_save_mcp_control(self, image_path: str, user_question: Optional[str] = None) -> None:
        """
        æ‰§è¡ŒMCPæ‘„åƒå¤´æ§åˆ¶å¹¶ç«‹å³ä¿å­˜ç»“æœï¼ˆç‹¬ç«‹ä»»åŠ¡ï¼‰
        
        Args:
            image_path: å›¾åƒæ–‡ä»¶è·¯å¾„
            user_question: ç”¨æˆ·é—®é¢˜
        """
        try:
            logger.info("ğŸ¯ å¼€å§‹ç‹¬ç«‹æ‰§è¡ŒMCPæ‘„åƒå¤´æ§åˆ¶...")
            
            # æ‰§è¡ŒMCPæ§åˆ¶
            mcp_result = await self._perform_mcp_control(image_path, user_question)
            
            if mcp_result and isinstance(mcp_result, dict):
                # ç«‹å³ä¿å­˜MCPç»“æœ
                self._save_mcp_result_to_details(image_path, mcp_result)
                logger.info("âœ… MCPæ‘„åƒå¤´æ§åˆ¶å®Œæˆå¹¶å·²ä¿å­˜")
            else:
                logger.error("âŒ MCPæ‘„åƒå¤´æ§åˆ¶å¤±è´¥æˆ–è¿”å›ç©ºç»“æœ")
                
        except Exception as e:
            logger.error(f"âŒ ç‹¬ç«‹MCPæ§åˆ¶ä»»åŠ¡å¤±è´¥: {str(e)}")
    
    def _save_mcp_result_to_details(self, image_path: str, mcp_result: Dict):
        """
        ä¿å­˜MCPç»“æœåˆ°å¯¹åº”çš„frameè¯¦æƒ…ç›®å½•
        
        Args:
            image_path: å›¾åƒæ–‡ä»¶è·¯å¾„
            mcp_result: MCPè°ƒç”¨ç»“æœæ•°æ®
        """
        try:
            # ä»å›¾åƒè·¯å¾„æ¨æ–­frameè¯¦æƒ…ç›®å½•
            # å›¾åƒè·¯å¾„æ ¼å¼é€šå¸¸ä¸º: .../session_*/frame_*_details/frame_*.jpg
            image_path_obj = Path(image_path)
            
            # æ£€æŸ¥æ˜¯å¦åœ¨detailsç›®å½•ä¸­
            if image_path_obj.parent.name.endswith('_details'):
                details_dir = image_path_obj.parent
            else:
                # å¦‚æœä¸åœ¨detailsç›®å½•ä¸­ï¼Œå°è¯•æŸ¥æ‰¾å¯¹åº”çš„detailsç›®å½•
                # è¿™ç§æƒ…å†µå¯èƒ½å‘ç”Ÿåœ¨ä¸´æ—¶æ–‡ä»¶æˆ–å…¶ä»–æƒ…å†µä¸‹
                logger.warning(f"å›¾åƒè·¯å¾„ä¸åœ¨detailsç›®å½•ä¸­: {image_path}")
                return
            
            # åˆ›å»ºMCPç»“æœæ–‡ä»¶è·¯å¾„
            mcp_result_file = details_dir / 'mcp_result.json'
            
            # å¢å¼ºMCPç»“æœæ•°æ®ï¼Œæ·»åŠ æ›´å¤šæœ‰ç”¨ä¿¡æ¯
            enhanced_mcp_result = mcp_result.copy()
            enhanced_mcp_result.update({
                'saved_at': time.time(),
                'saved_timestamp': datetime.now().isoformat(),
                'frame_details_dir': str(details_dir),
                'image_filename': image_path_obj.name
            })
            
            # ä¿å­˜MCPç»“æœåˆ°æ–‡ä»¶
            with open(mcp_result_file, 'w', encoding='utf-8') as f:
                json_module.dump(enhanced_mcp_result, f, ensure_ascii=False, indent=2, default=str)
            
            logger.info(f"ğŸ“ MCPç»“æœå·²ä¿å­˜åˆ°: {mcp_result_file}")
            
            # å¦‚æœMCPç»“æœåŒ…å«å¯¹è¯å†å²ä¿¡æ¯ï¼Œè®°å½•åˆ°æ—¥å¿—
            if 'mcp_response_data' in enhanced_mcp_result:
                response_data = enhanced_mcp_result['mcp_response_data']
                if isinstance(response_data, dict) and 'conversation_summary' in response_data:
                    conv_summary = response_data['conversation_summary']
                    logger.info(f"ğŸ“‹ å¯¹è¯å†å²çŠ¶æ€: {conv_summary.get('conversation_rounds', 0)} è½®å¯¹è¯ï¼Œ{conv_summary.get('total_messages', 0)} æ¡æ¶ˆæ¯")
            
        except Exception as e:
            logger.error(f"ä¿å­˜MCPç»“æœå¤±è´¥: {str(e)}")
    
    def _save_user_question_result_to_details(self, image_path: str, user_question: str, user_answer: str):
        """
        ä¿å­˜ç”¨æˆ·é—®é¢˜ç»“æœåˆ°å¯¹åº”çš„frameè¯¦æƒ…ç›®å½•
        
        Args:
            image_path: å›¾åƒæ–‡ä»¶è·¯å¾„
            user_question: ç”¨æˆ·é—®é¢˜
            user_answer: ç”¨æˆ·é—®é¢˜å›ç­”
        """
        try:
            # ä»å›¾åƒè·¯å¾„æ¨æ–­frameè¯¦æƒ…ç›®å½•
            # å›¾åƒè·¯å¾„æ ¼å¼é€šå¸¸ä¸º: .../session_*/frame_*_details/frame_*.jpg
            image_path_obj = Path(image_path)
            
            # æ£€æŸ¥æ˜¯å¦åœ¨detailsç›®å½•ä¸­
            if image_path_obj.parent.name.endswith('_details'):
                details_dir = image_path_obj.parent
            else:
                # å¦‚æœä¸åœ¨detailsç›®å½•ä¸­ï¼Œå°è¯•æŸ¥æ‰¾å¯¹åº”çš„detailsç›®å½•
                logger.warning(f"å›¾åƒè·¯å¾„ä¸åœ¨detailsç›®å½•ä¸­: {image_path}")
                return
            
            # åˆ›å»ºç”¨æˆ·é—®é¢˜ç»“æœæ–‡ä»¶è·¯å¾„
            user_question_result_file = details_dir / 'user_question.json'
            
            # æ„å»ºç”¨æˆ·é—®é¢˜ç»“æœæ•°æ®
            user_question_data = {
                'image_path': image_path,
                'user_question': user_question,
                'response': user_answer,
                'timestamp': time.time(),
                'timestamp_iso': datetime.now().isoformat(),
                'analysis_type': 'user_question'
            }
            
            # ä¿å­˜ç”¨æˆ·é—®é¢˜ç»“æœåˆ°æ–‡ä»¶
            with open(user_question_result_file, 'w', encoding='utf-8') as f:
                json_module.dump(user_question_data, f, ensure_ascii=False, indent=2, default=str)
            
            logger.info(f"ç”¨æˆ·é—®é¢˜ç»“æœå·²ä¿å­˜åˆ°: {user_question_result_file}")
            
        except Exception as e:
            logger.error(f"ä¿å­˜ç”¨æˆ·é—®é¢˜ç»“æœå¤±è´¥: {str(e)}")
    
    async def analyze_media_async(self, media_path: str, prompt: Optional[str] = None, fps: int = 2) -> Optional[str]:
        """
        è‡ªåŠ¨è¯†åˆ«å¹¶å¼‚æ­¥åˆ†æåª’ä½“æ–‡ä»¶ï¼ˆè§†é¢‘æˆ–å›¾åƒï¼‰
        
        Args:
            media_path: åª’ä½“æ–‡ä»¶è·¯å¾„
            prompt: åˆ†ææç¤ºè¯ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„é»˜è®¤æç¤ºè¯
            fps: è§†é¢‘å¸§ç‡ï¼ˆä»…å¯¹è§†é¢‘æœ‰æ•ˆï¼‰
            
        Returns:
            åˆ†æç»“æœæ–‡æœ¬ï¼Œå¦‚æœå¤±è´¥è¿”å›None
        """
        if self._is_video_file(media_path):
            logger.info(f"æ£€æµ‹åˆ°è§†é¢‘æ–‡ä»¶: {media_path}")
            return await self.analyze_video_async(media_path, prompt, fps)
        elif self._is_image_file(media_path):
            logger.info(f"æ£€æµ‹åˆ°å›¾åƒæ–‡ä»¶: {media_path}")
            return await self.analyze_image_async(media_path, prompt)
        else:
            logger.error(f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {media_path}")
            return None 

def smart_resize(
    height: int, width: int, factor: int = 28, min_pixels: int = 56 * 56, max_pixels: int = 14 * 14 * 4 * 1280
) -> Tuple[int, int]:
    """
    æ¨¡å‹æœåŠ¡çš„å›¾åƒresizeé€»è¾‘
    
    Rescales the image so that the following conditions are met:
    1. Both dimensions (height and width) are divisible by 'factor'.
    2. The total number of pixels is within the range ['min_pixels', 'max_pixels'].
    3. The aspect ratio of the image is maintained as closely as possible.
    
    Returns:
        Tuple[int, int]: (resized_height, resized_width)
    """
    if height < factor or width < factor:
        raise ValueError(f"height:{height} or width:{width} must be larger than factor:{factor}")
    elif max(height, width) / min(height, width) > 200:
        raise ValueError(
            f"absolute aspect ratio must be smaller than 200, got {max(height, width) / min(height, width)}"
        )
    h_bar = round(height / factor) * factor
    w_bar = round(width / factor) * factor
    if h_bar * w_bar > max_pixels:
        beta = math.sqrt((height * width) / max_pixels)
        h_bar = math.floor(height / beta / factor) * factor
        w_bar = math.floor(width / beta / factor) * factor
    elif h_bar * w_bar < min_pixels:
        beta = math.sqrt(min_pixels / (height * width))
        h_bar = math.ceil(height * beta / factor) * factor
        w_bar = math.ceil(width * beta / factor) * factor
    return h_bar, w_bar

def get_image_dimensions(image_path: str) -> Tuple[int, int]:
    """
    è·å–å›¾åƒçš„åŸå§‹å°ºå¯¸
    
    Returns:
        Tuple[int, int]: (width, height)
    """
    try:
        with Image.open(image_path) as img:
            return img.size  # PILè¿”å›(width, height)
    except Exception as e:
        logger.error(f"è·å–å›¾åƒå°ºå¯¸å¤±è´¥: {e}")
        return (0, 0) 