#!/usr/bin/env python3
"""
VLMå®¢æˆ·ç«¯æ¨¡å—
æä¾›è§†é¢‘å’Œå›¾åƒåˆ†æåŠŸèƒ½ï¼Œæ”¯æŒåŒæ­¥å’Œå¼‚æ­¥è°ƒç”¨
"""

import os
import base64
import asyncio
import logging
import math
import time
from datetime import datetime
from typing import Optional, Dict, List, Any, Tuple
from openai import AsyncOpenAI
from pathlib import Path
from PIL import Image
import requests
import json as json_module

# å¯¼å…¥é…ç½®ç®¡ç†æ¨¡å—
from ..core.config import load_config

logger = logging.getLogger(__name__)

class DashScopeVLMClient:
    def __init__(self, api_key: Optional[str] = None, model: Optional[str] = None, 
                 base_url: Optional[str] = None):
        """
        åˆå§‹åŒ–DashScope VLMå®¢æˆ·ç«¯ï¼ˆä½¿ç”¨OpenAI SDKï¼‰
        
        Args:
            api_key: APIå¯†é’¥ï¼Œå¦‚æœä¸ºNoneåˆ™ä»é…ç½®æ–‡ä»¶è¯»å–
            model: ä½¿ç”¨çš„æ¨¡å‹åç§°ï¼Œå¦‚æœä¸ºNoneåˆ™ä»é…ç½®æ–‡ä»¶è¯»å–
            base_url: APIåŸºç¡€URLï¼Œå¦‚æœä¸ºNoneåˆ™ä»é…ç½®æ–‡ä»¶è¯»å–
        """
        # åŠ è½½é…ç½®
        config = load_config()
        vlm_config = config.get('vlm', {})
        
        # è·å–APIå¯†é’¥
        self.api_key = api_key or vlm_config.get('api_key')
        if not self.api_key:
            # å°è¯•ä»ç¯å¢ƒå˜é‡è·å–
            self.api_key = os.environ.get('DASHSCOPE_API_KEY')
        
        if not self.api_key:
            raise ValueError("APIå¯†é’¥æœªè®¾ç½®ï¼Œè¯·åœ¨é…ç½®æ–‡ä»¶ä¸­è®¾ç½®ã€è®¾ç½®DASHSCOPE_API_KEYç¯å¢ƒå˜é‡æˆ–ä¼ å…¥api_keyå‚æ•°")
        
        # è·å–å…¶ä»–é…ç½®
        self.model = model or vlm_config.get('model', 'qwen-vl-max-latest')
        self.base_url = base_url or vlm_config.get('base_url', 'https://dashscope.aliyuncs.com/compatible-mode/v1')
        self.max_video_size_mb = vlm_config.get('max_video_size_mb', 100)
        self.max_base64_size_mb = vlm_config.get('max_base64_size_mb', 10)
        
        # è·å–é»˜è®¤æç¤ºè¯
        self.default_prompt = vlm_config.get('default_prompt', {})
        self.system_prompt = self.default_prompt.get('system', 
            "You are a helpful assistant that analyzes videos and returns structured JSON responses.")
        self.user_prompt_template = self.default_prompt.get('user_template', 
            "è¯·åˆ†æè¿™æ®µè§†é¢‘å†…å®¹")
        
        # åˆ›å»ºå¼‚æ­¥OpenAIå®¢æˆ·ç«¯
        self.async_client = AsyncOpenAI(
            api_key=self.api_key,
            base_url=self.base_url,
        )
        
        # æ”¯æŒçš„æ–‡ä»¶æ ¼å¼
        self.video_extensions = {'.mp4', '.avi', '.mov', '.mkv', '.wmv', '.flv', '.webm'}
        self.image_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.gif', '.tiff', '.webp'}
        
        logger.info(f"âœ… VLMå®¢æˆ·ç«¯åˆå§‹åŒ–å®Œæˆ:")
        logger.info(f"  - æ¨¡å‹: {self.model}")
        logger.info(f"  - åŸºç¡€URL: {self.base_url}")
        logger.info(f"  - æœ€å¤§è§†é¢‘å¤§å°: {self.max_video_size_mb}MB")
        logger.info(f"  - æœ€å¤§Base64å¤§å°: {self.max_base64_size_mb}MB")
        
    def _is_video_file(self, file_path: str) -> bool:
        """åˆ¤æ–­æ–‡ä»¶æ˜¯å¦ä¸ºè§†é¢‘æ–‡ä»¶"""
        return Path(file_path).suffix.lower() in self.video_extensions
    
    def _is_image_file(self, file_path: str) -> bool:
        """åˆ¤æ–­æ–‡ä»¶æ˜¯å¦ä¸ºå›¾åƒæ–‡ä»¶"""
        return Path(file_path).suffix.lower() in self.image_extensions
        
    def encode_video(self, video_path: str) -> str:
        """å°†è§†é¢‘æ–‡ä»¶ç¼–ç ä¸ºbase64æ ¼å¼"""
        try:
            # æ£€æŸ¥åŸå§‹æ–‡ä»¶å¤§å°
            file_size_mb = os.path.getsize(video_path) / (1024 * 1024)
            logger.info(f"åŸå§‹è§†é¢‘æ–‡ä»¶å¤§å°: {file_size_mb:.2f}MB")
            
            if file_size_mb > self.max_video_size_mb:
                raise ValueError(f"è§†é¢‘æ–‡ä»¶è¿‡å¤§: {file_size_mb:.2f}MB > {self.max_video_size_mb}MBé™åˆ¶")
            
            with open(video_path, "rb") as video_file:
                video_data = video_file.read()
                base64_data = base64.b64encode(video_data).decode("utf-8")
                
                # æ£€æŸ¥Base64ç¼–ç åçš„å¤§å°
                base64_size_mb = len(base64_data.encode('utf-8')) / (1024 * 1024)
                logger.info(f"Base64ç¼–ç åå¤§å°: {base64_size_mb:.2f}MB")
                
                # æ ¡éªŒBase64å¤§å°é™åˆ¶
                if base64_size_mb > self.max_base64_size_mb:
                    raise ValueError(f"Base64ç¼–ç åçš„è§†é¢‘è¿‡å¤§: {base64_size_mb:.2f}MB > {self.max_base64_size_mb}MBé™åˆ¶")
                
                return base64_data
        except Exception as e:
            logger.error(f"è§†é¢‘ç¼–ç å¤±è´¥: {str(e)}")
            raise
    
    def encode_image(self, image_path: str) -> str:
        """å°†å›¾åƒæ–‡ä»¶ç¼–ç ä¸ºbase64æ ¼å¼"""
        try:
            # æ£€æŸ¥åŸå§‹æ–‡ä»¶å¤§å°
            file_size_mb = os.path.getsize(image_path) / (1024 * 1024)
            logger.info(f"åŸå§‹å›¾åƒæ–‡ä»¶å¤§å°: {file_size_mb:.2f}MB")
            
            if file_size_mb > self.max_base64_size_mb:
                raise ValueError(f"å›¾åƒæ–‡ä»¶è¿‡å¤§: {file_size_mb:.2f}MB > {self.max_base64_size_mb}MBé™åˆ¶")
            
            with open(image_path, "rb") as image_file:
                image_data = image_file.read()
                base64_data = base64.b64encode(image_data).decode("utf-8")
                
                # æ£€æŸ¥Base64ç¼–ç åçš„å¤§å°
                base64_size_mb = len(base64_data.encode('utf-8')) / (1024 * 1024)
                logger.info(f"Base64ç¼–ç åå¤§å°: {base64_size_mb:.2f}MB")
                
                return base64_data
        except Exception as e:
            logger.error(f"å›¾åƒç¼–ç å¤±è´¥: {str(e)}")
            raise
        
    def analyze_video(self, video_path: str, prompt: Optional[str] = None, fps: int = 2) -> Optional[str]:
        """
        åŒæ­¥åˆ†æè§†é¢‘å†…å®¹ï¼ˆå…¼å®¹æ€§æ–¹æ³•ï¼‰
        
        Args:
            video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
            prompt: åˆ†ææç¤ºè¯ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„é»˜è®¤æç¤ºè¯
            fps: è§†é¢‘å¸§ç‡ï¼ˆç”¨äºæ§åˆ¶åˆ†æçš„å¸§æ•°ï¼‰
            
        Returns:
            åˆ†æç»“æœæ–‡æœ¬ï¼Œå¦‚æœå¤±è´¥è¿”å›None
        """
        try:
            # ä½¿ç”¨asyncioè¿è¡Œå¼‚æ­¥æ–¹æ³•
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            try:
                result = loop.run_until_complete(self.analyze_video_async(video_path, prompt, fps))
                return result
            finally:
                loop.close()
        except Exception as e:
            logger.error(f"åŒæ­¥è§†é¢‘åˆ†æå¤±è´¥: {str(e)}")
            return None
    
    def analyze_image(self, image_path: str, prompt: Optional[str] = None, 
                     user_question: Optional[str] = None, 
                     enable_camera_control: bool = True) -> Optional[str]:
        """
        åŒæ­¥åˆ†æå›¾åƒå†…å®¹
        
        Args:
            image_path: å›¾åƒæ–‡ä»¶è·¯å¾„
            prompt: åˆ†ææç¤ºè¯ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„é»˜è®¤æç¤ºè¯
            user_question: ç”¨æˆ·é—®é¢˜ï¼Œå¦‚æœæœ‰åˆ™ä¼šæ·»åŠ åˆ°æç¤ºè¯ä¸­
            enable_camera_control: æ˜¯å¦å¯ç”¨æ‘„åƒå¤´æ§åˆ¶åŠŸèƒ½ï¼ˆå“¨å…µæ¨¡å¼ï¼‰
            
        Returns:
            åˆ†æç»“æœæ–‡æœ¬ï¼Œå¦‚æœå¤±è´¥è¿”å›None
        """
        try:
            # ä½¿ç”¨asyncioè¿è¡Œå¼‚æ­¥æ–¹æ³•
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            try:
                result = loop.run_until_complete(
                    self.analyze_image_async(image_path, prompt, user_question, enable_camera_control)
                )
                return result
            finally:
                loop.close()
        except Exception as e:
            logger.error(f"åŒæ­¥å›¾åƒåˆ†æå¤±è´¥: {str(e)}")
            return None
    
    def analyze_media(self, media_path: str, prompt: Optional[str] = None, fps: int = 2, 
                     user_question: Optional[str] = None, 
                     enable_camera_control: bool = True) -> Optional[str]:
        """
        è‡ªåŠ¨è¯†åˆ«å¹¶åˆ†æåª’ä½“æ–‡ä»¶ï¼ˆè§†é¢‘æˆ–å›¾åƒï¼‰
        
        Args:
            media_path: åª’ä½“æ–‡ä»¶è·¯å¾„
            prompt: åˆ†ææç¤ºè¯ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„é»˜è®¤æç¤ºè¯
            fps: è§†é¢‘å¸§ç‡ï¼ˆä»…å¯¹è§†é¢‘æœ‰æ•ˆï¼‰
            user_question: ç”¨æˆ·é—®é¢˜ï¼Œå¦‚æœæœ‰åˆ™ä¼šæ·»åŠ åˆ°æç¤ºè¯ä¸­
            enable_camera_control: æ˜¯å¦å¯ç”¨æ‘„åƒå¤´æ§åˆ¶åŠŸèƒ½ï¼ˆå“¨å…µæ¨¡å¼ï¼‰
            
        Returns:
            åˆ†æç»“æœæ–‡æœ¬ï¼Œå¦‚æœå¤±è´¥è¿”å›None
        """
        if self._is_video_file(media_path):
            logger.info(f"æ£€æµ‹åˆ°è§†é¢‘æ–‡ä»¶: {media_path}")
            return self.analyze_video(media_path, prompt, fps)
        elif self._is_image_file(media_path):
            logger.info(f"æ£€æµ‹åˆ°å›¾åƒæ–‡ä»¶: {media_path}")
            return self.analyze_image(media_path, prompt, user_question, enable_camera_control)
        else:
            logger.error(f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {media_path}")
            return None
    
    async def analyze_video_async(self, video_path: str, prompt: Optional[str] = None, fps: int = 2) -> Optional[str]:
        """
        å¼‚æ­¥åˆ†æè§†é¢‘å†…å®¹
        
        Args:
            video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
            prompt: åˆ†ææç¤ºè¯ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„é»˜è®¤æç¤ºè¯
            fps: è§†é¢‘å¸§ç‡ï¼ˆç”¨äºæ§åˆ¶åˆ†æçš„å¸§æ•°ï¼‰
            
        Returns:
            åˆ†æç»“æœæ–‡æœ¬ï¼Œå¦‚æœå¤±è´¥è¿”å›None
        """
        try:
            # æ£€æŸ¥æ–‡ä»¶å¤§å°
            file_size_mb = os.path.getsize(video_path) / (1024 * 1024)
            if file_size_mb > self.max_video_size_mb:
                logger.error(f"è§†é¢‘æ–‡ä»¶è¿‡å¤§: {file_size_mb:.2f}MBï¼Œè¶…è¿‡{self.max_video_size_mb}MBé™åˆ¶")
                return None
                
            logger.info(f"å¼€å§‹å¼‚æ­¥åˆ†æè§†é¢‘: {video_path} ({file_size_mb:.2f}MB)")
            
            # ç¼–ç è§†é¢‘ä¸ºbase64
            base64_video = self.encode_video(video_path)
            
            # ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„é»˜è®¤æç¤ºè¯
            if prompt is None:
                prompt = self.user_prompt_template
            
            # æ„å»ºæ¶ˆæ¯ - è§†é¢‘æ ¼å¼
            messages: List[Dict[str, Any]] = [
                {
                    "role": "system",
                    "content": self.system_prompt
                },
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "video_url",
                            "video_url": {"url": f"data:video/mp4;base64,{base64_video}"},
                        },
                        {"type": "text", "text": prompt},
                    ],
                }
            ]
            
            # å¼‚æ­¥è°ƒç”¨API
            completion = await self.async_client.chat.completions.create(
                model=self.model,
                messages=messages  # type: ignore
            )
            
            # å¤„ç†å“åº”
            if completion.choices and len(completion.choices) > 0:
                result = completion.choices[0].message.content
                if result is not None:
                    logger.info(f"å¼‚æ­¥è§†é¢‘åˆ†æå®Œæˆï¼Œç»“æœé•¿åº¦: {len(result)} å­—ç¬¦")
                    return result
                else:
                    logger.error("APIè¿”å›ç»“æœä¸ºç©º")
                    return None
            else:
                logger.error(f"APIå“åº”æ ¼å¼å¼‚å¸¸: {completion}")
                return None
                
        except Exception as e:
            logger.error(f"å¼‚æ­¥è§†é¢‘åˆ†æå¤±è´¥: {str(e)}")
            return None
    
    async def analyze_image_async(self, image_path: str, prompt: Optional[str] = None, 
                                 user_question: Optional[str] = None, 
                                 enable_camera_control: bool = True) -> Optional[str]:
        """
        å¼‚æ­¥åˆ†æå›¾åƒå†…å®¹
        
        Args:
            image_path: å›¾åƒæ–‡ä»¶è·¯å¾„
            prompt: åˆ†ææç¤ºè¯ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„é»˜è®¤æç¤ºè¯
            user_question: ç”¨æˆ·é—®é¢˜ï¼Œå¦‚æœæœ‰åˆ™ä¼šæ·»åŠ åˆ°æç¤ºè¯ä¸­
            enable_camera_control: æ˜¯å¦å¯ç”¨æ‘„åƒå¤´æ§åˆ¶åŠŸèƒ½
            
        Returns:
            åˆ†æç»“æœæ–‡æœ¬ï¼Œå¦‚æœå¤±è´¥è¿”å›None
        """
        try:
            # æ£€æŸ¥æ–‡ä»¶å¤§å°
            file_size_mb = os.path.getsize(image_path) / (1024 * 1024)
            if file_size_mb > self.max_base64_size_mb:
                logger.error(f"å›¾åƒæ–‡ä»¶è¿‡å¤§: {file_size_mb:.2f}MBï¼Œè¶…è¿‡{self.max_base64_size_mb}MBé™åˆ¶")
                return None
                
            logger.info(f"å¼€å§‹å¼‚æ­¥åˆ†æå›¾åƒ: {image_path} ({file_size_mb:.2f}MB)")

            if user_question:
                logger.info(f"ç”¨æˆ·é—®é¢˜: {user_question}")
            if enable_camera_control:
                logger.info("å¯ç”¨æ‘„åƒå¤´æ§åˆ¶åŠŸèƒ½")
            
            # åˆ›å»ºå¹¶è¡Œä»»åŠ¡åˆ—è¡¨
            tasks = []
            
            # ä»»åŠ¡1: VLMå›¾åƒåˆ†æï¼ˆæ€»æ˜¯æ‰§è¡Œï¼‰
            vlm_task = asyncio.create_task(self._perform_vlm_analysis(image_path, prompt, user_question))
            tasks.append(vlm_task)
            
            # ä»»åŠ¡2: MCPæ‘„åƒå¤´æ§åˆ¶ï¼ˆå¦‚æœå¯ç”¨ä¸”æ²¡æœ‰ç”¨æˆ·é—®é¢˜ï¼‰
            mcp_task = None
            if enable_camera_control and not user_question:
                mcp_task = asyncio.create_task(self._perform_mcp_control(image_path, user_question))
                tasks.append(mcp_task)
            
            # å¹¶è¡Œæ‰§è¡Œæ‰€æœ‰ä»»åŠ¡
            logger.info(f"ğŸš€ å¼€å§‹å¹¶è¡Œæ‰§è¡Œ {len(tasks)} ä¸ªä»»åŠ¡...")
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            # å¤„ç†VLMåˆ†æç»“æœ
            vlm_result = results[0]
            if isinstance(vlm_result, Exception):
                logger.error(f"VLMåˆ†æå¤±è´¥: {vlm_result}")
                vlm_result = None
            
            # å¤„ç†MCPæ§åˆ¶ç»“æœ
            mcp_result = None
            if mcp_task is not None and len(results) > 1:
                mcp_result = results[1]
                if isinstance(mcp_result, Exception):
                    logger.error(f"MCPæ§åˆ¶å¤±è´¥: {mcp_result}")
                    mcp_result = None
            
            # ä¿å­˜MCPç»“æœåˆ°å¯¹åº”çš„frameè¯¦æƒ…ç›®å½•
            if mcp_result:
                self._save_mcp_result_to_details(image_path, mcp_result)
            
            logger.info(f"âœ… å¹¶è¡Œä»»åŠ¡æ‰§è¡Œå®Œæˆï¼ŒVLMç»“æœé•¿åº¦: {len(vlm_result) if vlm_result else 0} å­—ç¬¦")
            return vlm_result
                
        except Exception as e:
            logger.error(f"å¼‚æ­¥å›¾åƒåˆ†æå¤±è´¥: {str(e)}")
            return None

    async def _perform_vlm_analysis(self, image_path: str, prompt: Optional[str] = None, 
                                   user_question: Optional[str] = None) -> Optional[str]:
        """
        æ‰§è¡ŒVLMå›¾åƒåˆ†æ
        
        Args:
            image_path: å›¾åƒæ–‡ä»¶è·¯å¾„
            prompt: åˆ†ææç¤ºè¯
            user_question: ç”¨æˆ·é—®é¢˜
            
        Returns:
            åˆ†æç»“æœæ–‡æœ¬
        """
        try:
            logger.info("ğŸ” å¼€å§‹VLMå›¾åƒåˆ†æ...")
            vlm_start_time = time.time()
            
            # ç¼–ç å›¾åƒä¸ºbase64
            base64_image = self.encode_image(image_path)
            
            # è·å–å›¾åƒæ–‡ä»¶æ‰©å±•åï¼Œç”¨äºç¡®å®šMIMEç±»å‹
            ext = Path(image_path).suffix.lower()
            mime_type = {
                '.jpg': 'image/jpeg', '.jpeg': 'image/jpeg',
                '.png': 'image/png', '.bmp': 'image/bmp',
                '.gif': 'image/gif', '.tiff': 'image/tiff',
                '.webp': 'image/webp'
            }.get(ext, 'image/jpeg')
            
            # ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„é»˜è®¤æç¤ºè¯
            if prompt is None:
                prompt = self.user_prompt_template
            
            # å¦‚æœæœ‰ç”¨æˆ·é—®é¢˜ï¼Œæ·»åŠ åˆ°æç¤ºè¯ä¸­
            if user_question:
                prompt = f"{prompt}\n\nç”¨æˆ·é—®é¢˜: {user_question}"
            
            # æ„å»ºæ¶ˆæ¯ - å›¾åƒæ ¼å¼
            messages: List[Dict[str, Any]] = [
                {
                    "role": "system",
                    "content": self.system_prompt
                },
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "image_url",
                            "image_url": {"url": f"data:{mime_type};base64,{base64_image}"},
                        },
                        {"type": "text", "text": prompt},
                    ],
                }
            ]
            
            # å¼‚æ­¥è°ƒç”¨API
            completion = await self.async_client.chat.completions.create(
                model=self.model,
                messages=messages  # type: ignore
            )
            
            # å¤„ç†å“åº”
            if completion.choices and len(completion.choices) > 0:
                result = completion.choices[0].message.content
                if result is not None:
                    vlm_duration = time.time() - vlm_start_time
                    logger.info(f"âœ… VLMå›¾åƒåˆ†æå®Œæˆï¼Œè€—æ—¶: {vlm_duration:.2f}sï¼Œç»“æœé•¿åº¦: {len(result)} å­—ç¬¦")
                    return result
                else:
                    logger.error("VLM APIè¿”å›ç»“æœä¸ºç©º")
                    return None
            else:
                logger.error(f"VLM APIå“åº”æ ¼å¼å¼‚å¸¸: {completion}")
                return None
                
        except Exception as e:
            logger.error(f"VLMå›¾åƒåˆ†æå¤±è´¥: {str(e)}")
            return None

    async def _perform_mcp_control(self, image_path: str, user_question: Optional[str] = None) -> Optional[Dict]:
        """
        æ‰§è¡ŒMCPæ‘„åƒå¤´æ§åˆ¶
        
        Args:
            image_path: å›¾åƒæ–‡ä»¶è·¯å¾„
            user_question: ç”¨æˆ·é—®é¢˜
            
        Returns:
            MCPè°ƒç”¨ç»“æœæ•°æ®
        """
        try:
            logger.info("ğŸ¯ å¼€å§‹MCPæ‘„åƒå¤´æ§åˆ¶...")
            
            # é€šè¿‡ HTTP è¯·æ±‚ MCP æ¨ç†æœåŠ¡
            import requests
            
            # ä»é…ç½®æ–‡ä»¶è¯»å–æ¨ç†æœåŠ¡åœ°å€
            config = load_config()
            inference_config = config.get('camera_inference_service', {})
            host = inference_config.get('host', 'localhost')
            port = inference_config.get('port', 8082)
            inference_url = f"http://localhost:{port}/analyze"
            
            logger.info(f"ğŸŒ å‘é€è¯·æ±‚åˆ° MCP æ¨ç†æœåŠ¡: {inference_url}")
            
            # è®°å½•MCPè°ƒç”¨å¼€å§‹æ—¶é—´
            mcp_start_time = time.time()
            mcp_start_timestamp = datetime.now().isoformat()
            
            # æ„å»ºè¯·æ±‚æ•°æ®
            request_data = {
                "image_path": image_path,
            }
            
            # ä½¿ç”¨asyncioåœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡ŒåŒæ­¥çš„HTTPè¯·æ±‚
            loop = asyncio.get_event_loop()
            response = await loop.run_in_executor(
                None, 
                lambda: requests.post(
                    inference_url,
                    json=request_data,
                    timeout=30
                )
            )
            
            # è®°å½•MCPè°ƒç”¨ç»“æŸæ—¶é—´
            mcp_end_time = time.time()
            mcp_end_timestamp = datetime.now().isoformat()
            mcp_duration = mcp_end_time - mcp_start_time
            
            if response.status_code == 200:
                camera_result = response.json()
                logger.info(f"âœ… MCPæ‘„åƒå¤´æ§åˆ¶å®Œæˆï¼Œè€—æ—¶: {mcp_duration:.2f}s")
                
                # æ„å»ºMCPç»“æœæ•°æ®
                mcp_result = {
                    'image_path': image_path,
                    'mcp_start_time': mcp_start_time,
                    'mcp_end_time': mcp_end_time,
                    'mcp_start_timestamp': mcp_start_timestamp,
                    'mcp_end_timestamp': mcp_end_timestamp,
                    'mcp_duration': mcp_duration,
                    'mcp_request_data': request_data,
                    'mcp_response_status': response.status_code,
                    'mcp_response_data': camera_result,
                    'mcp_success': camera_result.get('success', False)
                }
                
                # è®°å½•è¯¦ç»†çš„æ§åˆ¶ç»“æœ
                if camera_result.get('success') and camera_result.get('data'):
                    data = camera_result['data']
                    control_result = data.get('control_result')
                    
                    if control_result:
                        if isinstance(control_result, dict):
                            if control_result.get('success'):
                                logger.info(f"ğŸ® æ‘„åƒå¤´æ§åˆ¶æ‰§è¡ŒæˆåŠŸ - å·¥å…·: {control_result.get('tool_name')}, å‚æ•°: {control_result.get('arguments')}")
                                logger.info(f"ğŸ“‹ æ§åˆ¶åŸå› : {control_result.get('reason')}")
                                logger.info(f"ğŸ“ æ‰§è¡Œç»“æœ: {control_result.get('result')}")
                            else:
                                logger.warning(f"âš ï¸ æ‘„åƒå¤´æ§åˆ¶æ‰§è¡Œå¤±è´¥: {control_result.get('result')}")
                        else:
                            logger.info("ğŸ“ æ‘„åƒå¤´æ¨ç†æœåŠ¡æœªè¿”å›æ§åˆ¶ç»“æœ")
                    else:
                        logger.info("ğŸ“ æ‘„åƒå¤´æ¨ç†æœåŠ¡æœªè¿”å›æ§åˆ¶ç»“æœ")
                else:
                    logger.warning("âš ï¸ æ‘„åƒå¤´æ¨ç†æœåŠ¡è¿”å›å¤±è´¥æˆ–æ— æ•°æ®")
                
                return mcp_result
            else:
                logger.error(f"âŒ MCPæ‘„åƒå¤´æ§åˆ¶å¤±è´¥: {response.status_code} - {response.text}")
                
                # å³ä½¿å¤±è´¥ä¹Ÿè®°å½•MCPç»“æœ
                mcp_result = {
                    'image_path': image_path,
                    'mcp_start_time': mcp_start_time,
                    'mcp_end_time': mcp_end_time,
                    'mcp_start_timestamp': mcp_start_timestamp,
                    'mcp_end_timestamp': mcp_end_timestamp,
                    'mcp_duration': mcp_duration,
                    'mcp_request_data': request_data,
                    'mcp_response_status': response.status_code,
                    'mcp_response_text': response.text,
                    'mcp_success': False,
                    'mcp_error': f"HTTP {response.status_code}: {response.text}"
                }
                return mcp_result
                
        except Exception as camera_error:
            logger.error(f"âŒ MCPæ‘„åƒå¤´æ§åˆ¶å¼‚å¸¸: {camera_error}")
            
            # è®°å½•å¼‚å¸¸æƒ…å†µçš„MCPç»“æœ
            mcp_result = {
                'image_path': image_path,
                'mcp_start_time': mcp_start_time if 'mcp_start_time' in locals() else time.time(),
                'mcp_end_time': time.time(),
                'mcp_start_timestamp': mcp_start_timestamp if 'mcp_start_timestamp' in locals() else datetime.now().isoformat(),
                'mcp_end_timestamp': datetime.now().isoformat(),
                'mcp_duration': time.time() - (mcp_start_time if 'mcp_start_time' in locals() else time.time()),
                'mcp_request_data': request_data if 'request_data' in locals() else None,
                'mcp_success': False,
                'mcp_error': str(camera_error),
                'mcp_exception': True
            }
            return mcp_result
    
    def _save_mcp_result_to_details(self, image_path: str, mcp_result: Dict):
        """
        ä¿å­˜MCPç»“æœåˆ°å¯¹åº”çš„frameè¯¦æƒ…ç›®å½•
        
        Args:
            image_path: å›¾åƒæ–‡ä»¶è·¯å¾„
            mcp_result: MCPè°ƒç”¨ç»“æœæ•°æ®
        """
        try:
            # ä»å›¾åƒè·¯å¾„æ¨æ–­frameè¯¦æƒ…ç›®å½•
            # å›¾åƒè·¯å¾„æ ¼å¼é€šå¸¸ä¸º: .../session_*/frame_*_details/frame_*.jpg
            image_path_obj = Path(image_path)
            
            # æ£€æŸ¥æ˜¯å¦åœ¨detailsç›®å½•ä¸­
            if image_path_obj.parent.name.endswith('_details'):
                details_dir = image_path_obj.parent
            else:
                # å¦‚æœä¸åœ¨detailsç›®å½•ä¸­ï¼Œå°è¯•æŸ¥æ‰¾å¯¹åº”çš„detailsç›®å½•
                # è¿™ç§æƒ…å†µå¯èƒ½å‘ç”Ÿåœ¨ä¸´æ—¶æ–‡ä»¶æˆ–å…¶ä»–æƒ…å†µä¸‹
                logger.warning(f"å›¾åƒè·¯å¾„ä¸åœ¨detailsç›®å½•ä¸­: {image_path}")
                return
            
            # åˆ›å»ºMCPç»“æœæ–‡ä»¶è·¯å¾„
            mcp_result_file = details_dir / 'mcp_result.json'
            
            # å¢å¼ºMCPç»“æœæ•°æ®ï¼Œæ·»åŠ æ›´å¤šæœ‰ç”¨ä¿¡æ¯
            enhanced_mcp_result = mcp_result.copy()
            enhanced_mcp_result.update({
                'saved_at': time.time(),
                'saved_timestamp': datetime.now().isoformat(),
                'frame_details_dir': str(details_dir),
                'image_filename': image_path_obj.name
            })
            
            # ä¿å­˜MCPç»“æœåˆ°æ–‡ä»¶
            with open(mcp_result_file, 'w', encoding='utf-8') as f:
                json_module.dump(enhanced_mcp_result, f, ensure_ascii=False, indent=2, default=str)
            
            logger.info(f"ğŸ“ MCPç»“æœå·²ä¿å­˜åˆ°: {mcp_result_file}")
            
            # å¦‚æœMCPç»“æœåŒ…å«å¯¹è¯å†å²ä¿¡æ¯ï¼Œè®°å½•åˆ°æ—¥å¿—
            if 'mcp_response_data' in enhanced_mcp_result:
                response_data = enhanced_mcp_result['mcp_response_data']
                if isinstance(response_data, dict) and 'conversation_summary' in response_data:
                    conv_summary = response_data['conversation_summary']
                    logger.info(f"ğŸ“‹ å¯¹è¯å†å²çŠ¶æ€: {conv_summary.get('conversation_rounds', 0)} è½®å¯¹è¯ï¼Œ{conv_summary.get('total_messages', 0)} æ¡æ¶ˆæ¯")
            
        except Exception as e:
            logger.error(f"ä¿å­˜MCPç»“æœå¤±è´¥: {str(e)}")
    
    async def analyze_media_async(self, media_path: str, prompt: Optional[str] = None, fps: int = 2) -> Optional[str]:
        """
        è‡ªåŠ¨è¯†åˆ«å¹¶å¼‚æ­¥åˆ†æåª’ä½“æ–‡ä»¶ï¼ˆè§†é¢‘æˆ–å›¾åƒï¼‰
        
        Args:
            media_path: åª’ä½“æ–‡ä»¶è·¯å¾„
            prompt: åˆ†ææç¤ºè¯ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„é»˜è®¤æç¤ºè¯
            fps: è§†é¢‘å¸§ç‡ï¼ˆä»…å¯¹è§†é¢‘æœ‰æ•ˆï¼‰
            
        Returns:
            åˆ†æç»“æœæ–‡æœ¬ï¼Œå¦‚æœå¤±è´¥è¿”å›None
        """
        if self._is_video_file(media_path):
            logger.info(f"æ£€æµ‹åˆ°è§†é¢‘æ–‡ä»¶: {media_path}")
            return await self.analyze_video_async(media_path, prompt, fps)
        elif self._is_image_file(media_path):
            logger.info(f"æ£€æµ‹åˆ°å›¾åƒæ–‡ä»¶: {media_path}")
            return await self.analyze_image_async(media_path, prompt)
        else:
            logger.error(f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {media_path}")
            return None 

def smart_resize(
    height: int, width: int, factor: int = 28, min_pixels: int = 56 * 56, max_pixels: int = 14 * 14 * 4 * 1280
) -> Tuple[int, int]:
    """
    æ¨¡å‹æœåŠ¡çš„å›¾åƒresizeé€»è¾‘
    
    Rescales the image so that the following conditions are met:
    1. Both dimensions (height and width) are divisible by 'factor'.
    2. The total number of pixels is within the range ['min_pixels', 'max_pixels'].
    3. The aspect ratio of the image is maintained as closely as possible.
    
    Returns:
        Tuple[int, int]: (resized_height, resized_width)
    """
    if height < factor or width < factor:
        raise ValueError(f"height:{height} or width:{width} must be larger than factor:{factor}")
    elif max(height, width) / min(height, width) > 200:
        raise ValueError(
            f"absolute aspect ratio must be smaller than 200, got {max(height, width) / min(height, width)}"
        )
    h_bar = round(height / factor) * factor
    w_bar = round(width / factor) * factor
    if h_bar * w_bar > max_pixels:
        beta = math.sqrt((height * width) / max_pixels)
        h_bar = math.floor(height / beta / factor) * factor
        w_bar = math.floor(width / beta / factor) * factor
    elif h_bar * w_bar < min_pixels:
        beta = math.sqrt(min_pixels / (height * width))
        h_bar = math.ceil(height * beta / factor) * factor
        w_bar = math.ceil(width * beta / factor) * factor
    return h_bar, w_bar

def get_image_dimensions(image_path: str) -> Tuple[int, int]:
    """
    è·å–å›¾åƒçš„åŸå§‹å°ºå¯¸
    
    Returns:
        Tuple[int, int]: (width, height)
    """
    try:
        with Image.open(image_path) as img:
            return img.size  # PILè¿”å›(width, height)
    except Exception as e:
        logger.error(f"è·å–å›¾åƒå°ºå¯¸å¤±è´¥: {e}")
        return (0, 0) 