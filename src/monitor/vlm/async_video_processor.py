#!/usr/bin/env python3
"""
å¼‚æ­¥è§†é¢‘å¤„ç†å™¨æ¨¡å—
æä¾›å¸§æ”¶é›†ã€è§†é¢‘ç”Ÿæˆå’Œå¼‚æ­¥VLMæ¨ç†åŠŸèƒ½
"""

import os
import cv2
import time
import threading
import queue
import tempfile
import asyncio
import json
import numpy as np
from pathlib import Path
from typing import Optional, Dict, List, Callable, Any
from datetime import datetime
import logging

from .vlm_client import DashScopeVLMClient
from ..core.config import load_config
from ..utils.image_utils import smart_resize_frame, validate_frame, get_frame_info

logger = logging.getLogger(__name__)

class AsyncVideoProcessor:
    def __init__(self, vlm_client: Optional[DashScopeVLMClient] = None, temp_dir: Optional[str] = None,
                 target_video_duration: Optional[float] = None, frames_per_second: Optional[int] = None,
                 original_fps: Optional[float] = None, max_concurrent_inferences: Optional[int] = None):
        """
        å¼‚æ­¥è§†é¢‘å¤„ç†å™¨
        
        Args:
            vlm_client: VLMå®¢æˆ·ç«¯ï¼Œå¦‚æœä¸ºNoneåˆ™è‡ªåŠ¨åˆ›å»º
            temp_dir: ä¸´æ—¶ç›®å½•
            target_video_duration: ç›®æ ‡è§†é¢‘æ—¶é•¿ï¼ˆç§’ï¼‰ï¼Œå¦‚æœä¸ºNoneåˆ™ä»é…ç½®è¯»å–
            frames_per_second: æ¯ç§’æŠ½å–çš„å¸§æ•°ï¼Œå¦‚æœä¸ºNoneåˆ™ä»é…ç½®è¯»å–
            original_fps: åŸå§‹è§†é¢‘å¸§ç‡ï¼Œå¦‚æœä¸ºNoneåˆ™ä»é…ç½®è¯»å–
            max_concurrent_inferences: æœ€å¤§å¹¶å‘æ¨ç†æ•°é‡ï¼Œå¦‚æœä¸ºNoneåˆ™ä»é…ç½®è¯»å–
        """
        # åŠ è½½é…ç½®
        config = load_config()
        video_config = config.get('video_processing', {})
        vlm_config = config.get('vlm', {})
        
        # åˆå§‹åŒ–VLMå®¢æˆ·ç«¯
        self.vlm_client = vlm_client or DashScopeVLMClient()
        
        # è®¾ç½®ä¸´æ—¶ç›®å½•
        self.temp_dir = temp_dir or tempfile.gettempdir()
        
        # æŠ½å¸§å‚æ•°ï¼ˆä¼˜å…ˆä½¿ç”¨ä¼ å…¥å‚æ•°ï¼Œå¦åˆ™ä»é…ç½®è¯»å–ï¼‰
        self.target_video_duration = target_video_duration or video_config.get('target_video_duration', 3.0)
        self.frames_per_second = frames_per_second or video_config.get('frames_per_second', 5)
        self.original_fps = original_fps or video_config.get('default_fps', 25.0)
        self.target_frames_per_video = int(self.target_video_duration * self.frames_per_second)
        self.frames_per_interval = int(self.original_fps / self.frames_per_second)
        
        # æ£€æµ‹å›¾åƒæ¨¡å¼ï¼šå½“target_video_durationã€frames_per_secondã€target_frames_per_videoéƒ½ä¸º1æ—¶
        self.image_mode = (self.target_video_duration == 1.0 and 
                          self.frames_per_second == 1 and 
                          self.target_frames_per_video == 1)
        
        # è®¡ç®—éœ€è¦æ”¶é›†çš„æ€»å¸§æ•°ï¼ˆ3ç§’çš„åŸå§‹å¸§æ•°ï¼‰
        self.frames_to_collect_per_video = int(self.target_video_duration * self.original_fps)
        
        # å¹¶å‘æ§åˆ¶
        self.max_concurrent_inferences = max_concurrent_inferences or vlm_config.get('max_concurrent_inferences', 3)
        
        # å›¾åƒç¼©æ”¾é…ç½®ï¼ˆå®Œå…¨ä»é…ç½®æ–‡ä»¶è¯»å–ï¼‰
        self.enable_frame_resize = video_config.get('enable_frame_resize', True)
        self.target_width = video_config.get('target_width', 640)
        self.target_height = video_config.get('target_height', 360)
        self.max_frame_size_mb = video_config.get('max_frame_size_mb', 5.0)
        self.maintain_aspect_ratio = video_config.get('maintain_aspect_ratio', True)
        
        # ç¼“å†²åŒºå’Œé˜Ÿåˆ—
        self.frame_buffer = []
        self.frame_queue = queue.Queue(maxsize=100)
        self.result_queue = queue.Queue(maxsize=20)
        
        # çº¿ç¨‹æ§åˆ¶
        self.stop_event = threading.Event()
        self.video_writer_thread = None
        
        # å¼‚æ­¥æ¨ç†æ§åˆ¶
        self.active_inference_tasks = []  # å­˜å‚¨æ´»è·ƒçš„å¼‚æ­¥ä»»åŠ¡
        self.inference_loop = None
        self.inference_event_loop = None
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.total_frames_received = 0
        self.total_videos_created = 0
        self.total_images_created = 0  # æ–°å¢ï¼šå›¾åƒè®¡æ•°
        self.total_inferences_started = 0
        self.total_inferences_completed = 0
        self.start_time = None
        self.frames_resized = 0
        self.frames_invalid = 0
        
        # å®éªŒæ—¥å¿—
        self.experiment_log = []
        
        logger.info(f"å¼‚æ­¥è§†é¢‘å¤„ç†å™¨åˆå§‹åŒ–:")
        if self.image_mode:
            logger.info(f"  - ğŸ–¼ï¸ å›¾åƒæ¨¡å¼å·²å¯ç”¨ï¼ˆæ¯å¸§å•ç‹¬æ¨ç†ï¼‰")
            logger.info(f"  - æ¯å¸§æ¨ç†é—´éš”: æ¯{self.frames_per_interval:.1f}å¸§æŠ½1å¸§")
        else:
            logger.info(f"  - ğŸ¬ è§†é¢‘æ¨¡å¼ï¼ˆæ‰¹é‡å¸§æ¨ç†ï¼‰")
            logger.info(f"  - ç›®æ ‡è§†é¢‘æ—¶é•¿: {self.target_video_duration}s")
            logger.info(f"  - æ¯ä¸ªè§†é¢‘æ€»å¸§æ•°: {self.target_frames_per_video}å¸§")
            logger.info(f"  - æ¯ä¸ªè§†é¢‘æ”¶é›†åŸå§‹å¸§æ•°: {self.frames_to_collect_per_video}å¸§")
        
        logger.info(f"  - æ¯ç§’æŠ½å¸§æ•°: {self.frames_per_second}å¸§")
        logger.info(f"  - åŸå§‹å¸§ç‡: {self.original_fps}fps")
        logger.info(f"  - æŠ½å¸§é—´éš”: æ¯{self.frames_per_interval:.1f}å¸§æŠ½1å¸§")
        logger.info(f"  - æœ€å¤§å¹¶å‘æ¨ç†æ•°: {self.max_concurrent_inferences}")
        if self.enable_frame_resize:
            logger.info(f"  - å¸§ç¼©æ”¾å·²å¯ç”¨: ç›®æ ‡å°ºå¯¸ {self.target_width}x{self.target_height}")
            logger.info(f"    * æœ€å¤§å¸§å¤§å°: {self.max_frame_size_mb}MB")
            logger.info(f"    * ä¿æŒå®½é«˜æ¯”: {self.maintain_aspect_ratio}")
        else:
            logger.info(f"  - å¸§ç¼©æ”¾å·²ç¦ç”¨")

    def start(self):
        """å¯åŠ¨å¼‚æ­¥å¤„ç†"""
        self.stop_event.clear()
        self.start_time = time.time()
        
        # å¯åŠ¨è§†é¢‘å†™å…¥çº¿ç¨‹
        self.video_writer_thread = threading.Thread(
            target=self._video_writer_worker,
            name="VideoWriter"
        )
        self.video_writer_thread.start()
        
        # å¯åŠ¨å¼‚æ­¥æ¨ç†äº‹ä»¶å¾ªç¯çº¿ç¨‹
        self.inference_loop = threading.Thread(
            target=self._start_inference_loop,
            name="InferenceLoop"
        )
        self.inference_loop.start()
        
        # ç­‰å¾…äº‹ä»¶å¾ªç¯å¯åŠ¨å®Œæˆ
        max_wait = 5.0  # æœ€å¤šç­‰å¾…5ç§’
        wait_start = time.time()
        while self.inference_event_loop is None and time.time() - wait_start < max_wait:
            time.sleep(0.1)
        
        if self.inference_event_loop is None:
            logger.error("äº‹ä»¶å¾ªç¯å¯åŠ¨è¶…æ—¶")
        else:
            logger.info("å¼‚æ­¥è§†é¢‘å¤„ç†å™¨å·²å¯åŠ¨ï¼Œäº‹ä»¶å¾ªç¯å°±ç»ª")

    def stop(self):
        """åœæ­¢å¼‚æ­¥å¤„ç†"""
        self.stop_event.set()
        
        if self.video_writer_thread:
            self.video_writer_thread.join()
            
        # åœæ­¢å¼‚æ­¥æ¨ç†å¾ªç¯
        if self.inference_event_loop and not self.inference_event_loop.is_closed():
            try:
                # ç­‰å¾…æ‰€æœ‰æ´»è·ƒä»»åŠ¡å®Œæˆ
                if self.active_inference_tasks:
                    logger.info(f"ç­‰å¾… {len(self.active_inference_tasks)} ä¸ªæ¨ç†ä»»åŠ¡å®Œæˆ...")
                    # ä½¿ç”¨çº¿ç¨‹å®‰å…¨çš„æ–¹å¼åœæ­¢äº‹ä»¶å¾ªç¯
                    future = asyncio.run_coroutine_threadsafe(self._stop_inference_loop(), self.inference_event_loop)
                    future.result(timeout=30)  # æœ€å¤šç­‰å¾…30ç§’
            except Exception as e:
                logger.warning(f"åœæ­¢æ¨ç†å¾ªç¯æ—¶å‡ºé”™: {str(e)}")
            
        if self.inference_loop:
            self.inference_loop.join(timeout=10)
            
        logger.info(f"å¼‚æ­¥è§†é¢‘å¤„ç†å™¨å·²åœæ­¢ï¼Œæ€»å…±å¤„ç†{self.total_frames_received}å¸§ï¼Œ"
                   f"ç”Ÿæˆ{self.total_videos_created}ä¸ªè§†é¢‘ç‰‡æ®µï¼Œ"
                   f"å®Œæˆ{self.total_inferences_completed}/{self.total_inferences_started}ä¸ªæ¨ç†")
        
        # ä¿å­˜å¹¶è‡ªåŠ¨æ’åºå®éªŒæ—¥å¿—
        self._save_and_sort_experiment_log()

    def add_frame(self, frame, timestamp: Optional[float] = None):
        """æ·»åŠ å¸§åˆ°å¤„ç†é˜Ÿåˆ—"""
        try:
            # éªŒè¯å¸§æœ‰æ•ˆæ€§
            if not validate_frame(frame):
                logger.warning("æ¥æ”¶åˆ°æ— æ•ˆå¸§ï¼Œè·³è¿‡")
                self.frames_invalid += 1
                return
            
            # è·å–å¸§ä¿¡æ¯
            frame_info = get_frame_info(frame)
            logger.debug(f"æ¥æ”¶å¸§: {frame_info['resolution']}, {frame_info['size_mb']:.2f}MB")
            
            # åº”ç”¨å›¾åƒç¼©æ”¾ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            processed_frame = frame
            if self.enable_frame_resize:
                resized_frame = smart_resize_frame(
                    frame, 
                    target_width=self.target_width,
                    target_height=self.target_height,
                    max_size_mb=self.max_frame_size_mb,
                    maintain_aspect_ratio=self.maintain_aspect_ratio
                )
                if resized_frame is not None:
                    processed_frame = resized_frame
                    self.frames_resized += 1
                    
                    # è®°å½•ç¼©æ”¾ä¿¡æ¯
                    new_info = get_frame_info(processed_frame)
                    logger.debug(f"å¸§å·²ç¼©æ”¾: {frame_info['resolution']} -> {new_info['resolution']}, "
                               f"{frame_info['size_mb']:.2f}MB -> {new_info['size_mb']:.2f}MB")
            
            frame_data = {
                'frame': processed_frame,
                'timestamp': timestamp or time.time(),
                'frame_number': self.total_frames_received + 1,
                'relative_timestamp': (timestamp or time.time()) - (self.start_time or time.time()),
                'original_info': frame_info,
                'processed_info': get_frame_info(processed_frame) if processed_frame is not frame else frame_info,
                'was_resized': processed_frame is not frame
            }
            
            self.frame_queue.put(frame_data, timeout=1)
            self.total_frames_received += 1
            
            if self.total_frames_received % 50 == 0:
                logger.info(f"å·²æ¥æ”¶ {self.total_frames_received} å¸§ "
                          f"(ç¼©æ”¾: {self.frames_resized}, æ— æ•ˆ: {self.frames_invalid})")
                
        except queue.Full:
            logger.warning("å¸§é˜Ÿåˆ—å·²æ»¡ï¼Œä¸¢å¼ƒå¸§")
        except Exception as e:
            logger.error(f"æ·»åŠ å¸§å¤±è´¥: {str(e)}")

    def get_result(self, timeout: float = 1.0) -> Optional[Dict]:
        """è·å–æ¨ç†ç»“æœ"""
        try:
            return self.result_queue.get(timeout=timeout)
        except queue.Empty:
            return None

    def _start_inference_loop(self):
        """åœ¨å•ç‹¬çº¿ç¨‹ä¸­å¯åŠ¨å¼‚æ­¥äº‹ä»¶å¾ªç¯"""
        self.inference_event_loop = asyncio.new_event_loop()
        asyncio.set_event_loop(self.inference_event_loop)
        
        logger.info("æ¨ç†äº‹ä»¶å¾ªç¯å·²åˆ›å»º")
        
        try:
            self.inference_event_loop.run_until_complete(self._inference_manager())
        except Exception as e:
            logger.error(f"æ¨ç†äº‹ä»¶å¾ªç¯é”™è¯¯: {str(e)}")
        finally:
            try:
                # æ¸…ç†äº‹ä»¶å¾ªç¯
                pending = asyncio.all_tasks(self.inference_event_loop)
                if pending:
                    logger.info(f"å–æ¶ˆ {len(pending)} ä¸ªå¾…å¤„ç†ä»»åŠ¡")
                    for task in pending:
                        task.cancel()
                    # ç­‰å¾…ä»»åŠ¡å–æ¶ˆå®Œæˆ
                    self.inference_event_loop.run_until_complete(
                        asyncio.gather(*pending, return_exceptions=True)
                    )
            except Exception as e:
                logger.warning(f"æ¸…ç†äº‹ä»¶å¾ªç¯æ—¶å‡ºé”™: {str(e)}")
            finally:
                self.inference_event_loop.close()

    async def _stop_inference_loop(self):
        """åœæ­¢å¼‚æ­¥æ¨ç†å¾ªç¯"""
        # ç­‰å¾…æ‰€æœ‰æ´»è·ƒä»»åŠ¡å®Œæˆ
        if self.active_inference_tasks:
            completed_tasks = []
            for task in self.active_inference_tasks:
                if not task.done():
                    try:
                        result = await asyncio.wait_for(task, timeout=10.0)
                        completed_tasks.append(result)
                    except asyncio.TimeoutError:
                        logger.warning("æ¨ç†ä»»åŠ¡è¶…æ—¶ï¼Œå¼ºåˆ¶å–æ¶ˆ")
                        task.cancel()
                    except Exception as e:
                        logger.warning(f"æ¨ç†ä»»åŠ¡å¼‚å¸¸: {str(e)}")
            logger.info(f"å®Œæˆäº† {len(completed_tasks)} ä¸ªæ¨ç†ä»»åŠ¡")

    async def _inference_manager(self):
        """å¼‚æ­¥æ¨ç†ç®¡ç†å™¨"""
        logger.info("æ¨ç†ç®¡ç†å™¨å¯åŠ¨")
        while not self.stop_event.is_set():
            try:
                # æ¸…ç†å·²å®Œæˆçš„ä»»åŠ¡
                before_count = len(self.active_inference_tasks)
                self.active_inference_tasks = [
                    task for task in self.active_inference_tasks 
                    if not task.done()
                ]
                after_count = len(self.active_inference_tasks)
                
                if before_count != after_count:
                    logger.debug(f"æ¸…ç†äº† {before_count - after_count} ä¸ªå·²å®Œæˆä»»åŠ¡ï¼Œå‰©ä½™ {after_count} ä¸ª")
                
                # çŸ­æš‚ä¼‘çœ é¿å…å¿™ç­‰å¾…
                await asyncio.sleep(0.1)
                
            except Exception as e:
                logger.error(f"æ¨ç†ç®¡ç†å™¨é”™è¯¯: {str(e)}")
                await asyncio.sleep(1)  # å‡ºé”™æ—¶ç­‰å¾…æ›´é•¿æ—¶é—´
        
        logger.info("æ¨ç†ç®¡ç†å™¨åœæ­¢")

    def _submit_inference_task(self, video_info: Dict):
        """æäº¤å¼‚æ­¥æ¨ç†ä»»åŠ¡"""
        if self.inference_event_loop and not self.inference_event_loop.is_closed() and len(self.active_inference_tasks) < self.max_concurrent_inferences:
            try:
                task = asyncio.run_coroutine_threadsafe(
                    self._inference_worker_async(video_info),
                    self.inference_event_loop
                )
                self.active_inference_tasks.append(task)
                self.total_inferences_started += 1
                
                logger.info(f"æäº¤å¼‚æ­¥æ¨ç†ä»»åŠ¡: {os.path.basename(video_info['video_path'])}")
                logger.info(f"  - å½“å‰å¹¶å‘æ•°: {len(self.active_inference_tasks)}/{self.max_concurrent_inferences}")
                logger.info(f"  - æ€»å¯åŠ¨æ•°: {self.total_inferences_started}")
            except Exception as e:
                logger.error(f"æäº¤æ¨ç†ä»»åŠ¡å¤±è´¥: {str(e)}")
        else:
            if self.inference_event_loop is None:
                logger.warning("äº‹ä»¶å¾ªç¯æœªå°±ç»ªï¼Œè·³è¿‡æ¨ç†")
            elif self.inference_event_loop.is_closed():
                logger.warning("äº‹ä»¶å¾ªç¯å·²å…³é—­ï¼Œè·³è¿‡æ¨ç†")
            elif len(self.active_inference_tasks) >= self.max_concurrent_inferences:
                logger.warning(f"æ¨ç†ä»»åŠ¡é˜Ÿåˆ—å·²æ»¡ ({len(self.active_inference_tasks)}/{self.max_concurrent_inferences})ï¼Œè·³è¿‡æ¨ç†")
            else:
                logger.warning("æ¨ç†ä»»åŠ¡æäº¤å¤±è´¥ï¼ŒåŸå› æœªçŸ¥")

    async def _inference_worker_async(self, media_info: Dict):
        """çœŸæ­£çš„å¼‚æ­¥æ¨ç†å·¥ä½œå‡½æ•°"""
        try:
            # è®°å½•æ¨ç†å¼€å§‹æ—¶é—´
            inference_start_time = time.time()
            inference_start_timestamp = datetime.now().isoformat()
            
            media_type = media_info.get('media_type', 'video')
            media_path = media_info.get('media_path', media_info.get('video_path', media_info.get('image_path')))
            
            logger.info(f"å¼€å§‹å¼‚æ­¥VLMæ¨ç†: {os.path.basename(media_path)} ({media_type})")
            logger.info(f"  - æ¨ç†å¼€å§‹æ—¶é—´: {inference_start_timestamp}")
            
            if media_type == 'image':
                logger.info(f"  - å›¾åƒå¸§å·: {media_info.get('frame_number', 'N/A')}")
                logger.info(f"  - å›¾åƒæ—¶é—´æˆ³: {media_info.get('relative_timestamp', 'N/A'):.2f}s")
                
                # æ‰§è¡Œå¼‚æ­¥å›¾åƒæ¨ç†
                result = await self.vlm_client.analyze_image_async(
                    media_path, 
                    prompt=None  # ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„é»˜è®¤æç¤ºè¯
                )
            else:
                logger.info(f"  - æºè§†é¢‘æ—¶é—´èŒƒå›´: {media_info.get('start_relative_timestamp', 'N/A'):.2f}s - {media_info.get('end_relative_timestamp', 'N/A'):.2f}s")
                
                # æ‰§è¡Œå¼‚æ­¥è§†é¢‘æ¨ç†
                result = await self.vlm_client.analyze_video_async(
                    media_path, 
                    prompt=None,  # ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„é»˜è®¤æç¤ºè¯
                    fps=2
                )
            
            # è®°å½•æ¨ç†ç»“æŸæ—¶é—´
            inference_end_time = time.time()
            inference_end_timestamp = datetime.now().isoformat()
            inference_duration = inference_end_time - inference_start_time
            
            logger.info(f"å¼‚æ­¥VLMæ¨ç†å®Œæˆ: {os.path.basename(media_path)} ({media_type})")
            logger.info(f"  - æ¨ç†ç»“æŸæ—¶é—´: {inference_end_timestamp}")
            logger.info(f"  - æ¨ç†è€—æ—¶: {inference_duration:.2f}s")
            logger.info(f"  - ç»“æœé•¿åº¦: {len(result) if result else 0}å­—ç¬¦")
            
            # å°†ç»“æœæ”¾å…¥ç»“æœé˜Ÿåˆ—
            result_data = {
                'media_path': media_path,
                'media_type': media_type,
                'result': result,
                'media_info': media_info,
                'inference_start_time': inference_start_time,
                'inference_end_time': inference_end_time,
                'inference_start_timestamp': inference_start_timestamp,
                'inference_end_timestamp': inference_end_timestamp,
                'inference_duration': inference_duration,
                'result_received_at': time.time()
            }
            
            # ä¸ºäº†å‘åå…¼å®¹ï¼Œä¿ç•™video_pathå­—æ®µ
            if 'video_path' not in result_data:
                result_data['video_path'] = media_path
            if 'video_info' not in result_data:
                result_data['video_info'] = media_info
            
            # è®°å½•åˆ°å®éªŒæ—¥å¿—
            self.experiment_log.append(result_data.copy())
            self.total_inferences_completed += 1
            
            # ä¿å­˜æ¨ç†ç»“æœåˆ°åª’ä½“è¯¦æƒ…æ–‡ä»¶å¤¹
            self._save_inference_result_to_details(result_data)
            
            try:
                self.result_queue.put(result_data, timeout=1)
                logger.info(f"å¼‚æ­¥æ¨ç†ç»“æœå·²å…¥é˜Ÿ: {os.path.basename(media_path)} ({media_type})")
            except queue.Full:
                logger.warning("ç»“æœé˜Ÿåˆ—å·²æ»¡ï¼Œä¸¢å¼ƒç»“æœ")
                
        except Exception as e:
            logger.error(f"å¼‚æ­¥æ¨ç†å¤±è´¥: {str(e)}")
            self.total_inferences_completed += 1  # å³ä½¿å¤±è´¥ä¹Ÿè®¡å…¥å®Œæˆæ•°
            
        # æ³¨æ„ï¼šä¸åˆ é™¤ä¸´æ—¶æ–‡ä»¶ï¼Œä¿ç•™ç”¨äºè°ƒè¯•
        logger.debug(f"ä¿ç•™åª’ä½“æ–‡ä»¶ç”¨äºè°ƒè¯•: {media_path}")

    def _sample_frames_by_time(self, frames_data: List[Dict]) -> List[Dict]:
        """
        æŒ‰æ—¶é—´é—´éš”æŠ½å¸§ï¼šæ¯ç§’æŠ½å–æŒ‡å®šæ•°é‡çš„å¸§
        
        Args:
            frames_data: å¸§æ•°æ®åˆ—è¡¨
            
        Returns:
            æŠ½å–çš„å¸§æ•°æ®åˆ—è¡¨
        """
        if len(frames_data) < self.target_frames_per_video:
            logger.warning(f"å¸§æ•°ä¸è¶³: {len(frames_data)} < {self.target_frames_per_video}")
            return frames_data
        
        sampled_frames = []
        
        # è®¡ç®—æ—¶é—´èŒƒå›´
        start_time = frames_data[0]['relative_timestamp']
        end_time = frames_data[-1]['relative_timestamp']
        total_duration = end_time - start_time
        
        logger.info(f"å¼€å§‹æŠ½å¸§: æ€»å¸§æ•°={len(frames_data)}, æ—¶é—´èŒƒå›´={start_time:.2f}s-{end_time:.2f}s")
        
        # æŒ‰æ—¶é—´å‡åŒ€åˆ†å¸ƒæŠ½å¸§
        for second in range(int(self.target_video_duration)):
            # è®¡ç®—è¿™ä¸€ç§’çš„æ—¶é—´èŒƒå›´
            second_start = start_time + second
            second_end = second_start + 1.0
            
            # æ‰¾åˆ°è¿™ä¸€ç§’å†…çš„æ‰€æœ‰å¸§
            second_frames = [f for f in frames_data 
                           if second_start <= f['relative_timestamp'] < second_end]
            
            logger.debug(f"ç¬¬{second+1}ç§’ ({second_start:.2f}s-{second_end:.2f}s): æ‰¾åˆ°{len(second_frames)}å¸§")
            
            if len(second_frames) >= self.frames_per_second:
                # ä»è¿™ä¸€ç§’çš„å¸§ä¸­å‡åŒ€æŠ½å–æŒ‡å®šæ•°é‡çš„å¸§
                indices = np.linspace(0, len(second_frames) - 1, self.frames_per_second, dtype=int)
                for idx in indices:
                    sampled_frames.append(second_frames[idx])
                    logger.debug(f"  æŠ½å–å¸§: ç´¢å¼•{idx}, å¸§å·{second_frames[idx]['frame_number']}")
            elif second_frames:
                # å¦‚æœè¿™ä¸€ç§’çš„å¸§æ•°ä¸è¶³ï¼Œå…¨éƒ¨ä½¿ç”¨
                sampled_frames.extend(second_frames)
                logger.debug(f"  ä½¿ç”¨å…¨éƒ¨{len(second_frames)}å¸§")
        
        # å¦‚æœæŠ½å–çš„å¸§æ•°ä¸è¶³ï¼Œä»å‰©ä½™å¸§ä¸­è¡¥å……
        if len(sampled_frames) < self.target_frames_per_video:
            remaining_needed = self.target_frames_per_video - len(sampled_frames)
            used_frame_numbers = {f['frame_number'] for f in sampled_frames}
            remaining_frames = [f for f in frames_data if f['frame_number'] not in used_frame_numbers]
            
            if remaining_frames:
                step = max(1, len(remaining_frames) // remaining_needed)
                additional_frames = remaining_frames[::step][:remaining_needed]
                sampled_frames.extend(additional_frames)
                logger.debug(f"è¡¥å……{len(additional_frames)}å¸§")
        
        # æŒ‰æ—¶é—´æˆ³æ’åº
        sampled_frames.sort(key=lambda x: x['timestamp'])
        
        # è®°å½•æŠ½å¸§è¯¦æƒ…
        if sampled_frames:
            original_time_range = (frames_data[0]['relative_timestamp'], frames_data[-1]['relative_timestamp'])
            sampled_time_range = (sampled_frames[0]['relative_timestamp'], sampled_frames[-1]['relative_timestamp'])
            
            logger.info(f"æŠ½å¸§å®Œæˆ: {len(frames_data)}å¸§ -> {len(sampled_frames)}å¸§")
            logger.info(f"åŸå§‹æ—¶é—´èŒƒå›´: {original_time_range[0]:.2f}s - {original_time_range[1]:.2f}s")
            logger.info(f"æŠ½å–æ—¶é—´èŒƒå›´: {sampled_time_range[0]:.2f}s - {sampled_time_range[1]:.2f}s")
            logger.info(f"æŠ½å–å¸§è¯¦æƒ…: {[f['frame_number'] for f in sampled_frames]}")
        else:
            logger.error("æŠ½å¸§å¤±è´¥ï¼šæ²¡æœ‰æŠ½å–åˆ°ä»»ä½•å¸§")
        
        return sampled_frames

    def _video_writer_worker(self):
        """è§†é¢‘å†™å…¥å·¥ä½œçº¿ç¨‹"""
        try:
            while not self.stop_event.is_set():
                try:
                    frame_data = self.frame_queue.get(timeout=1)
                except queue.Empty:
                    continue
                
                if self.image_mode:
                    # å›¾åƒæ¨¡å¼ï¼šç›´æ¥å¤„ç†å•å¸§
                    self._process_single_frame(frame_data)
                else:
                    # è§†é¢‘æ¨¡å¼ï¼šæ”¶é›†å¸§å¹¶åˆ›å»ºè§†é¢‘
                    self._process_video_frames(frame_data)
                    
        except Exception as e:
            logger.error(f"è§†é¢‘å†™å…¥çº¿ç¨‹é”™è¯¯: {str(e)}")
    
    def _process_single_frame(self, frame_data: Dict):
        """å¤„ç†å•å¸§å›¾åƒï¼ˆå›¾åƒæ¨¡å¼ï¼‰"""
        try:
            # æ£€æŸ¥æ˜¯å¦éœ€è¦æŠ½å¸§ï¼ˆæŒ‰é—´éš”ï¼‰
            if self.total_frames_received % self.frames_per_interval != 0:
                return
            
            # åˆ›å»ºå›¾åƒæ–‡ä»¶
            image_creation_start = time.time()
            image_path = self._create_image_from_frame(frame_data)
            image_creation_time = time.time() - image_creation_start
            
            if image_path:
                # ä¿å­˜å›¾åƒè¯¦æƒ…åˆ°å®éªŒç›®å½•
                image_info = self._save_image_details(frame_data, image_path, image_creation_time)
                
                # ä½¿ç”¨ä¿å­˜åçš„å›¾åƒè·¯å¾„
                final_image_path = image_info.get('image_path', image_path)
                
                image_info.update({
                    'media_path': final_image_path,  # ç»Ÿä¸€ä½¿ç”¨media_pathå­—æ®µ
                    'media_type': 'image',
                    'frame_count': 1,
                    'timestamp': frame_data['timestamp'],
                    'relative_timestamp': frame_data['relative_timestamp'],
                    'frame_number': frame_data['frame_number'],
                    'image_creation_time': image_creation_time,
                    'image_creation_timestamp': datetime.fromtimestamp(image_creation_start).isoformat(),
                    'created_at': time.time()
                })
                
                self.total_images_created += 1
                logger.info(f"å›¾åƒå·²ç”Ÿæˆ: {os.path.basename(image_path)}")
                logger.info(f"  - å¸§å·: {frame_data['frame_number']}")
                logger.info(f"  - æ—¶é—´æˆ³: {frame_data['relative_timestamp']:.2f}s")
                logger.info(f"  - å›¾åƒåˆ›å»ºè€—æ—¶: {image_creation_time:.3f}s")
                
                # ç«‹å³æäº¤å¼‚æ­¥æ¨ç†ä»»åŠ¡
                self._submit_inference_task(image_info)
                
        except Exception as e:
            logger.error(f"å¤„ç†å•å¸§å›¾åƒå¤±è´¥: {str(e)}")
    
    def _process_video_frames(self, frame_data: Dict):
        """å¤„ç†è§†é¢‘å¸§ï¼ˆè§†é¢‘æ¨¡å¼ï¼‰"""
        # æ·»åŠ åˆ°ç¼“å†²åŒº
        self.frame_buffer.append(frame_data)
        
        # å½“ç¼“å†²åŒºè¾¾åˆ°ä¸€ä¸ªè§†é¢‘æ‰€éœ€çš„å¸§æ•°æ—¶ï¼Œè¿›è¡ŒæŠ½å¸§å¹¶åˆ›å»ºè§†é¢‘
        if len(self.frame_buffer) >= self.frames_to_collect_per_video:
            # æŠ½å–å¸§
            sampled_frames = self._sample_frames_by_time(self.frame_buffer[:self.frames_to_collect_per_video])
            
            # åˆ›å»ºè§†é¢‘
            video_creation_start = time.time()
            video_path = self._create_video_from_frames(sampled_frames)
            video_creation_time = time.time() - video_creation_start
            
            if video_path:
                # è®¡ç®—æ—¶é—´èŒƒå›´
                start_timestamp = sampled_frames[0]['timestamp']
                end_timestamp = sampled_frames[-1]['timestamp']
                start_relative = sampled_frames[0]['relative_timestamp']
                end_relative = sampled_frames[-1]['relative_timestamp']
                
                # ä¿å­˜æŠ½å¸§è¯¦æƒ…åˆ°å®éªŒç›®å½•
                video_info = self._save_video_details(sampled_frames, video_path, video_creation_time)
                
                # ä½¿ç”¨ä¿å­˜åçš„è§†é¢‘è·¯å¾„ï¼ˆå¯èƒ½å·²è¢«ç§»åŠ¨åˆ°detailsæ–‡ä»¶å¤¹ï¼‰
                final_video_path = video_info.get('video_path', video_path)
                
                video_info.update({
                    'media_path': final_video_path,  # ç»Ÿä¸€ä½¿ç”¨media_pathå­—æ®µ
                    'media_type': 'video',
                    'frame_count': len(sampled_frames),
                    'start_timestamp': start_timestamp,
                    'end_timestamp': end_timestamp,
                    'start_relative_timestamp': start_relative,
                    'end_relative_timestamp': end_relative,
                    'duration': end_timestamp - start_timestamp,
                    'relative_duration': end_relative - start_relative,
                    'original_frame_range': (
                        sampled_frames[0]['frame_number'],
                        sampled_frames[-1]['frame_number']
                    ),
                    'video_creation_time': video_creation_time,
                    'video_creation_timestamp': datetime.fromtimestamp(video_creation_start).isoformat(),
                    'created_at': time.time()
                })
                
                self.total_videos_created += 1
                logger.info(f"è§†é¢‘ç‰‡æ®µå·²ç”Ÿæˆ: {os.path.basename(video_path)}")
                logger.info(f"  - å¸§èŒƒå›´: {video_info['original_frame_range']}")
                logger.info(f"  - æºè§†é¢‘æ—¶é—´: {start_relative:.2f}s - {end_relative:.2f}s")
                logger.info(f"  - è§†é¢‘åˆ›å»ºè€—æ—¶: {video_creation_time:.3f}s")
                
                # ç«‹å³æäº¤å¼‚æ­¥æ¨ç†ä»»åŠ¡
                self._submit_inference_task(video_info)
            
            # ç§»é™¤å·²å¤„ç†çš„å¸§ï¼Œä¿ç•™25%é‡å ä»¥ç¡®ä¿è¿ç»­æ€§
            overlap_frames = self.frames_to_collect_per_video // 4
            self.frame_buffer = self.frame_buffer[self.frames_to_collect_per_video - overlap_frames:]
    
    def _create_image_from_frame(self, frame_data: Dict) -> Optional[str]:
        """ä»å•å¸§åˆ›å»ºå›¾åƒæ–‡ä»¶"""
        try:
            # åˆ›å»ºå›¾åƒæ–‡ä»¶è·¯å¾„
            timestamp = datetime.fromtimestamp(frame_data['timestamp'])
            image_name = f"frame_{frame_data['frame_number']:06d}_{timestamp.strftime('%H%M%S_%f')[:-3]}.jpg"
            image_path = os.path.join(self.temp_dir, image_name)
            
            # ç¡®ä¿ç›®å½•å­˜åœ¨
            os.makedirs(os.path.dirname(image_path), exist_ok=True)
            
            # ä¿å­˜å›¾åƒ
            success = cv2.imwrite(image_path, frame_data['frame'])
            
            if success:
                logger.debug(f"å›¾åƒå·²ä¿å­˜: {image_path}")
                return image_path
            else:
                logger.error(f"ä¿å­˜å›¾åƒå¤±è´¥: {image_path}")
                return None
                
        except Exception as e:
            logger.error(f"åˆ›å»ºå›¾åƒæ–‡ä»¶å¤±è´¥: {str(e)}")
            return None
    
    def _save_image_details(self, frame_data: Dict, image_path: str, creation_time: float) -> Dict:
        """ä¿å­˜å›¾åƒè¯¦æƒ…åˆ°å®éªŒç›®å½•"""
        try:
            # åˆ›å»ºå›¾åƒè¯¦æƒ…ç›®å½•
            image_name = os.path.splitext(os.path.basename(image_path))[0]
            details_dir = os.path.join(self.temp_dir, f"{image_name}_details")
            os.makedirs(details_dir, exist_ok=True)
            
            # å°†å›¾åƒæ–‡ä»¶ç§»åŠ¨åˆ°detailsæ–‡ä»¶å¤¹å†…
            new_image_path = os.path.join(details_dir, os.path.basename(image_path))
            if os.path.exists(image_path) and image_path != new_image_path:
                import shutil
                shutil.move(image_path, new_image_path)
                logger.debug(f"å›¾åƒæ–‡ä»¶å·²ç§»åŠ¨åˆ°: {new_image_path}")
            else:
                new_image_path = image_path
            
            # ä¿å­˜è¯¦æƒ…JSON
            details = {
                'image_path': new_image_path,
                'creation_time': creation_time,
                'creation_timestamp': datetime.fromtimestamp(time.time()).isoformat(),
                'frame_number': frame_data['frame_number'],
                'timestamp': frame_data['timestamp'],
                'timestamp_iso': datetime.fromtimestamp(frame_data['timestamp']).isoformat(),
                'relative_timestamp': frame_data['relative_timestamp'],
                'frame_info': {
                    'width': frame_data['frame'].shape[1],
                    'height': frame_data['frame'].shape[0],
                    'channels': frame_data['frame'].shape[2] if len(frame_data['frame'].shape) > 2 else 1
                }
            }
            
            details_file = os.path.join(details_dir, 'image_details.json')
            with open(details_file, 'w', encoding='utf-8') as f:
                json.dump(details, f, ensure_ascii=False, indent=2, default=str)
            
            logger.info(f"å›¾åƒè¯¦æƒ…å·²ä¿å­˜: {details_dir}")
            return {
                'details_dir': details_dir, 
                'details_file': details_file,
                'image_path': new_image_path
            }
            
        except Exception as e:
            logger.error(f"ä¿å­˜å›¾åƒè¯¦æƒ…å¤±è´¥: {str(e)}")
            return {'image_path': image_path}

    def _create_video_from_frames(self, frames_data: List[Dict]) -> Optional[str]:
        """ä»å¸§æ•°æ®åˆ›å»ºè§†é¢‘æ–‡ä»¶"""
        if not frames_data:
            return None
            
        try:
            video_path = self._create_temp_video_path()
            
            # ç¡®ä¿ç›®å½•å­˜åœ¨
            video_dir = os.path.dirname(video_path)
            os.makedirs(video_dir, exist_ok=True)
            
            # è·å–ç¬¬ä¸€å¸§çš„å°ºå¯¸
            first_frame = frames_data[0]['frame']
            height, width = first_frame.shape[:2]
            
            # åˆ›å»ºè§†é¢‘å†™å…¥å™¨ï¼Œä½¿ç”¨ç›®æ ‡å¸§ç‡
            output_fps = self.frames_per_second  # è¾“å‡ºè§†é¢‘çš„å¸§ç‡ç­‰äºæ¯ç§’æŠ½å–çš„å¸§æ•°
            
            # å°è¯•å¤šç§ç¼–ç å™¨ï¼ŒæŒ‰ä¼˜å…ˆçº§æ’åº
            codecs_to_try = [
                ('mp4v', 'MP4V'),  # æœ€å…¼å®¹çš„ç¼–ç å™¨
                ('XVID', 'XVID'),  # å¹¿æ³›æ”¯æŒçš„ç¼–ç å™¨
                ('avc1', 'H.264'), # H.264ç¼–ç å™¨
                ('H264', 'H.264'), # å¦ä¸€ç§H.264ç¼–ç å™¨
                ('MJPG', 'MJPG'),  # Motion JPEG
            ]
            
            writer = None
            used_codec = None
            temp_video_path = video_path  # ä¸´æ—¶è§†é¢‘è·¯å¾„
            
            for codec_name, codec_desc in codecs_to_try:
                try:
                    fourcc = cv2.VideoWriter.fourcc(*codec_name)
                    writer = cv2.VideoWriter(temp_video_path, fourcc, output_fps, (width, height))
                    
                    # æµ‹è¯•å†™å…¥å™¨æ˜¯å¦æ­£å¸¸å·¥ä½œ
                    if writer.isOpened():
                        used_codec = codec_desc
                        logger.debug(f"æˆåŠŸä½¿ç”¨ç¼–ç å™¨: {codec_desc} ({codec_name})")
                        break
                    else:
                        writer.release()
                        writer = None
                        logger.debug(f"ç¼–ç å™¨ {codec_desc} ({codec_name}) ä¸å¯ç”¨")
                except Exception as e:
                    logger.debug(f"ç¼–ç å™¨ {codec_desc} ({codec_name}) åˆå§‹åŒ–å¤±è´¥: {str(e)}")
                    if writer:
                        writer.release()
                        writer = None
            
            if writer is None or not writer.isOpened():
                logger.error("æ‰€æœ‰è§†é¢‘ç¼–ç å™¨éƒ½ä¸å¯ç”¨")
                return None
            
            # å†™å…¥æ‰€æœ‰å¸§
            frames_written = 0
            for frame_data in frames_data:
                try:
                    writer.write(frame_data['frame'])
                    frames_written += 1
                except Exception as e:
                    logger.warning(f"å†™å…¥å¸§å¤±è´¥: {str(e)}")
                    
            writer.release()
            
            if frames_written == 0:
                logger.error("æ²¡æœ‰æˆåŠŸå†™å…¥ä»»ä½•å¸§")
                if os.path.exists(temp_video_path):
                    os.remove(temp_video_path)
                return None
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨ä¸”æœ‰å†…å®¹
            if not os.path.exists(temp_video_path):
                logger.error(f"è§†é¢‘æ–‡ä»¶åˆ›å»ºå¤±è´¥ï¼Œæ–‡ä»¶ä¸å­˜åœ¨: {temp_video_path}")
                return None
            
            file_size_mb = os.path.getsize(temp_video_path) / (1024 * 1024)
            
            if file_size_mb == 0:
                logger.error("è§†é¢‘æ–‡ä»¶å¤§å°ä¸º0ï¼Œåˆ é™¤æ–‡ä»¶")
                os.remove(temp_video_path)
                return None
            
            if file_size_mb > 95:  # å¦‚æœè¶…è¿‡95MBï¼Œåˆ é™¤æ–‡ä»¶
                os.remove(temp_video_path)
                logger.warning(f"è§†é¢‘æ–‡ä»¶è¿‡å¤§ ({file_size_mb:.2f}MB)ï¼Œå·²åˆ é™¤")
                return None
            
            # å¦‚æœä½¿ç”¨çš„ä¸æ˜¯H.264ç¼–ç å™¨ï¼Œå°è¯•ç”¨FFmpegè½¬æ¢ä¸ºH.264
            final_video_path = temp_video_path
            if used_codec != 'H.264' and self._is_ffmpeg_available():
                h264_video_path = temp_video_path.replace('.mp4', '_h264.mp4')
                if self._convert_to_h264_with_ffmpeg(temp_video_path, h264_video_path):
                    # è½¬æ¢æˆåŠŸï¼Œä½¿ç”¨H.264ç‰ˆæœ¬
                    final_video_path = h264_video_path
                    used_codec = 'H.264 (FFmpeg)'
                    
                    # åˆ é™¤åŸå§‹æ–‡ä»¶
                    try:
                        os.remove(temp_video_path)
                    except:
                        pass
                    
                    # æ›´æ–°æ–‡ä»¶å¤§å°
                    file_size_mb = os.path.getsize(final_video_path) / (1024 * 1024)
                    logger.debug(f"FFmpegè½¬æ¢æˆåŠŸï¼Œæ–°æ–‡ä»¶å¤§å°: {file_size_mb:.2f}MB")
                else:
                    logger.debug("FFmpegè½¬æ¢å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹æ–‡ä»¶")
                    
            logger.debug(f"è§†é¢‘æ–‡ä»¶åˆ›å»ºæˆåŠŸ: {final_video_path}")
            logger.debug(f"  - ç¼–ç å™¨: {used_codec}")
            logger.debug(f"  - æ–‡ä»¶å¤§å°: {file_size_mb:.2f}MB")
            logger.debug(f"  - å¸§ç‡: {output_fps}fps")
            logger.debug(f"  - å†™å…¥å¸§æ•°: {frames_written}/{len(frames_data)}")
            
            return final_video_path
            
        except Exception as e:
            logger.error(f"åˆ›å»ºè§†é¢‘æ–‡ä»¶å¤±è´¥: {str(e)}")
            # æ¸…ç†å¯èƒ½åˆ›å»ºçš„æ–‡ä»¶
            for path_var in ['temp_video_path', 'final_video_path', 'h264_video_path']:
                if path_var in locals():
                    path = locals()[path_var]
                    if os.path.exists(path):
                        try:
                            os.remove(path)
                        except:
                            pass
            return None

    def _is_ffmpeg_available(self) -> bool:
        """æ£€æŸ¥FFmpegæ˜¯å¦å¯ç”¨"""
        try:
            import subprocess
            result = subprocess.run(['ffmpeg', '-version'], 
                                  capture_output=True, text=True, timeout=5)
            return result.returncode == 0
        except:
            return False

    def _convert_to_h264_with_ffmpeg(self, input_path: str, output_path: str) -> bool:
        """ä½¿ç”¨FFmpegå°†è§†é¢‘è½¬æ¢ä¸ºH.264æ ¼å¼"""
        try:
            import subprocess
            
            # FFmpegå‘½ä»¤ï¼šè½¬æ¢ä¸ºH.264ï¼Œä¿æŒåŸå§‹å¸§ç‡å’Œåˆ†è¾¨ç‡
            cmd = [
                'ffmpeg',
                '-i', input_path,           # è¾“å…¥æ–‡ä»¶
                '-c:v', 'libx264',          # ä½¿ç”¨H.264ç¼–ç å™¨
                '-preset', 'fast',          # å¿«é€Ÿç¼–ç é¢„è®¾
                '-crf', '23',               # è´¨é‡è®¾ç½®ï¼ˆ18-28ï¼Œè¶Šå°è´¨é‡è¶Šå¥½ï¼‰
                '-movflags', '+faststart',  # ä¼˜åŒ–ç½‘ç»œæ’­æ”¾
                '-y',                       # è¦†ç›–è¾“å‡ºæ–‡ä»¶
                output_path                 # è¾“å‡ºæ–‡ä»¶
            ]
            
            logger.debug(f"æ‰§è¡ŒFFmpegè½¬æ¢: {' '.join(cmd)}")
            
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=30)
            
            if result.returncode == 0 and os.path.exists(output_path):
                output_size = os.path.getsize(output_path)
                if output_size > 0:
                    logger.debug(f"FFmpegè½¬æ¢æˆåŠŸ: {output_path} ({output_size} bytes)")
                    return True
                else:
                    logger.warning("FFmpegè½¬æ¢åæ–‡ä»¶å¤§å°ä¸º0")
                    return False
            else:
                logger.warning(f"FFmpegè½¬æ¢å¤±è´¥: {result.stderr}")
                return False
                
        except subprocess.TimeoutExpired:
            logger.warning("FFmpegè½¬æ¢è¶…æ—¶")
            return False
        except Exception as e:
            logger.warning(f"FFmpegè½¬æ¢å¼‚å¸¸: {str(e)}")
            return False

    def _save_and_sort_experiment_log(self):
        """ä¿å­˜å¹¶è‡ªåŠ¨æ’åºå®éªŒæ—¥å¿—"""
        try:
            # æŒ‰original_frame_rangeæ’åºinference_logï¼Œæ–¹ä¾¿è°ƒè¯•
            sorted_experiment_log = sorted(
                self.experiment_log, 
                key=lambda x: x.get('video_info', {}).get('original_frame_range', [0, 0])[0]
            )
            
            log_file = os.path.join(self.temp_dir, 'experiment_log.json')
            with open(log_file, 'w', encoding='utf-8') as f:
                json.dump({
                    'processor_config': {
                        'target_video_duration': self.target_video_duration,
                        'frames_per_second': self.frames_per_second,
                        'original_fps': self.original_fps,
                        'target_frames_per_video': self.target_frames_per_video,
                        'frames_to_collect_per_video': self.frames_to_collect_per_video,
                        'max_concurrent_inferences': self.max_concurrent_inferences
                    },
                    'statistics': {
                        'total_frames_received': self.total_frames_received,
                        'total_videos_created': self.total_videos_created,
                        'total_images_created': self.total_images_created,
                        'total_inferences_started': self.total_inferences_started,
                        'total_inferences_completed': self.total_inferences_completed,
                        'start_time': self.start_time,
                        'start_timestamp': datetime.fromtimestamp(self.start_time).isoformat() if self.start_time else None,
                        'total_duration': time.time() - (self.start_time or time.time())
                    },
                    'inference_log': sorted_experiment_log  # ä½¿ç”¨æ’åºåçš„æ—¥å¿—
                }, f, ensure_ascii=False, indent=2, default=str)
            
            logger.info(f"å®éªŒæ—¥å¿—å·²ä¿å­˜å¹¶è‡ªåŠ¨æ’åº: {log_file}")
            logger.info(f"æ¨ç†æ—¥å¿—å·²æŒ‰å¸§èŒƒå›´æ’åºï¼Œå…± {len(sorted_experiment_log)} æ¡è®°å½•")
            
        except Exception as e:
            logger.error(f"ä¿å­˜å®éªŒæ—¥å¿—å¤±è´¥: {str(e)}")

    def _create_temp_video_path(self) -> str:
        """åˆ›å»ºä¸´æ—¶è§†é¢‘æ–‡ä»¶è·¯å¾„"""
        timestamp = int(time.time() * 1000)
        filename = f"sampled_video_{timestamp}.mp4"
        return os.path.join(self.temp_dir, filename)

    def _save_inference_result_to_details(self, result_data: Dict):
        """ä¿å­˜æ¨ç†ç»“æœåˆ°è§†é¢‘è¯¦æƒ…æ–‡ä»¶å¤¹"""
        try:
            # æå–è§†é¢‘ä¿¡æ¯å’Œæ¨ç†ç»“æœ
            video_info = result_data.get('video_info', {})
            details_dir = video_info.get('details_dir')
            
            if not details_dir or not os.path.exists(details_dir):
                logger.warning(f"è§†é¢‘è¯¦æƒ…ç›®å½•ä¸å­˜åœ¨: {details_dir}")
                return
            
            # åˆ›å»ºæ¨ç†ç»“æœæ–‡ä»¶è·¯å¾„
            inference_result_file = os.path.join(details_dir, 'inference_result.json')
            
            # å‡†å¤‡è¦ä¿å­˜çš„æ¨ç†ç»“æœæ•°æ®
            inference_data = {
                'video_path': result_data['video_path'],
                'inference_start_time': result_data['inference_start_time'],
                'inference_end_time': result_data['inference_end_time'],
                'inference_start_timestamp': result_data['inference_start_timestamp'],
                'inference_end_timestamp': result_data['inference_end_timestamp'],
                'inference_duration': result_data['inference_duration'],
                'result_received_at': result_data['result_received_at'],
                'raw_result': result_data['result']  # åŸå§‹ç»“æœå­—ç¬¦ä¸²
            }
            
            # å°è¯•è§£æJSONç»“æœ
            try:
                result_text = result_data['result']
                if result_text:
                    # å¦‚æœç»“æœåŒ…å«```jsonæ ‡è®°ï¼Œæå–JSONéƒ¨åˆ†
                    if '```json' in result_text:
                        start_idx = result_text.find('```json') + 7
                        end_idx = result_text.find('```', start_idx)
                        if end_idx > start_idx:
                            json_text = result_text[start_idx:end_idx].strip()
                        else:
                            json_text = result_text
                    else:
                        json_text = result_text.strip()
                    
                    # å°è¯•è§£æJSON
                    import json
                    parsed_result = json.loads(json_text)
                    inference_data['parsed_result'] = parsed_result
                    logger.debug(f"æˆåŠŸè§£ææ¨ç†ç»“æœJSON")
                    
            except (json.JSONDecodeError, ValueError) as e:
                logger.warning(f"æ— æ³•è§£ææ¨ç†ç»“æœä¸ºJSON: {str(e)}")
                inference_data['parse_error'] = str(e)
            
            # ä¿å­˜æ¨ç†ç»“æœåˆ°æ–‡ä»¶
            with open(inference_result_file, 'w', encoding='utf-8') as f:
                json.dump(inference_data, f, ensure_ascii=False, indent=2, default=str)
            
            logger.info(f"æ¨ç†ç»“æœå·²ä¿å­˜åˆ°: {inference_result_file}")
            
        except Exception as e:
            logger.error(f"ä¿å­˜æ¨ç†ç»“æœå¤±è´¥: {str(e)}") 

    def _save_video_details(self, sampled_frames: List[Dict], video_path: str, creation_time: float) -> Dict:
        """ä¿å­˜è§†é¢‘è¯¦æƒ…åˆ°å®éªŒç›®å½•"""
        try:
            # åˆ›å»ºè§†é¢‘è¯¦æƒ…ç›®å½•
            video_name = os.path.splitext(os.path.basename(video_path))[0]
            details_dir = os.path.join(self.temp_dir, f"{video_name}_details")
            os.makedirs(details_dir, exist_ok=True)
            
            # å°†è§†é¢‘æ–‡ä»¶ç§»åŠ¨åˆ°detailsæ–‡ä»¶å¤¹å†…
            new_video_path = os.path.join(details_dir, os.path.basename(video_path))
            if os.path.exists(video_path) and video_path != new_video_path:
                import shutil
                shutil.move(video_path, new_video_path)
                logger.debug(f"è§†é¢‘æ–‡ä»¶å·²ç§»åŠ¨åˆ°: {new_video_path}")
            else:
                new_video_path = video_path
            
            # ä¿å­˜æŠ½å–çš„å¸§
            frame_paths = []
            for i, frame_data in enumerate(sampled_frames):
                frame_path = os.path.join(details_dir, f"frame_{i:02d}_orig_{frame_data['frame_number']:04d}.jpg")
                cv2.imwrite(frame_path, frame_data['frame'])
                frame_paths.append(frame_path)
            
            # ä¿å­˜è¯¦æƒ…JSON
            details = {
                'video_path': new_video_path,  # ä½¿ç”¨æ–°çš„è§†é¢‘è·¯å¾„
                'creation_time': creation_time,
                'creation_timestamp': datetime.fromtimestamp(time.time()).isoformat(),
                'total_frames': len(sampled_frames),
                'frames_per_second': self.frames_per_second,
                'target_duration': self.target_video_duration,
                'sampled_frames': [
                    {
                        'index': i,
                        'original_frame_number': frame['frame_number'],
                        'timestamp': frame['timestamp'],
                        'timestamp_iso': datetime.fromtimestamp(frame['timestamp']).isoformat(),
                        'relative_timestamp': frame['relative_timestamp'],
                        'saved_path': frame_paths[i]
                    }
                    for i, frame in enumerate(sampled_frames)
                ]
            }
            
            details_file = os.path.join(details_dir, 'video_details.json')
            with open(details_file, 'w', encoding='utf-8') as f:
                json.dump(details, f, ensure_ascii=False, indent=2, default=str)
            
            logger.info(f"è§†é¢‘è¯¦æƒ…å·²ä¿å­˜: {details_dir}")
            return {
                'details_dir': details_dir, 
                'details_file': details_file,
                'video_path': new_video_path  # è¿”å›æ–°çš„è§†é¢‘è·¯å¾„
            }
            
        except Exception as e:
            logger.error(f"ä¿å­˜è§†é¢‘è¯¦æƒ…å¤±è´¥: {str(e)}")
            return {'video_path': video_path}  # å¤±è´¥æ—¶è¿”å›åŸè·¯å¾„ 