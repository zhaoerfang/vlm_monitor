#!/usr/bin/env python3
"""
å¼‚æ­¥è§†é¢‘å¤„ç†å™¨æ¨¡å—
æä¾›å¸§æ”¶é›†ã€è§†é¢‘ç”Ÿæˆå’Œå¼‚æ­¥VLMæ¨ç†åŠŸèƒ½
"""

import os
import cv2
import time
import threading
import queue
import tempfile
import asyncio
import json
import numpy as np
from pathlib import Path
from typing import Optional, Dict, List, Callable, Any
from datetime import datetime
import logging

from .vlm_client import DashScopeVLMClient, get_image_dimensions, smart_resize
from .user_question_manager import UserQuestionManager, init_question_manager
from ..core.config import load_config
from ..utils.image_utils import smart_resize_frame, validate_frame, get_frame_info

logger = logging.getLogger(__name__)

class AsyncVideoProcessor:
    def __init__(self, vlm_client: Optional[DashScopeVLMClient] = None, temp_dir: Optional[str] = None,
                 target_video_duration: Optional[float] = None, frames_per_second: Optional[int] = None,
                 original_fps: Optional[float] = None, max_concurrent_inferences: Optional[int] = None):
        """
        å¼‚æ­¥è§†é¢‘å¤„ç†å™¨
        
        Args:
            vlm_client: VLMå®¢æˆ·ç«¯ï¼Œå¦‚æœä¸ºNoneåˆ™è‡ªåŠ¨åˆ›å»º
            temp_dir: ä¸´æ—¶ç›®å½•
            target_video_duration: ç›®æ ‡è§†é¢‘æ—¶é•¿ï¼ˆç§’ï¼‰ï¼Œå¦‚æœä¸ºNoneåˆ™ä»é…ç½®è¯»å–
            frames_per_second: æ¯ç§’æŠ½å–çš„å¸§æ•°ï¼Œå¦‚æœä¸ºNoneåˆ™ä»é…ç½®è¯»å–
            original_fps: åŸå§‹è§†é¢‘å¸§ç‡ï¼Œå¦‚æœä¸ºNoneåˆ™ä»é…ç½®è¯»å–
            max_concurrent_inferences: æœ€å¤§å¹¶å‘æ¨ç†æ•°é‡ï¼Œå¦‚æœä¸ºNoneåˆ™ä»é…ç½®è¯»å–
        """
        # åŠ è½½é…ç½®
        config = load_config()
        video_config = config.get('video_processing', {})
        vlm_config = config.get('vlm', {})
        asr_config = config.get('asr', {})
        
        # åˆå§‹åŒ–VLMå®¢æˆ·ç«¯
        self.vlm_client = vlm_client or DashScopeVLMClient()
        
        # åˆå§‹åŒ–ç”¨æˆ·é—®é¢˜ç®¡ç†å™¨ï¼ˆå¦‚æœASRæœåŠ¡å¯ç”¨ï¼‰
        self.question_manager = None
        if asr_config.get('enabled', False):
            asr_host = asr_config.get('host', 'localhost')
            asr_port = asr_config.get('port', 8081)
            asr_url = f"http://{asr_host}:{asr_port}"
            self.question_manager = init_question_manager(asr_server_url=asr_url)
            logger.info(f"ç”¨æˆ·é—®é¢˜ç®¡ç†å™¨å·²åˆå§‹åŒ–: {asr_url}")
        else:
            logger.info("ASRæœåŠ¡æœªå¯ç”¨ï¼Œè·³è¿‡ç”¨æˆ·é—®é¢˜ç®¡ç†å™¨åˆå§‹åŒ–")
        
        # è®¾ç½®ä¸´æ—¶ç›®å½•
        self.temp_dir = temp_dir or tempfile.gettempdir()
        
        # æŠ½å¸§å‚æ•°ï¼ˆä¼˜å…ˆä½¿ç”¨ä¼ å…¥å‚æ•°ï¼Œå¦åˆ™ä»é…ç½®è¯»å–ï¼‰
        self.target_video_duration = target_video_duration or video_config.get('target_video_duration', 3.0)
        self.frames_per_second = frames_per_second or video_config.get('frames_per_second', 5)
        self.original_fps = original_fps or video_config.get('default_fps', 25.0)
        self.target_frames_per_video = int(self.target_video_duration * self.frames_per_second)
        self.frames_per_interval = int(self.original_fps / self.frames_per_second)
        
        # æ£€æµ‹å›¾åƒæ¨¡å¼ï¼šå½“target_video_durationã€frames_per_secondã€target_frames_per_videoéƒ½ä¸º1æ—¶
        self.image_mode = (self.target_video_duration == 1.0 and 
                          self.frames_per_second == 1 and 
                          self.target_frames_per_video == 1)
        
        # è®¡ç®—éœ€è¦æ”¶é›†çš„æ€»å¸§æ•°ï¼ˆ3ç§’çš„åŸå§‹å¸§æ•°ï¼‰
        self.frames_to_collect_per_video = int(self.target_video_duration * self.original_fps)
        
        # å¹¶å‘æ§åˆ¶
        self.max_concurrent_inferences = max_concurrent_inferences or vlm_config.get('max_concurrent_inferences', 3)
        
        # å›¾åƒç¼©æ”¾é…ç½®ï¼ˆå®Œå…¨ä»é…ç½®æ–‡ä»¶è¯»å–ï¼‰
        self.enable_frame_resize = video_config.get('enable_frame_resize', True)
        self.target_width = video_config.get('target_width', 640)
        self.target_height = video_config.get('target_height', 360)
        self.max_frame_size_mb = video_config.get('max_frame_size_mb', 5.0)
        self.maintain_aspect_ratio = video_config.get('maintain_aspect_ratio', True)
        
        # ç¼“å†²åŒºå’Œé˜Ÿåˆ—
        self.frame_buffer = []
        self.frame_queue = queue.Queue(maxsize=100)
        self.result_queue = queue.Queue(maxsize=20)
        
        # çº¿ç¨‹æ§åˆ¶
        self.stop_event = threading.Event()
        self.video_writer_thread = None
        
        # å¼‚æ­¥æ¨ç†æ§åˆ¶
        self.active_inference_tasks = []  # å­˜å‚¨æ´»è·ƒçš„å¼‚æ­¥ä»»åŠ¡
        self.inference_loop = None
        self.inference_event_loop = None
        
        # ğŸ†• åŒæ­¥æ¨ç†æ¨¡å¼æ§åˆ¶
        self.sync_inference_mode = vlm_config.get('sync_inference_mode', True)  # ä»é…ç½®è¯»å–ï¼Œé»˜è®¤å¯ç”¨åŒæ­¥æ¨ç†æ¨¡å¼
        self.current_inference_lock = threading.Lock()  # æ¨ç†çŠ¶æ€é”
        self.current_inference_active = False  # å½“å‰æ˜¯å¦æœ‰æ¨ç†åœ¨è¿›è¡Œ
        self.current_inference_details = None  # å½“å‰æ¨ç†çš„è¯¦ç»†ä¿¡æ¯
        self.pending_frame_data = None  # å¾…å¤„ç†çš„æœ€æ–°å¸§æ•°æ®
        self.pending_frame_lock = threading.Lock()  # å¾…å¤„ç†å¸§é”
        self.last_inference_completion_time = 0  # ä¸Šæ¬¡æ¨ç†å®Œæˆæ—¶é—´
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.total_frames_received = 0
        self.total_videos_created = 0
        self.total_images_created = 0  # æ–°å¢ï¼šå›¾åƒè®¡æ•°
        self.total_inferences_started = 0
        self.total_inferences_completed = 0
        self.start_time = None
        self.frames_resized = 0
        self.frames_invalid = 0
        
        # ğŸ†• åŒæ­¥æ¨¡å¼ç»Ÿè®¡
        self.frames_skipped_sync_mode = 0  # åŒæ­¥æ¨¡å¼ä¸‹è·³è¿‡çš„å¸§æ•°
        self.user_questions_processed = 0  # å¤„ç†çš„ç”¨æˆ·é—®é¢˜æ•°
        
        # å®éªŒæ—¥å¿—
        self.experiment_log = []
        
        # å“¨å…µæ¨¡å¼çŠ¶æ€ç®¡ç†
        self.sentry_mode_enabled = True  # é»˜è®¤å¯ç”¨å“¨å…µæ¨¡å¼
        self._sentry_mode_lock = threading.Lock()  # çº¿ç¨‹å®‰å…¨é”
        
        # åç«¯APIé…ç½®ï¼ˆç”¨äºè·å–å“¨å…µæ¨¡å¼çŠ¶æ€ï¼‰
        self.backend_api_url = "http://localhost:8080"  # é»˜è®¤åç«¯APIåœ°å€
        self._last_sentry_mode_check = 0  # ä¸Šæ¬¡æ£€æŸ¥å“¨å…µæ¨¡å¼çš„æ—¶é—´
        self._sentry_mode_check_interval = 5.0  # æ£€æŸ¥é—´éš”ï¼ˆç§’ï¼‰
        
        # ğŸ†• ç”¨æˆ·é—®é¢˜ä¸»åŠ¨ç›‘å¬æœºåˆ¶
        self.user_question_monitor_thread = None
        self.user_question_monitor_enabled = True  # æ˜¯å¦å¯ç”¨ç”¨æˆ·é—®é¢˜ä¸»åŠ¨ç›‘å¬
        self.last_question_check_time = 0  # ä¸Šæ¬¡æ£€æŸ¥ç”¨æˆ·é—®é¢˜çš„æ—¶é—´
        self.question_check_interval = 0.5  # ç”¨æˆ·é—®é¢˜æ£€æŸ¥é—´éš”ï¼ˆç§’ï¼‰
        
        logger.info(f"å¼‚æ­¥è§†é¢‘å¤„ç†å™¨åˆå§‹åŒ–:")
        if self.image_mode:
            logger.info(f"  - ğŸ–¼ï¸ å›¾åƒæ¨¡å¼å·²å¯ç”¨ï¼ˆæ¯å¸§å•ç‹¬æ¨ç†ï¼‰")
            logger.info(f"  - æ¯å¸§æ¨ç†é—´éš”: æ¯{self.frames_per_interval:.1f}å¸§æŠ½1å¸§")
        else:
            logger.info(f"  - ğŸ¬ è§†é¢‘æ¨¡å¼ï¼ˆæ‰¹é‡å¸§æ¨ç†ï¼‰")
            logger.info(f"  - ç›®æ ‡è§†é¢‘æ—¶é•¿: {self.target_video_duration}s")
            logger.info(f"  - æ¯ä¸ªè§†é¢‘æ€»å¸§æ•°: {self.target_frames_per_video}å¸§")
            logger.info(f"  - æ¯ä¸ªè§†é¢‘æ”¶é›†åŸå§‹å¸§æ•°: {self.frames_to_collect_per_video}å¸§")
        
        logger.info(f"  - æ¯ç§’æŠ½å¸§æ•°: {self.frames_per_second}å¸§")
        logger.info(f"  - åŸå§‹å¸§ç‡: {self.original_fps}fps")
        logger.info(f"  - æŠ½å¸§é—´éš”: æ¯{self.frames_per_interval:.1f}å¸§æŠ½1å¸§")
        logger.info(f"  - æœ€å¤§å¹¶å‘æ¨ç†æ•°: {self.max_concurrent_inferences}")
        logger.info(f"  - ğŸ›¡ï¸ å“¨å…µæ¨¡å¼: {'å¯ç”¨' if self.sentry_mode_enabled else 'ç¦ç”¨'}")
        logger.info(f"  - ğŸ”„ åŒæ­¥æ¨ç†æ¨¡å¼: {'å¯ç”¨' if self.sync_inference_mode else 'ç¦ç”¨'}")
        if self.enable_frame_resize:
            logger.info(f"  - å¸§ç¼©æ”¾å·²å¯ç”¨: ç›®æ ‡å°ºå¯¸ {self.target_width}x{self.target_height}")
            logger.info(f"    * æœ€å¤§å¸§å¤§å°: {self.max_frame_size_mb}MB")
            logger.info(f"    * ä¿æŒå®½é«˜æ¯”: {self.maintain_aspect_ratio}")
        else:
            logger.info(f"  - å¸§ç¼©æ”¾å·²ç¦ç”¨")

    def start(self):
        """å¯åŠ¨å¼‚æ­¥å¤„ç†"""
        self.stop_event.clear()
        self.start_time = time.time()
        
        # å¯åŠ¨ç”¨æˆ·é—®é¢˜ç®¡ç†å™¨ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        if self.question_manager:
            self.question_manager.start()
        
        # å¯åŠ¨è§†é¢‘å†™å…¥çº¿ç¨‹
        self.video_writer_thread = threading.Thread(
            target=self._video_writer_worker,
            name="VideoWriter"
        )
        self.video_writer_thread.start()
        
        # å¯åŠ¨å¼‚æ­¥æ¨ç†äº‹ä»¶å¾ªç¯çº¿ç¨‹
        self.inference_loop = threading.Thread(
            target=self._start_inference_loop,
            name="InferenceLoop"
        )
        self.inference_loop.start()
        
        # ğŸ†• å¯åŠ¨ç”¨æˆ·é—®é¢˜ç›‘å¬çº¿ç¨‹
        if self.question_manager and self.user_question_monitor_enabled:
            self.user_question_monitor_thread = threading.Thread(
                target=self._user_question_monitor_worker,
                name="UserQuestionMonitor"
            )
            self.user_question_monitor_thread.start()
            logger.info("ç”¨æˆ·é—®é¢˜ä¸»åŠ¨ç›‘å¬çº¿ç¨‹å·²å¯åŠ¨")
        
        # ç­‰å¾…äº‹ä»¶å¾ªç¯å¯åŠ¨å®Œæˆ
        max_wait = 5.0  # æœ€å¤šç­‰å¾…5ç§’
        wait_start = time.time()
        while self.inference_event_loop is None and time.time() - wait_start < max_wait:
            time.sleep(0.1)
        
        if self.inference_event_loop is None:
            logger.error("äº‹ä»¶å¾ªç¯å¯åŠ¨è¶…æ—¶")
        else:
            logger.info("å¼‚æ­¥è§†é¢‘å¤„ç†å™¨å·²å¯åŠ¨ï¼Œäº‹ä»¶å¾ªç¯å°±ç»ª")

    def stop(self):
        """åœæ­¢å¼‚æ­¥å¤„ç†"""
        self.stop_event.set()
        
        # åœæ­¢ç”¨æˆ·é—®é¢˜ç®¡ç†å™¨ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        if self.question_manager:
            self.question_manager.stop()
        
        # ğŸ†• åœæ­¢ç”¨æˆ·é—®é¢˜ç›‘å¬çº¿ç¨‹
        if self.user_question_monitor_thread:
            self.user_question_monitor_thread.join(timeout=5)
            logger.info("ç”¨æˆ·é—®é¢˜ç›‘å¬çº¿ç¨‹å·²åœæ­¢")
        
        if self.video_writer_thread:
            self.video_writer_thread.join()
            
        # åœæ­¢å¼‚æ­¥æ¨ç†å¾ªç¯
        if self.inference_event_loop and not self.inference_event_loop.is_closed():
            try:
                # ç­‰å¾…æ‰€æœ‰æ´»è·ƒä»»åŠ¡å®Œæˆ
                if self.active_inference_tasks:
                    logger.info(f"ç­‰å¾… {len(self.active_inference_tasks)} ä¸ªæ¨ç†ä»»åŠ¡å®Œæˆ...")
                    # ä½¿ç”¨çº¿ç¨‹å®‰å…¨çš„æ–¹å¼åœæ­¢äº‹ä»¶å¾ªç¯
                    future = asyncio.run_coroutine_threadsafe(self._stop_inference_loop(), self.inference_event_loop)
                    future.result(timeout=30)  # æœ€å¤šç­‰å¾…30ç§’
            except Exception as e:
                logger.warning(f"åœæ­¢æ¨ç†å¾ªç¯æ—¶å‡ºé”™: {str(e)}")
            
        if self.inference_loop:
            self.inference_loop.join(timeout=10)
            
        if self.sync_inference_mode:
            logger.info(f"å¼‚æ­¥è§†é¢‘å¤„ç†å™¨å·²åœæ­¢ï¼ˆåŒæ­¥æ¨ç†æ¨¡å¼ï¼‰ï¼Œæ€»å…±å¤„ç†{self.total_frames_received}å¸§ï¼Œ"
                       f"ç”Ÿæˆ{self.total_videos_created}ä¸ªè§†é¢‘ç‰‡æ®µï¼Œç”Ÿæˆ{self.total_images_created}ä¸ªå›¾åƒï¼Œ"
                       f"å®Œæˆ{self.total_inferences_completed}/{self.total_inferences_started}ä¸ªæ¨ç†ï¼Œ"
                       f"è·³è¿‡{self.frames_skipped_sync_mode}å¸§ï¼Œå¤„ç†{self.user_questions_processed}ä¸ªç”¨æˆ·é—®é¢˜")
        else:
            logger.info(f"å¼‚æ­¥è§†é¢‘å¤„ç†å™¨å·²åœæ­¢ï¼ˆå¼‚æ­¥æ¨ç†æ¨¡å¼ï¼‰ï¼Œæ€»å…±å¤„ç†{self.total_frames_received}å¸§ï¼Œ"
                       f"ç”Ÿæˆ{self.total_videos_created}ä¸ªè§†é¢‘ç‰‡æ®µï¼Œç”Ÿæˆ{self.total_images_created}ä¸ªå›¾åƒï¼Œ"
                       f"å®Œæˆ{self.total_inferences_completed}/{self.total_inferences_started}ä¸ªæ¨ç†")
        
        # ä¿å­˜å¹¶è‡ªåŠ¨æ’åºå®éªŒæ—¥å¿—
        self._save_and_sort_experiment_log()

    def add_frame(self, frame, timestamp: Optional[float] = None):
        """æ·»åŠ å¸§åˆ°å¤„ç†é˜Ÿåˆ—"""
        try:
            # éªŒè¯å¸§æœ‰æ•ˆæ€§
            if not validate_frame(frame):
                logger.warning("æ¥æ”¶åˆ°æ— æ•ˆå¸§ï¼Œè·³è¿‡")
                self.frames_invalid += 1
                return
            
            # è·å–å¸§ä¿¡æ¯
            frame_info = get_frame_info(frame)
            logger.debug(f"æ¥æ”¶å¸§: {frame_info['resolution']}, {frame_info['size_mb']:.2f}MB")
            
            # åº”ç”¨å›¾åƒç¼©æ”¾ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            processed_frame = frame
            if self.enable_frame_resize:
                resized_frame = smart_resize_frame(
                    frame, 
                    target_width=self.target_width,
                    target_height=self.target_height,
                    max_size_mb=self.max_frame_size_mb,
                    maintain_aspect_ratio=self.maintain_aspect_ratio
                )
                if resized_frame is not None:
                    processed_frame = resized_frame
                    self.frames_resized += 1
                    
                    # è®°å½•ç¼©æ”¾ä¿¡æ¯
                    new_info = get_frame_info(processed_frame)
                    logger.debug(f"å¸§å·²ç¼©æ”¾: {frame_info['resolution']} -> {new_info['resolution']}, "
                               f"{frame_info['size_mb']:.2f}MB -> {new_info['size_mb']:.2f}MB")
            
            frame_data = {
                'frame': processed_frame,
                'timestamp': timestamp or time.time(),
                'frame_number': self.total_frames_received + 1,
                'relative_timestamp': (timestamp or time.time()) - (self.start_time or time.time()),
                'original_info': frame_info,
                'processed_info': get_frame_info(processed_frame) if processed_frame is not frame else frame_info,
                'was_resized': processed_frame is not frame
            }
            
            # ğŸ†• åŒæ­¥æ¨ç†æ¨¡å¼æ§åˆ¶é€»è¾‘
            if self.sync_inference_mode:
                # æ£€æŸ¥æ˜¯å¦æœ‰ç”¨æˆ·é—®é¢˜ï¼ˆä¼˜å…ˆçº§æœ€é«˜ï¼‰
                has_user_question = False
                if self.question_manager:
                    has_user_question = self.question_manager.has_available_question()
                
                # æ£€æŸ¥å½“å‰æ¨ç†çŠ¶æ€
                with self.current_inference_lock:
                    inference_active = self.current_inference_active
                
                if has_user_question:
                    # ğŸš¨ ç”¨æˆ·é—®é¢˜ä¼˜å…ˆï¼Œç«‹å³å¤„ç†å¸§
                    logger.info(f"ğŸš¨ æ£€æµ‹åˆ°ç”¨æˆ·é—®é¢˜ï¼Œä¼˜å…ˆå¤„ç†å¸§ {frame_data['frame_number']}")
                    
                    # ğŸ”§ ç”¨æˆ·é—®é¢˜å¼ºåˆ¶ä¸­æ–­ï¼šå¦‚æœæœ‰æ¨ç†åœ¨è¿›è¡Œï¼Œå¼ºåˆ¶é‡ç½®æ¨ç†çŠ¶æ€
                    with self.current_inference_lock:
                        if self.current_inference_active:
                            logger.warning(f"ğŸš¨ ç”¨æˆ·é—®é¢˜å¼ºåˆ¶ä¸­æ–­å½“å‰æ¨ç†ï¼Œé‡ç½®æ¨ç†çŠ¶æ€")
                            self.current_inference_active = False
                            self.current_inference_details = None
                    
                    # ğŸ”§ ä¼˜åŒ–ï¼šå¦‚æœæœ‰ç¼“å­˜å¸§ï¼Œä¼˜å…ˆä½¿ç”¨ç¼“å­˜å¸§å¤„ç†ç”¨æˆ·é—®é¢˜ï¼ˆç¼“å­˜å¸§å¯èƒ½æ›´æ¥è¿‘é—®é¢˜æå‡ºçš„æ—¶é—´ï¼‰
                    with self.pending_frame_lock:
                        if self.pending_frame_data is not None:
                            # ä½¿ç”¨ç¼“å­˜å¸§å¤„ç†ç”¨æˆ·é—®é¢˜ï¼Œå½“å‰å¸§æˆä¸ºæ–°çš„ç¼“å­˜å¸§
                            pending_frame = self.pending_frame_data
                            self.pending_frame_data = frame_data  # å½“å‰å¸§æˆä¸ºæ–°çš„ç¼“å­˜å¸§
                            logger.info(f"ğŸš¨ ä½¿ç”¨ç¼“å­˜å¸§ {pending_frame['frame_number']} å¤„ç†ç”¨æˆ·é—®é¢˜ï¼Œå½“å‰å¸§ {frame_data['frame_number']} æˆä¸ºæ–°ç¼“å­˜")
                            self._add_frame_to_queue(pending_frame)
                            self.user_questions_processed += 1
                            return  # å½“å‰å¸§å·²ç¼“å­˜ï¼Œä¸å¢åŠ total_frames_received
                        else:
                            # æ²¡æœ‰ç¼“å­˜å¸§ï¼Œç›´æ¥ä½¿ç”¨å½“å‰å¸§å¤„ç†ç”¨æˆ·é—®é¢˜
                            self._add_frame_to_queue(frame_data)
                            self.user_questions_processed += 1
                elif not inference_active:
                    # æ²¡æœ‰æ¨ç†åœ¨è¿›è¡Œï¼Œå¯ä»¥å¤„ç†æ–°å¸§
                    logger.debug(f"âœ… æ¨ç†ç©ºé—²ï¼Œå¤„ç†å¸§ {frame_data['frame_number']}")
                    
                    # ğŸ”§ ä¿®å¤ï¼šæ£€æŸ¥æ˜¯å¦æœ‰ç¼“å­˜å¸§éœ€è¦å…ˆå¤„ç†
                    with self.pending_frame_lock:
                        if self.pending_frame_data is not None:
                            # æœ‰ç¼“å­˜å¸§ï¼Œå¤„ç†ç¼“å­˜å¸§ï¼Œå½“å‰å¸§æˆä¸ºæ–°çš„ç¼“å­˜å¸§
                            pending_frame = self.pending_frame_data
                            self.pending_frame_data = frame_data  # å½“å‰å¸§æˆä¸ºæ–°çš„ç¼“å­˜å¸§
                            logger.info(f"ğŸ”„ å¤„ç†ç¼“å­˜å¸§ {pending_frame['frame_number']}ï¼Œå½“å‰å¸§ {frame_data['frame_number']} æˆä¸ºæ–°ç¼“å­˜")
                            self._add_frame_to_queue(pending_frame)
                            return  # å½“å‰å¸§å·²ç¼“å­˜ï¼Œä¸å¢åŠ total_frames_received
                        else:
                            # æ²¡æœ‰ç¼“å­˜å¸§ï¼Œç›´æ¥å¤„ç†å½“å‰å¸§
                            self._add_frame_to_queue(frame_data)
                else:
                    # ğŸ”§ ä¿®å¤ï¼šæœ‰æ¨ç†åœ¨è¿›è¡Œï¼Œå§‹ç»ˆç»´æŠ¤æœ€æ–°çš„å¾…å¤„ç†å¸§ï¼ˆä¿ç•™æœ€æ–°å¸§ï¼‰
                    with self.pending_frame_lock:
                        if self.pending_frame_data is None:
                            logger.debug(f"â³ æ¨ç†è¿›è¡Œä¸­ï¼Œç¼“å­˜å¸§ {frame_data['frame_number']}")
                        else:
                            logger.debug(f"â³ æ¨ç†è¿›è¡Œä¸­ï¼Œæ›´æ–°ç¼“å­˜å¸§ {self.pending_frame_data['frame_number']} -> {frame_data['frame_number']}")
                            self.frames_skipped_sync_mode += 1
                        self.pending_frame_data = frame_data
                    return  # ä¸å¢åŠ total_frames_receivedï¼Œå› ä¸ºå¸§è¢«ç¼“å­˜è€Œä¸æ˜¯å¤„ç†
            else:
                # å¼‚æ­¥æ¨¡å¼ï¼Œç›´æ¥æ·»åŠ åˆ°é˜Ÿåˆ—
                self._add_frame_to_queue(frame_data)
            
            self.total_frames_received += 1
            
            if self.total_frames_received % 50 == 0:
                if self.sync_inference_mode:
                    logger.info(f"å·²æ¥æ”¶ {self.total_frames_received} å¸§ "
                              f"(ç¼©æ”¾: {self.frames_resized}, æ— æ•ˆ: {self.frames_invalid}, "
                              f"åŒæ­¥è·³è¿‡: {self.frames_skipped_sync_mode}, ç”¨æˆ·é—®é¢˜: {self.user_questions_processed})")
                else:
                    logger.info(f"å·²æ¥æ”¶ {self.total_frames_received} å¸§ "
                              f"(ç¼©æ”¾: {self.frames_resized}, æ— æ•ˆ: {self.frames_invalid})")
                
        except Exception as e:
            logger.error(f"æ·»åŠ å¸§å¤±è´¥: {str(e)}")
    
    def _add_frame_to_queue(self, frame_data: Dict):
        """å°†å¸§æ•°æ®æ·»åŠ åˆ°å¤„ç†é˜Ÿåˆ—"""
        try:
            self.frame_queue.put(frame_data, timeout=1)
        except queue.Full:
            logger.warning("å¸§é˜Ÿåˆ—å·²æ»¡ï¼Œä¸¢å¼ƒå¸§")

    def get_result(self, timeout: float = 1.0) -> Optional[Dict]:
        """è·å–æ¨ç†ç»“æœ"""
        try:
            return self.result_queue.get(timeout=timeout)
        except queue.Empty:
            return None

    def _start_inference_loop(self):
        """åœ¨å•ç‹¬çº¿ç¨‹ä¸­å¯åŠ¨å¼‚æ­¥äº‹ä»¶å¾ªç¯"""
        self.inference_event_loop = asyncio.new_event_loop()
        asyncio.set_event_loop(self.inference_event_loop)
        
        logger.info("æ¨ç†äº‹ä»¶å¾ªç¯å·²åˆ›å»º")
        
        try:
            self.inference_event_loop.run_until_complete(self._inference_manager())
        except Exception as e:
            logger.error(f"æ¨ç†äº‹ä»¶å¾ªç¯é”™è¯¯: {str(e)}")
        finally:
            try:
                # æ¸…ç†äº‹ä»¶å¾ªç¯
                pending = asyncio.all_tasks(self.inference_event_loop)
                if pending:
                    logger.info(f"å–æ¶ˆ {len(pending)} ä¸ªå¾…å¤„ç†ä»»åŠ¡")
                    for task in pending:
                        task.cancel()
                    # ç­‰å¾…ä»»åŠ¡å–æ¶ˆå®Œæˆ
                    self.inference_event_loop.run_until_complete(
                        asyncio.gather(*pending, return_exceptions=True)
                    )
            except Exception as e:
                logger.warning(f"æ¸…ç†äº‹ä»¶å¾ªç¯æ—¶å‡ºé”™: {str(e)}")
            finally:
                self.inference_event_loop.close()

    async def _stop_inference_loop(self):
        """åœæ­¢å¼‚æ­¥æ¨ç†å¾ªç¯"""
        # ç­‰å¾…æ‰€æœ‰æ´»è·ƒä»»åŠ¡å®Œæˆ
        if self.active_inference_tasks:
            completed_tasks = []
            for task in self.active_inference_tasks:
                if not task.done():
                    try:
                        result = await asyncio.wait_for(task, timeout=10.0)
                        completed_tasks.append(result)
                    except asyncio.TimeoutError:
                        logger.warning("æ¨ç†ä»»åŠ¡è¶…æ—¶ï¼Œå¼ºåˆ¶å–æ¶ˆ")
                        task.cancel()
                    except Exception as e:
                        logger.warning(f"æ¨ç†ä»»åŠ¡å¼‚å¸¸: {str(e)}")
            logger.info(f"å®Œæˆäº† {len(completed_tasks)} ä¸ªæ¨ç†ä»»åŠ¡")

    async def _inference_manager(self):
        """å¼‚æ­¥æ¨ç†ç®¡ç†å™¨"""
        logger.info("æ¨ç†ç®¡ç†å™¨å¯åŠ¨")
        while not self.stop_event.is_set():
            try:
                # æ¸…ç†å·²å®Œæˆçš„ä»»åŠ¡
                before_count = len(self.active_inference_tasks)
                self.active_inference_tasks = [
                    task for task in self.active_inference_tasks 
                    if not task.done()
                ]
                after_count = len(self.active_inference_tasks)
                
                if before_count != after_count:
                    logger.debug(f"æ¸…ç†äº† {before_count - after_count} ä¸ªå·²å®Œæˆä»»åŠ¡ï¼Œå‰©ä½™ {after_count} ä¸ª")
                
                # çŸ­æš‚ä¼‘çœ é¿å…å¿™ç­‰å¾…
                await asyncio.sleep(0.1)
                
            except Exception as e:
                logger.error(f"æ¨ç†ç®¡ç†å™¨é”™è¯¯: {str(e)}")
                await asyncio.sleep(1)  # å‡ºé”™æ—¶ç­‰å¾…æ›´é•¿æ—¶é—´
        
        logger.info("æ¨ç†ç®¡ç†å™¨åœæ­¢")

    def _submit_inference_task(self, media_info: Dict):
        """æäº¤å¼‚æ­¥æ¨ç†ä»»åŠ¡"""
        if self.inference_event_loop and not self.inference_event_loop.is_closed() and len(self.active_inference_tasks) < self.max_concurrent_inferences:
            try:
                # ğŸ†• åŒæ­¥æ¨ç†æ¨¡å¼ï¼šè®¾ç½®æ¨ç†çŠ¶æ€
                if self.sync_inference_mode:
                    with self.current_inference_lock:
                        if self.current_inference_active:
                            logger.warning("åŒæ­¥æ¨ç†æ¨¡å¼ä¸‹å°è¯•æäº¤æ–°ä»»åŠ¡ï¼Œä½†å½“å‰å·²æœ‰æ¨ç†åœ¨è¿›è¡Œ")
                            return
                        self.current_inference_active = True
                        self.current_inference_details = {
                            'media_path': media_info.get('media_path', media_info.get('video_path', media_info.get('image_path', 'unknown'))),
                            'media_type': media_info.get('media_type', 'video'),
                            'start_time': time.time(),
                            'frame_number': media_info.get('frame_number', 'N/A')
                        }
                        logger.info(f"ğŸ”„ åŒæ­¥æ¨ç†å¼€å§‹: {os.path.basename(self.current_inference_details['media_path'])} "
                                  f"(å¸§å·: {self.current_inference_details['frame_number']})")
                
                task = asyncio.run_coroutine_threadsafe(
                    self._inference_worker_async(media_info),
                    self.inference_event_loop
                )
                self.active_inference_tasks.append(task)
                self.total_inferences_started += 1
                
                # è·å–åª’ä½“è·¯å¾„ï¼Œå…¼å®¹å›¾åƒå’Œè§†é¢‘æ¨¡å¼
                media_path = media_info.get('media_path', media_info.get('video_path', media_info.get('image_path', 'unknown')))
                media_type = media_info.get('media_type', 'video')
                
                if not self.sync_inference_mode:  # å¼‚æ­¥æ¨¡å¼æ‰æ‰“å°è¯¦ç»†ä¿¡æ¯
                    logger.info(f"æäº¤å¼‚æ­¥æ¨ç†ä»»åŠ¡: {os.path.basename(media_path)} ({media_type})")
                    logger.info(f"  - å½“å‰å¹¶å‘æ•°: {len(self.active_inference_tasks)}/{self.max_concurrent_inferences}")
                    logger.info(f"  - æ€»å¯åŠ¨æ•°: {self.total_inferences_started}")
            except Exception as e:
                logger.error(f"æäº¤æ¨ç†ä»»åŠ¡å¤±è´¥: {str(e)}")
                # ğŸ†• åŒæ­¥æ¨ç†æ¨¡å¼ï¼šå‡ºé”™æ—¶é‡ç½®çŠ¶æ€
                if self.sync_inference_mode:
                    with self.current_inference_lock:
                        self.current_inference_active = False
                        self.current_inference_details = None
        else:
            if self.inference_event_loop is None:
                logger.warning("äº‹ä»¶å¾ªç¯æœªå°±ç»ªï¼Œè·³è¿‡æ¨ç†")
            elif self.inference_event_loop.is_closed():
                logger.warning("äº‹ä»¶å¾ªç¯å·²å…³é—­ï¼Œè·³è¿‡æ¨ç†")
            elif len(self.active_inference_tasks) >= self.max_concurrent_inferences:
                if not self.sync_inference_mode:  # å¼‚æ­¥æ¨¡å¼æ‰è­¦å‘Š
                    logger.warning(f"æ¨ç†ä»»åŠ¡é˜Ÿåˆ—å·²æ»¡ ({len(self.active_inference_tasks)}/{self.max_concurrent_inferences})ï¼Œè·³è¿‡æ¨ç†")
            else:
                logger.warning("æ¨ç†ä»»åŠ¡æäº¤å¤±è´¥ï¼ŒåŸå› æœªçŸ¥")

    async def _inference_worker_async(self, media_info: Dict):
        """çœŸæ­£çš„å¼‚æ­¥æ¨ç†å·¥ä½œå‡½æ•°"""
        try:
            # è®°å½•æ¨ç†å¼€å§‹æ—¶é—´
            inference_start_time = time.time()
            inference_start_timestamp = datetime.now().isoformat()
            
            media_type = media_info.get('media_type', 'video')
            media_path = media_info.get('media_path', media_info.get('video_path', media_info.get('image_path')))
            
            # è·å–å½“å‰ç”¨æˆ·é—®é¢˜ï¼ˆåŸå­æ€§åˆ†é…ï¼‰
            user_question = None
            task_id = None
            if self.question_manager:
                user_question, task_id = self.question_manager.acquire_question()
            
            logger.info(f"å¼€å§‹å¼‚æ­¥VLMæ¨ç†: {os.path.basename(media_path)} ({media_type})")
            logger.info(f"  - æ¨ç†å¼€å§‹æ—¶é—´: {inference_start_timestamp}")
            if user_question and task_id:
                logger.info(f"  - ç”¨æˆ·é—®é¢˜: {user_question}")
                logger.info(f"  - ä»»åŠ¡ID: {task_id}")
            
            if media_type == 'image':
                logger.info(f"  - å›¾åƒå¸§å·: {media_info.get('frame_number', 'N/A')}")
                logger.info(f"  - å›¾åƒæ—¶é—´æˆ³: {media_info.get('relative_timestamp', 'N/A'):.2f}s")
                
                # ä»åç«¯åŒæ­¥å“¨å…µæ¨¡å¼çŠ¶æ€
                self._update_sentry_mode_from_backend()
                
                # è·å–å½“å‰å“¨å…µæ¨¡å¼çŠ¶æ€
                enable_camera_control = self.get_sentry_mode()
                logger.info(f"  - å“¨å…µæ¨¡å¼: {'å¯ç”¨' if enable_camera_control else 'ç¦ç”¨'}")
                
                # æ‰§è¡Œå¼‚æ­¥å›¾åƒæ¨ç†
                result = await self.vlm_client.analyze_image_async(
                    media_path, 
                    prompt=None,  # ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„é»˜è®¤æç¤ºè¯
                    user_question=user_question,
                    enable_camera_control=enable_camera_control  # ä¼ é€’å“¨å…µæ¨¡å¼çŠ¶æ€
                )
            else:
                logger.info(f"  - æºè§†é¢‘æ—¶é—´èŒƒå›´: {media_info.get('start_relative_timestamp', 'N/A'):.2f}s - {media_info.get('end_relative_timestamp', 'N/A'):.2f}s")
                
                # æ‰§è¡Œå¼‚æ­¥è§†é¢‘æ¨ç†ï¼ˆæš‚æ—¶ä¸æ”¯æŒç”¨æˆ·é—®é¢˜ï¼Œå› ä¸ºè§†é¢‘åˆ†ææ–¹æ³•è¿˜æ²¡ä¿®æ”¹ï¼‰
                result = await self.vlm_client.analyze_video_async(
                    media_path, 
                    prompt=None,  # ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„é»˜è®¤æç¤ºè¯
                    fps=2
                )
            
            # è®°å½•æ¨ç†ç»“æŸæ—¶é—´
            inference_end_time = time.time()
            inference_end_timestamp = datetime.now().isoformat()
            inference_duration = inference_end_time - inference_start_time
            
            logger.info(f"å¼‚æ­¥VLMæ¨ç†å®Œæˆ: {os.path.basename(media_path)} ({media_type})")
            logger.info(f"  - æ¨ç†ç»“æŸæ—¶é—´: {inference_end_timestamp}")
            logger.info(f"  - æ¨ç†è€—æ—¶: {inference_duration:.2f}s")
            logger.info(f"  - ç»“æœé•¿åº¦: {len(result) if result else 0}å­—ç¬¦")
            
            # å°†ç»“æœæ”¾å…¥ç»“æœé˜Ÿåˆ—
            result_data = {
                'media_path': media_path,
                'media_type': media_type,
                'result': result,
                'media_info': media_info,
                'inference_start_time': inference_start_time,
                'inference_end_time': inference_end_time,
                'inference_start_timestamp': inference_start_timestamp,
                'inference_end_timestamp': inference_end_timestamp,
                'inference_duration': inference_duration,
                'result_received_at': time.time(),
                'user_question': user_question,  # æ·»åŠ ç”¨æˆ·é—®é¢˜
                'task_id': task_id,  # æ·»åŠ ä»»åŠ¡ID
                'raw_result': result  # æ·»åŠ åŸå§‹ç»“æœï¼ˆå…¼å®¹æ€§ï¼‰
            }
            
            # ä¸ºäº†å‘åå…¼å®¹ï¼Œä¿ç•™video_pathå­—æ®µ
            if 'video_path' not in result_data:
                result_data['video_path'] = media_path
            if 'video_info' not in result_data:
                result_data['video_info'] = media_info
            
            # è®°å½•åˆ°å®éªŒæ—¥å¿—
            self.experiment_log.append(result_data.copy())
            self.total_inferences_completed += 1
            
            # ä¿å­˜æ¨ç†ç»“æœåˆ°åª’ä½“è¯¦æƒ…æ–‡ä»¶å¤¹
            self._save_inference_result_to_details(result_data)
            
            # å¦‚æœæœ‰ç”¨æˆ·é—®é¢˜ï¼Œé‡Šæ”¾é—®é¢˜ï¼ˆæ— è®ºæ¨ç†æ˜¯å¦æˆåŠŸï¼‰
            if user_question and task_id and self.question_manager:
                success = result is not None and len(str(result).strip()) > 0
                self.question_manager.release_question(task_id, success)
                if success:
                    logger.info(f"æ¨ç†æˆåŠŸï¼Œä»»åŠ¡ {task_id} å·²é‡Šæ”¾ç”¨æˆ·é—®é¢˜: {user_question}")
                else:
                    logger.warning(f"æ¨ç†å¤±è´¥ï¼Œä»»åŠ¡ {task_id} å·²é‡Šæ”¾ç”¨æˆ·é—®é¢˜: {user_question}")
            
            try:
                self.result_queue.put(result_data, timeout=1)
                logger.info(f"å¼‚æ­¥æ¨ç†ç»“æœå·²å…¥é˜Ÿ: {os.path.basename(media_path)} ({media_type})")
            except queue.Full:
                logger.warning("ç»“æœé˜Ÿåˆ—å·²æ»¡ï¼Œä¸¢å¼ƒç»“æœ")
                
        except Exception as e:
            logger.error(f"å¼‚æ­¥æ¨ç†å¤±è´¥: {str(e)}")
            self.total_inferences_completed += 1  # å³ä½¿å¤±è´¥ä¹Ÿè®¡å…¥å®Œæˆæ•°
            
            # å¦‚æœæœ‰ç”¨æˆ·é—®é¢˜ï¼Œç¡®ä¿é‡Šæ”¾é—®é¢˜ï¼ˆæ¨ç†å¤±è´¥ï¼‰
            if 'user_question' in locals() and 'task_id' in locals() and user_question and task_id and self.question_manager:
                self.question_manager.release_question(task_id, success=False)
                logger.warning(f"æ¨ç†å¼‚å¸¸ï¼Œä»»åŠ¡ {task_id} å·²é‡Šæ”¾ç”¨æˆ·é—®é¢˜: {user_question}")
        
        finally:
            # ğŸ†• åŒæ­¥æ¨ç†æ¨¡å¼ï¼šæ¨ç†å®Œæˆåçš„å¤„ç†
            if self.sync_inference_mode:
                with self.current_inference_lock:
                    if self.current_inference_active and self.current_inference_details:
                        inference_duration = time.time() - self.current_inference_details['start_time']
                        logger.info(f"âœ… åŒæ­¥æ¨ç†å®Œæˆ: {os.path.basename(self.current_inference_details['media_path'])} "
                                  f"(å¸§å·: {self.current_inference_details['frame_number']}, è€—æ—¶: {inference_duration:.2f}s)")
                        
                        self.current_inference_active = False
                        self.current_inference_details = None
                        self.last_inference_completion_time = time.time()
                
                # ğŸ”§ ä¿®å¤ï¼šä¸å†è°ƒç”¨_process_pending_frameï¼Œé¿å…å¤„ç†è¿‡æ—¶çš„ç¼“å­˜å¸§
                # è®©add_frameæ–¹æ³•ä¸­çš„æ–°å¸§æ£€æµ‹åˆ°æ¨ç†ç©ºé—²åè‡ªç„¶å¤„ç†æœ€æ–°å¸§
                logger.debug("ğŸ”„ åŒæ­¥æ¨ç†å®Œæˆï¼Œç­‰å¾…æ–°çš„å®æ—¶å¸§...")
            
        # æ³¨æ„ï¼šä¸åˆ é™¤ä¸´æ—¶æ–‡ä»¶ï¼Œä¿ç•™ç”¨äºè°ƒè¯•
        logger.debug(f"ä¿ç•™åª’ä½“æ–‡ä»¶ç”¨äºè°ƒè¯•: {media_path}")

    def _process_pending_frame(self):
        """
        å¤„ç†å¾…å¤„ç†çš„å¸§ï¼ˆåŒæ­¥æ¨ç†æ¨¡å¼ï¼‰
        
        âš ï¸ å·²åºŸå¼ƒï¼šæ­¤æ–¹æ³•å­˜åœ¨æ—¶åºç«äº‰é—®é¢˜ï¼Œä¼šå¯¼è‡´å¤„ç†è¿‡æ—¶çš„ç¼“å­˜å¸§
        ç°åœ¨æ”¹ä¸ºè®©add_frameæ–¹æ³•ç›´æ¥å¤„ç†æœ€æ–°çš„å®æ—¶å¸§
        """
        logger.warning("âš ï¸ _process_pending_frameæ–¹æ³•å·²åºŸå¼ƒï¼Œä¸åº”è¢«è°ƒç”¨")
        # ä¿ç•™æ–¹æ³•ä½“ä»¥é¿å…ç ´åç°æœ‰è°ƒç”¨ï¼Œä½†ä¸æ‰§è¡Œä»»ä½•æ“ä½œ
        pass

    def _sample_frames_by_time(self, frames_data: List[Dict]) -> List[Dict]:
        """
        æŒ‰æ—¶é—´é—´éš”æŠ½å¸§ï¼šæ¯ç§’æŠ½å–æŒ‡å®šæ•°é‡çš„å¸§
        
        Args:
            frames_data: å¸§æ•°æ®åˆ—è¡¨
            
        Returns:
            æŠ½å–çš„å¸§æ•°æ®åˆ—è¡¨
        """
        if len(frames_data) < self.target_frames_per_video:
            logger.warning(f"å¸§æ•°ä¸è¶³: {len(frames_data)} < {self.target_frames_per_video}")
            return frames_data
        
        sampled_frames = []
        
        # è®¡ç®—æ—¶é—´èŒƒå›´
        start_time = frames_data[0]['relative_timestamp']
        end_time = frames_data[-1]['relative_timestamp']
        total_duration = end_time - start_time
        
        logger.info(f"å¼€å§‹æŠ½å¸§: æ€»å¸§æ•°={len(frames_data)}, æ—¶é—´èŒƒå›´={start_time:.2f}s-{end_time:.2f}s")
        
        # æŒ‰æ—¶é—´å‡åŒ€åˆ†å¸ƒæŠ½å¸§
        for second in range(int(self.target_video_duration)):
            # è®¡ç®—è¿™ä¸€ç§’çš„æ—¶é—´èŒƒå›´
            second_start = start_time + second
            second_end = second_start + 1.0
            
            # æ‰¾åˆ°è¿™ä¸€ç§’å†…çš„æ‰€æœ‰å¸§
            second_frames = [f for f in frames_data 
                           if second_start <= f['relative_timestamp'] < second_end]
            
            logger.debug(f"ç¬¬{second+1}ç§’ ({second_start:.2f}s-{second_end:.2f}s): æ‰¾åˆ°{len(second_frames)}å¸§")
            
            if len(second_frames) >= self.frames_per_second:
                # ä»è¿™ä¸€ç§’çš„å¸§ä¸­å‡åŒ€æŠ½å–æŒ‡å®šæ•°é‡çš„å¸§
                indices = np.linspace(0, len(second_frames) - 1, self.frames_per_second, dtype=int)
                for idx in indices:
                    sampled_frames.append(second_frames[idx])
                    logger.debug(f"  æŠ½å–å¸§: ç´¢å¼•{idx}, å¸§å·{second_frames[idx]['frame_number']}")
            elif second_frames:
                # å¦‚æœè¿™ä¸€ç§’çš„å¸§æ•°ä¸è¶³ï¼Œå…¨éƒ¨ä½¿ç”¨
                sampled_frames.extend(second_frames)
                logger.debug(f"  ä½¿ç”¨å…¨éƒ¨{len(second_frames)}å¸§")
        
        # å¦‚æœæŠ½å–çš„å¸§æ•°ä¸è¶³ï¼Œä»å‰©ä½™å¸§ä¸­è¡¥å……
        if len(sampled_frames) < self.target_frames_per_video:
            remaining_needed = self.target_frames_per_video - len(sampled_frames)
            used_frame_numbers = {f['frame_number'] for f in sampled_frames}
            remaining_frames = [f for f in frames_data if f['frame_number'] not in used_frame_numbers]
            
            if remaining_frames:
                step = max(1, len(remaining_frames) // remaining_needed)
                additional_frames = remaining_frames[::step][:remaining_needed]
                sampled_frames.extend(additional_frames)
                logger.debug(f"è¡¥å……{len(additional_frames)}å¸§")
        
        # æŒ‰æ—¶é—´æˆ³æ’åº
        sampled_frames.sort(key=lambda x: x['timestamp'])
        
        # è®°å½•æŠ½å¸§è¯¦æƒ…
        if sampled_frames:
            original_time_range = (frames_data[0]['relative_timestamp'], frames_data[-1]['relative_timestamp'])
            sampled_time_range = (sampled_frames[0]['relative_timestamp'], sampled_frames[-1]['relative_timestamp'])
            
            logger.info(f"æŠ½å¸§å®Œæˆ: {len(frames_data)}å¸§ -> {len(sampled_frames)}å¸§")
            logger.info(f"åŸå§‹æ—¶é—´èŒƒå›´: {original_time_range[0]:.2f}s - {original_time_range[1]:.2f}s")
            logger.info(f"æŠ½å–æ—¶é—´èŒƒå›´: {sampled_time_range[0]:.2f}s - {sampled_time_range[1]:.2f}s")
            logger.info(f"æŠ½å–å¸§è¯¦æƒ…: {[f['frame_number'] for f in sampled_frames]}")
        else:
            logger.error("æŠ½å¸§å¤±è´¥ï¼šæ²¡æœ‰æŠ½å–åˆ°ä»»ä½•å¸§")
        
        return sampled_frames

    def _video_writer_worker(self):
        """è§†é¢‘å†™å…¥å·¥ä½œçº¿ç¨‹"""
        try:
            while not self.stop_event.is_set():
                try:
                    frame_data = self.frame_queue.get(timeout=1)
                except queue.Empty:
                    continue
                
                if self.image_mode:
                    # å›¾åƒæ¨¡å¼ï¼šç›´æ¥å¤„ç†å•å¸§
                    self._process_single_frame(frame_data)
                else:
                    # è§†é¢‘æ¨¡å¼ï¼šæ”¶é›†å¸§å¹¶åˆ›å»ºè§†é¢‘
                    self._process_video_frames(frame_data)
                    
        except Exception as e:
            logger.error(f"è§†é¢‘å†™å…¥çº¿ç¨‹é”™è¯¯: {str(e)}")
    
    def _process_single_frame(self, frame_data: Dict):
        """å¤„ç†å•å¸§å›¾åƒï¼ˆå›¾åƒæ¨¡å¼ï¼‰"""
        try:
            # æ£€æŸ¥æ˜¯å¦éœ€è¦æŠ½å¸§ï¼ˆæŒ‰é—´éš”ï¼‰
            if self.total_frames_received % self.frames_per_interval != 0:
                return
            
            # åˆ›å»ºå›¾åƒæ–‡ä»¶
            image_creation_start = time.time()
            image_path = self._create_image_from_frame(frame_data)
            image_creation_time = time.time() - image_creation_start
            
            if image_path:
                # ä¿å­˜å›¾åƒè¯¦æƒ…åˆ°å®éªŒç›®å½•
                image_info = self._save_image_details(frame_data, image_path, image_creation_time)
                
                # ä½¿ç”¨ä¿å­˜åçš„å›¾åƒè·¯å¾„
                final_image_path = image_info.get('image_path', image_path)
                
                image_info.update({
                    'media_path': final_image_path,  # ç»Ÿä¸€ä½¿ç”¨media_pathå­—æ®µ
                    'video_path': final_image_path,  # ä¸ºäº†å‘åå…¼å®¹ï¼Œæ·»åŠ video_pathå­—æ®µ
                    'media_type': 'image',
                    'frame_count': 1,
                    'timestamp': frame_data['timestamp'],
                    'relative_timestamp': frame_data['relative_timestamp'],
                    'frame_number': frame_data['frame_number'],
                    'image_creation_time': image_creation_time,
                    'image_creation_timestamp': datetime.fromtimestamp(image_creation_start).isoformat(),
                    'created_at': time.time()
                })
                
                self.total_images_created += 1
                logger.info(f"å›¾åƒå·²ç”Ÿæˆ: {os.path.basename(image_path)}")
                logger.info(f"  - å¸§å·: {frame_data['frame_number']}")
                logger.info(f"  - æ—¶é—´æˆ³: {frame_data['relative_timestamp']:.2f}s")
                logger.info(f"  - å›¾åƒåˆ›å»ºè€—æ—¶: {image_creation_time:.3f}s")
                
                # ç«‹å³æäº¤å¼‚æ­¥æ¨ç†ä»»åŠ¡
                self._submit_inference_task(image_info)
                
        except Exception as e:
            logger.error(f"å¤„ç†å•å¸§å›¾åƒå¤±è´¥: {str(e)}")
    
    def _process_video_frames(self, frame_data: Dict):
        """å¤„ç†è§†é¢‘å¸§ï¼ˆè§†é¢‘æ¨¡å¼ï¼‰"""
        # æ·»åŠ åˆ°ç¼“å†²åŒº
        self.frame_buffer.append(frame_data)
        
        # å½“ç¼“å†²åŒºè¾¾åˆ°ä¸€ä¸ªè§†é¢‘æ‰€éœ€çš„å¸§æ•°æ—¶ï¼Œè¿›è¡ŒæŠ½å¸§å¹¶åˆ›å»ºè§†é¢‘
        if len(self.frame_buffer) >= self.frames_to_collect_per_video:
            # æŠ½å–å¸§
            sampled_frames = self._sample_frames_by_time(self.frame_buffer[:self.frames_to_collect_per_video])
            
            # åˆ›å»ºè§†é¢‘
            video_creation_start = time.time()
            video_path = self._create_video_from_frames(sampled_frames)
            video_creation_time = time.time() - video_creation_start
            
            if video_path:
                # è®¡ç®—æ—¶é—´èŒƒå›´
                start_timestamp = sampled_frames[0]['timestamp']
                end_timestamp = sampled_frames[-1]['timestamp']
                start_relative = sampled_frames[0]['relative_timestamp']
                end_relative = sampled_frames[-1]['relative_timestamp']
                
                # ä¿å­˜æŠ½å¸§è¯¦æƒ…åˆ°å®éªŒç›®å½•
                video_info = self._save_video_details(sampled_frames, video_path, video_creation_time)
                
                # ä½¿ç”¨ä¿å­˜åçš„è§†é¢‘è·¯å¾„ï¼ˆå¯èƒ½å·²è¢«ç§»åŠ¨åˆ°detailsæ–‡ä»¶å¤¹ï¼‰
                final_video_path = video_info.get('video_path', video_path)
                
                video_info.update({
                    'media_path': final_video_path,  # ç»Ÿä¸€ä½¿ç”¨media_pathå­—æ®µ
                    'media_type': 'video',
                    'frame_count': len(sampled_frames),
                    'start_timestamp': start_timestamp,
                    'end_timestamp': end_timestamp,
                    'start_relative_timestamp': start_relative,
                    'end_relative_timestamp': end_relative,
                    'duration': end_timestamp - start_timestamp,
                    'relative_duration': end_relative - start_relative,
                    'original_frame_range': (
                        sampled_frames[0]['frame_number'],
                        sampled_frames[-1]['frame_number']
                    ),
                    'video_creation_time': video_creation_time,
                    'video_creation_timestamp': datetime.fromtimestamp(video_creation_start).isoformat(),
                    'created_at': time.time()
                })
                
                self.total_videos_created += 1
                logger.info(f"è§†é¢‘ç‰‡æ®µå·²ç”Ÿæˆ: {os.path.basename(video_path)}")
                logger.info(f"  - å¸§èŒƒå›´: {video_info['original_frame_range']}")
                logger.info(f"  - æºè§†é¢‘æ—¶é—´: {start_relative:.2f}s - {end_relative:.2f}s")
                logger.info(f"  - è§†é¢‘åˆ›å»ºè€—æ—¶: {video_creation_time:.3f}s")
                
                # ç«‹å³æäº¤å¼‚æ­¥æ¨ç†ä»»åŠ¡
                self._submit_inference_task(video_info)
            
            # ç§»é™¤å·²å¤„ç†çš„å¸§ï¼Œä¿ç•™25%é‡å ä»¥ç¡®ä¿è¿ç»­æ€§
            overlap_frames = self.frames_to_collect_per_video // 4
            self.frame_buffer = self.frame_buffer[self.frames_to_collect_per_video - overlap_frames:]
    
    def _create_image_from_frame(self, frame_data: Dict) -> Optional[str]:
        """ä»å•å¸§åˆ›å»ºå›¾åƒæ–‡ä»¶"""
        try:
            # åˆ›å»ºå›¾åƒæ–‡ä»¶è·¯å¾„
            timestamp = datetime.fromtimestamp(frame_data['timestamp'])
            image_name = f"frame_{frame_data['frame_number']:06d}_{timestamp.strftime('%H%M%S_%f')[:-3]}.jpg"
            image_path = os.path.join(self.temp_dir, image_name)
            
            # ç¡®ä¿ç›®å½•å­˜åœ¨
            os.makedirs(os.path.dirname(image_path), exist_ok=True)
            
            # ä¿å­˜å›¾åƒ
            success = cv2.imwrite(image_path, frame_data['frame'])
            
            if success:
                logger.debug(f"å›¾åƒå·²ä¿å­˜: {image_path}")
                return image_path
            else:
                logger.error(f"ä¿å­˜å›¾åƒå¤±è´¥: {image_path}")
                return None
                
        except Exception as e:
            logger.error(f"åˆ›å»ºå›¾åƒæ–‡ä»¶å¤±è´¥: {str(e)}")
            return None
    
    def _save_image_details(self, frame_data: Dict, image_path: str, creation_time: float) -> Dict:
        """ä¿å­˜å›¾åƒè¯¦æƒ…åˆ°å®éªŒç›®å½•"""
        try:
            # åˆ›å»ºå›¾åƒè¯¦æƒ…ç›®å½•
            image_name = os.path.splitext(os.path.basename(image_path))[0]
            details_dir = os.path.join(self.temp_dir, f"{image_name}_details")
            os.makedirs(details_dir, exist_ok=True)
            
            # å°†å›¾åƒæ–‡ä»¶ç§»åŠ¨åˆ°detailsæ–‡ä»¶å¤¹å†…
            new_image_path = os.path.join(details_dir, os.path.basename(image_path))
            if os.path.exists(image_path) and image_path != new_image_path:
                import shutil
                shutil.move(image_path, new_image_path)
                logger.debug(f"å›¾åƒæ–‡ä»¶å·²ç§»åŠ¨åˆ°: {new_image_path}")
            else:
                new_image_path = image_path
            
            # è·å–å›¾åƒå°ºå¯¸ä¿¡æ¯
            original_width, original_height = get_image_dimensions(new_image_path)
            
            # è®¡ç®—æ¨¡å‹resizeåçš„å°ºå¯¸
            model_height, model_width = 0, 0
            if original_width > 0 and original_height > 0:
                try:
                    model_height, model_width = smart_resize(original_height, original_width)
                    logger.debug(f"å›¾åƒå°ºå¯¸ä¿¡æ¯: åŸå§‹({original_width}x{original_height}) -> æ¨¡å‹({model_width}x{model_height})")
                except Exception as e:
                    logger.warning(f"è®¡ç®—æ¨¡å‹resizeå°ºå¯¸å¤±è´¥: {e}")
            
            # ä¿å­˜è¯¦æƒ…JSON
            details = {
                'image_path': new_image_path,
                'creation_time': creation_time,
                'creation_timestamp': datetime.fromtimestamp(time.time()).isoformat(),
                'frame_number': frame_data['frame_number'],
                'timestamp': frame_data['timestamp'],
                'timestamp_iso': datetime.fromtimestamp(frame_data['timestamp']).isoformat(),
                'relative_timestamp': frame_data['relative_timestamp'],
                'frame_info': {
                    'width': frame_data['frame'].shape[1],
                    'height': frame_data['frame'].shape[0],
                    'channels': frame_data['frame'].shape[2] if len(frame_data['frame'].shape) > 2 else 1
                },
                'image_dimensions': {
                    'original_width': original_width,
                    'original_height': original_height,
                    'model_width': model_width,
                    'model_height': model_height,
                    'scale_x': model_width / original_width if original_width > 0 else 1.0,
                    'scale_y': model_height / original_height if original_height > 0 else 1.0
                }
            }
            
            details_file = os.path.join(details_dir, 'image_details.json')
            with open(details_file, 'w', encoding='utf-8') as f:
                json.dump(details, f, ensure_ascii=False, indent=2, default=str)
            
            logger.info(f"å›¾åƒè¯¦æƒ…å·²ä¿å­˜: {details_dir}")
            return {
                'details_dir': details_dir, 
                'details_file': details_file,
                'image_path': new_image_path,
                'image_dimensions': details['image_dimensions']
            }
            
        except Exception as e:
            logger.error(f"ä¿å­˜å›¾åƒè¯¦æƒ…å¤±è´¥: {str(e)}")
            return {'image_path': image_path}

    def _create_video_from_frames(self, frames_data: List[Dict]) -> Optional[str]:
        """ä»å¸§æ•°æ®åˆ›å»ºè§†é¢‘æ–‡ä»¶"""
        if not frames_data:
            return None
            
        try:
            video_path = self._create_temp_video_path()
            
            # ç¡®ä¿ç›®å½•å­˜åœ¨
            video_dir = os.path.dirname(video_path)
            os.makedirs(video_dir, exist_ok=True)
            
            # è·å–ç¬¬ä¸€å¸§çš„å°ºå¯¸
            first_frame = frames_data[0]['frame']
            height, width = first_frame.shape[:2]
            
            # åˆ›å»ºè§†é¢‘å†™å…¥å™¨ï¼Œä½¿ç”¨ç›®æ ‡å¸§ç‡
            output_fps = self.frames_per_second  # è¾“å‡ºè§†é¢‘çš„å¸§ç‡ç­‰äºæ¯ç§’æŠ½å–çš„å¸§æ•°
            
            # å°è¯•å¤šç§ç¼–ç å™¨ï¼ŒæŒ‰ä¼˜å…ˆçº§æ’åº
            codecs_to_try = [
                ('mp4v', 'MP4V'),  # æœ€å…¼å®¹çš„ç¼–ç å™¨
                ('XVID', 'XVID'),  # å¹¿æ³›æ”¯æŒçš„ç¼–ç å™¨
                ('avc1', 'H.264'), # H.264ç¼–ç å™¨
                ('H264', 'H.264'), # å¦ä¸€ç§H.264ç¼–ç å™¨
                ('MJPG', 'MJPG'),  # Motion JPEG
            ]
            
            writer = None
            used_codec = None
            temp_video_path = video_path  # ä¸´æ—¶è§†é¢‘è·¯å¾„
            
            for codec_name, codec_desc in codecs_to_try:
                try:
                    fourcc = cv2.VideoWriter.fourcc(*codec_name)
                    writer = cv2.VideoWriter(temp_video_path, fourcc, output_fps, (width, height))
                    
                    # æµ‹è¯•å†™å…¥å™¨æ˜¯å¦æ­£å¸¸å·¥ä½œ
                    if writer.isOpened():
                        used_codec = codec_desc
                        logger.debug(f"æˆåŠŸä½¿ç”¨ç¼–ç å™¨: {codec_desc} ({codec_name})")
                        break
                    else:
                        writer.release()
                        writer = None
                        logger.debug(f"ç¼–ç å™¨ {codec_desc} ({codec_name}) ä¸å¯ç”¨")
                except Exception as e:
                    logger.debug(f"ç¼–ç å™¨ {codec_desc} ({codec_name}) åˆå§‹åŒ–å¤±è´¥: {str(e)}")
                    if writer:
                        writer.release()
                        writer = None
            
            if writer is None or not writer.isOpened():
                logger.error("æ‰€æœ‰è§†é¢‘ç¼–ç å™¨éƒ½ä¸å¯ç”¨")
                return None
            
            # å†™å…¥æ‰€æœ‰å¸§
            frames_written = 0
            for frame_data in frames_data:
                try:
                    writer.write(frame_data['frame'])
                    frames_written += 1
                except Exception as e:
                    logger.warning(f"å†™å…¥å¸§å¤±è´¥: {str(e)}")
                    
            writer.release()
            
            if frames_written == 0:
                logger.error("æ²¡æœ‰æˆåŠŸå†™å…¥ä»»ä½•å¸§")
                if os.path.exists(temp_video_path):
                    os.remove(temp_video_path)
                return None
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨ä¸”æœ‰å†…å®¹
            if not os.path.exists(temp_video_path):
                logger.error(f"è§†é¢‘æ–‡ä»¶åˆ›å»ºå¤±è´¥ï¼Œæ–‡ä»¶ä¸å­˜åœ¨: {temp_video_path}")
                return None
            
            file_size_mb = os.path.getsize(temp_video_path) / (1024 * 1024)
            
            if file_size_mb == 0:
                logger.error("è§†é¢‘æ–‡ä»¶å¤§å°ä¸º0ï¼Œåˆ é™¤æ–‡ä»¶")
                os.remove(temp_video_path)
                return None
            
            if file_size_mb > 95:  # å¦‚æœè¶…è¿‡95MBï¼Œåˆ é™¤æ–‡ä»¶
                os.remove(temp_video_path)
                logger.warning(f"è§†é¢‘æ–‡ä»¶è¿‡å¤§ ({file_size_mb:.2f}MB)ï¼Œå·²åˆ é™¤")
                return None
            
            # å¦‚æœä½¿ç”¨çš„ä¸æ˜¯H.264ç¼–ç å™¨ï¼Œå°è¯•ç”¨FFmpegè½¬æ¢ä¸ºH.264
            final_video_path = temp_video_path
            if used_codec != 'H.264' and self._is_ffmpeg_available():
                h264_video_path = temp_video_path.replace('.mp4', '_h264.mp4')
                if self._convert_to_h264_with_ffmpeg(temp_video_path, h264_video_path):
                    # è½¬æ¢æˆåŠŸï¼Œä½¿ç”¨H.264ç‰ˆæœ¬
                    final_video_path = h264_video_path
                    used_codec = 'H.264 (FFmpeg)'
                    
                    # åˆ é™¤åŸå§‹æ–‡ä»¶
                    try:
                        os.remove(temp_video_path)
                    except:
                        pass
                    
                    # æ›´æ–°æ–‡ä»¶å¤§å°
                    file_size_mb = os.path.getsize(final_video_path) / (1024 * 1024)
                    logger.debug(f"FFmpegè½¬æ¢æˆåŠŸï¼Œæ–°æ–‡ä»¶å¤§å°: {file_size_mb:.2f}MB")
                else:
                    logger.debug("FFmpegè½¬æ¢å¤±è´¥ï¼Œä½¿ç”¨åŸå§‹æ–‡ä»¶")
                    
            logger.debug(f"è§†é¢‘æ–‡ä»¶åˆ›å»ºæˆåŠŸ: {final_video_path}")
            logger.debug(f"  - ç¼–ç å™¨: {used_codec}")
            logger.debug(f"  - æ–‡ä»¶å¤§å°: {file_size_mb:.2f}MB")
            logger.debug(f"  - å¸§ç‡: {output_fps}fps")
            logger.debug(f"  - å†™å…¥å¸§æ•°: {frames_written}/{len(frames_data)}")
            
            return final_video_path
            
        except Exception as e:
            logger.error(f"åˆ›å»ºè§†é¢‘æ–‡ä»¶å¤±è´¥: {str(e)}")
            # æ¸…ç†å¯èƒ½åˆ›å»ºçš„æ–‡ä»¶
            for path_var in ['temp_video_path', 'final_video_path', 'h264_video_path']:
                if path_var in locals():
                    path = locals()[path_var]
                    if os.path.exists(path):
                        try:
                            os.remove(path)
                        except:
                            pass
            return None

    def _is_ffmpeg_available(self) -> bool:
        """æ£€æŸ¥FFmpegæ˜¯å¦å¯ç”¨"""
        try:
            import subprocess
            result = subprocess.run(['ffmpeg', '-version'], 
                                  capture_output=True, text=True, timeout=5)
            return result.returncode == 0
        except:
            return False

    def _convert_to_h264_with_ffmpeg(self, input_path: str, output_path: str) -> bool:
        """ä½¿ç”¨FFmpegå°†è§†é¢‘è½¬æ¢ä¸ºH.264æ ¼å¼"""
        try:
            import subprocess
            
            # FFmpegå‘½ä»¤ï¼šè½¬æ¢ä¸ºH.264ï¼Œä¿æŒåŸå§‹å¸§ç‡å’Œåˆ†è¾¨ç‡
            cmd = [
                'ffmpeg',
                '-i', input_path,           # è¾“å…¥æ–‡ä»¶
                '-c:v', 'libx264',          # ä½¿ç”¨H.264ç¼–ç å™¨
                '-preset', 'fast',          # å¿«é€Ÿç¼–ç é¢„è®¾
                '-crf', '23',               # è´¨é‡è®¾ç½®ï¼ˆ18-28ï¼Œè¶Šå°è´¨é‡è¶Šå¥½ï¼‰
                '-movflags', '+faststart',  # ä¼˜åŒ–ç½‘ç»œæ’­æ”¾
                '-y',                       # è¦†ç›–è¾“å‡ºæ–‡ä»¶
                output_path                 # è¾“å‡ºæ–‡ä»¶
            ]
            
            logger.debug(f"æ‰§è¡ŒFFmpegè½¬æ¢: {' '.join(cmd)}")
            
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=30)
            
            if result.returncode == 0 and os.path.exists(output_path):
                output_size = os.path.getsize(output_path)
                if output_size > 0:
                    logger.debug(f"FFmpegè½¬æ¢æˆåŠŸ: {output_path} ({output_size} bytes)")
                    return True
                else:
                    logger.warning("FFmpegè½¬æ¢åæ–‡ä»¶å¤§å°ä¸º0")
                    return False
            else:
                logger.warning(f"FFmpegè½¬æ¢å¤±è´¥: {result.stderr}")
                return False
                
        except subprocess.TimeoutExpired:
            logger.warning("FFmpegè½¬æ¢è¶…æ—¶")
            return False
        except Exception as e:
            logger.warning(f"FFmpegè½¬æ¢å¼‚å¸¸: {str(e)}")
            return False

    def _save_and_sort_experiment_log(self):
        """ä¿å­˜å¹¶è‡ªåŠ¨æ’åºå®éªŒæ—¥å¿—"""
        try:
            # æŒ‰original_frame_rangeæ’åºinference_logï¼Œæ–¹ä¾¿è°ƒè¯•
            sorted_experiment_log = sorted(
                self.experiment_log, 
                key=lambda x: x.get('video_info', {}).get('original_frame_range', [0, 0])[0]
            )
            
            log_file = os.path.join(self.temp_dir, 'experiment_log.json')
            with open(log_file, 'w', encoding='utf-8') as f:
                json.dump({
                    'processor_config': {
                        'target_video_duration': self.target_video_duration,
                        'frames_per_second': self.frames_per_second,
                        'original_fps': self.original_fps,
                        'target_frames_per_video': self.target_frames_per_video,
                        'frames_to_collect_per_video': self.frames_to_collect_per_video,
                        'max_concurrent_inferences': self.max_concurrent_inferences
                    },
                    'statistics': {
                        'total_frames_received': self.total_frames_received,
                        'total_videos_created': self.total_videos_created,
                        'total_images_created': self.total_images_created,
                        'total_inferences_started': self.total_inferences_started,
                        'total_inferences_completed': self.total_inferences_completed,
                        'start_time': self.start_time,
                        'start_timestamp': datetime.fromtimestamp(self.start_time).isoformat() if self.start_time else None,
                        'total_duration': time.time() - (self.start_time or time.time())
                    },
                    'inference_log': sorted_experiment_log  # ä½¿ç”¨æ’åºåçš„æ—¥å¿—
                }, f, ensure_ascii=False, indent=2, default=str)
            
            logger.info(f"å®éªŒæ—¥å¿—å·²ä¿å­˜å¹¶è‡ªåŠ¨æ’åº: {log_file}")
            logger.info(f"æ¨ç†æ—¥å¿—å·²æŒ‰å¸§èŒƒå›´æ’åºï¼Œå…± {len(sorted_experiment_log)} æ¡è®°å½•")
            
        except Exception as e:
            logger.error(f"ä¿å­˜å®éªŒæ—¥å¿—å¤±è´¥: {str(e)}")

    def _create_temp_video_path(self) -> str:
        """åˆ›å»ºä¸´æ—¶è§†é¢‘æ–‡ä»¶è·¯å¾„"""
        timestamp = int(time.time() * 1000)
        filename = f"sampled_video_{timestamp}.mp4"
        return os.path.join(self.temp_dir, filename)

    def _save_inference_result_to_details(self, result_data: Dict):
        """ä¿å­˜æ¨ç†ç»“æœåˆ°è§†é¢‘è¯¦æƒ…æ–‡ä»¶å¤¹"""
        try:
            # æå–è§†é¢‘ä¿¡æ¯å’Œæ¨ç†ç»“æœ
            video_info = result_data.get('video_info', {})
            details_dir = video_info.get('details_dir')
            
            if not details_dir or not os.path.exists(details_dir):
                logger.warning(f"è§†é¢‘è¯¦æƒ…ç›®å½•ä¸å­˜åœ¨: {details_dir}")
                return
            
            # åˆ›å»ºæ¨ç†ç»“æœæ–‡ä»¶è·¯å¾„
            inference_result_file = os.path.join(details_dir, 'inference_result.json')
            
            # å‡†å¤‡è¦ä¿å­˜çš„æ¨ç†ç»“æœæ•°æ®
            inference_data = {
                'video_path': result_data['video_path'],
                'inference_start_time': result_data['inference_start_time'],
                'inference_end_time': result_data['inference_end_time'],
                'inference_start_timestamp': result_data['inference_start_timestamp'],
                'inference_end_timestamp': result_data['inference_end_timestamp'],
                'inference_duration': result_data['inference_duration'],
                'result_received_at': result_data['result_received_at'],
                'raw_result': result_data['result'],  # åŸå§‹ç»“æœå­—ç¬¦ä¸²
                'user_question': result_data.get('user_question')  # ç”¨æˆ·é—®é¢˜
            }
            
            # å°è¯•è§£æJSONç»“æœ
            try:
                result_text = result_data['result']
                if result_text:
                    # å¦‚æœç»“æœåŒ…å«```jsonæ ‡è®°ï¼Œæå–JSONéƒ¨åˆ†
                    if '```json' in result_text:
                        start_idx = result_text.find('```json') + 7
                        end_idx = result_text.find('```', start_idx)
                        if end_idx > start_idx:
                            json_text = result_text[start_idx:end_idx].strip()
                        else:
                            json_text = result_text
                    else:
                        json_text = result_text.strip()
                    
                    # å°è¯•è§£æJSON
                    import json
                    parsed_result = json.loads(json_text)
                    inference_data['parsed_result'] = parsed_result
                    logger.debug(f"æˆåŠŸè§£ææ¨ç†ç»“æœJSON")
                    
            except (json.JSONDecodeError, ValueError) as e:
                logger.warning(f"æ— æ³•è§£ææ¨ç†ç»“æœä¸ºJSON: {str(e)}")
                inference_data['parse_error'] = str(e)
            
            # ä¿å­˜æ¨ç†ç»“æœåˆ°æ–‡ä»¶
            with open(inference_result_file, 'w', encoding='utf-8') as f:
                json.dump(inference_data, f, ensure_ascii=False, indent=2, default=str)
            
            logger.info(f"æ¨ç†ç»“æœå·²ä¿å­˜åˆ°: {inference_result_file}")
            
        except Exception as e:
            logger.error(f"ä¿å­˜æ¨ç†ç»“æœå¤±è´¥: {str(e)}") 

    def _save_video_details(self, sampled_frames: List[Dict], video_path: str, creation_time: float) -> Dict:
        """ä¿å­˜è§†é¢‘è¯¦æƒ…åˆ°å®éªŒç›®å½•"""
        try:
            # åˆ›å»ºè§†é¢‘è¯¦æƒ…ç›®å½•
            video_name = os.path.splitext(os.path.basename(video_path))[0]
            details_dir = os.path.join(self.temp_dir, f"{video_name}_details")
            os.makedirs(details_dir, exist_ok=True)
            
            # å°†è§†é¢‘æ–‡ä»¶ç§»åŠ¨åˆ°detailsæ–‡ä»¶å¤¹å†…
            new_video_path = os.path.join(details_dir, os.path.basename(video_path))
            if os.path.exists(video_path) and video_path != new_video_path:
                import shutil
                shutil.move(video_path, new_video_path)
                logger.debug(f"è§†é¢‘æ–‡ä»¶å·²ç§»åŠ¨åˆ°: {new_video_path}")
            else:
                new_video_path = video_path
            
            # ä¿å­˜æŠ½å–çš„å¸§
            frame_paths = []
            for i, frame_data in enumerate(sampled_frames):
                frame_path = os.path.join(details_dir, f"frame_{i:02d}_orig_{frame_data['frame_number']:04d}.jpg")
                cv2.imwrite(frame_path, frame_data['frame'])
                frame_paths.append(frame_path)
            
            # ä¿å­˜è¯¦æƒ…JSON
            details = {
                'video_path': new_video_path,  # ä½¿ç”¨æ–°çš„è§†é¢‘è·¯å¾„
                'creation_time': creation_time,
                'creation_timestamp': datetime.fromtimestamp(time.time()).isoformat(),
                'total_frames': len(sampled_frames),
                'frames_per_second': self.frames_per_second,
                'target_duration': self.target_video_duration,
                'sampled_frames': [
                    {
                        'index': i,
                        'original_frame_number': frame['frame_number'],
                        'timestamp': frame['timestamp'],
                        'timestamp_iso': datetime.fromtimestamp(frame['timestamp']).isoformat(),
                        'relative_timestamp': frame['relative_timestamp'],
                        'saved_path': frame_paths[i]
                    }
                    for i, frame in enumerate(sampled_frames)
                ]
            }
            
            details_file = os.path.join(details_dir, 'video_details.json')
            with open(details_file, 'w', encoding='utf-8') as f:
                json.dump(details, f, ensure_ascii=False, indent=2, default=str)
            
            logger.info(f"è§†é¢‘è¯¦æƒ…å·²ä¿å­˜: {details_dir}")
            return {
                'details_dir': details_dir, 
                'details_file': details_file,
                'video_path': new_video_path  # è¿”å›æ–°çš„è§†é¢‘è·¯å¾„
            }
            
        except Exception as e:
            logger.error(f"ä¿å­˜è§†é¢‘è¯¦æƒ…å¤±è´¥: {str(e)}")
            return {'video_path': video_path}  # å¤±è´¥æ—¶è¿”å›åŸè·¯å¾„ 

    def set_sentry_mode(self, enabled: bool):
        """
        è®¾ç½®å“¨å…µæ¨¡å¼çŠ¶æ€
        
        Args:
            enabled: Trueå¯ç”¨å“¨å…µæ¨¡å¼ï¼ŒFalseç¦ç”¨å“¨å…µæ¨¡å¼
        """
        with self._sentry_mode_lock:
            old_state = self.sentry_mode_enabled
            self.sentry_mode_enabled = enabled
            
            if old_state != enabled:
                mode_text = "å¯ç”¨" if enabled else "ç¦ç”¨"
                logger.info(f"ğŸ›¡ï¸ å“¨å…µæ¨¡å¼å·²{mode_text}")
                
                # å¦‚æœæœ‰ç”¨æˆ·é—®é¢˜ç®¡ç†å™¨ï¼Œä¹Ÿé€šçŸ¥å®ƒ
                if self.question_manager:
                    logger.info(f"é€šçŸ¥ç”¨æˆ·é—®é¢˜ç®¡ç†å™¨ï¼šå“¨å…µæ¨¡å¼{mode_text}")
    
    def get_sentry_mode(self) -> bool:
        """
        è·å–å½“å‰å“¨å…µæ¨¡å¼çŠ¶æ€
        
        Returns:
            bool: Trueè¡¨ç¤ºå¯ç”¨ï¼ŒFalseè¡¨ç¤ºç¦ç”¨
        """
        with self._sentry_mode_lock:
            return self.sentry_mode_enabled
    
    def toggle_sentry_mode(self) -> bool:
        """
        åˆ‡æ¢å“¨å…µæ¨¡å¼çŠ¶æ€
        
        Returns:
            bool: åˆ‡æ¢åçš„çŠ¶æ€
        """
        with self._sentry_mode_lock:
            self.sentry_mode_enabled = not self.sentry_mode_enabled
            mode_text = "å¯ç”¨" if self.sentry_mode_enabled else "ç¦ç”¨"
            logger.info(f"ğŸ›¡ï¸ å“¨å…µæ¨¡å¼å·²{mode_text}")
            return self.sentry_mode_enabled
    
    def _update_sentry_mode_from_backend(self):
        """
        ä»åç«¯APIæ›´æ–°å“¨å…µæ¨¡å¼çŠ¶æ€
        """
        try:
            import requests
            
            current_time = time.time()
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°ï¼ˆé¿å…é¢‘ç¹è¯·æ±‚ï¼‰
            if current_time - self._last_sentry_mode_check < self._sentry_mode_check_interval:
                return
            
            self._last_sentry_mode_check = current_time
            
            # è¯·æ±‚åç«¯APIè·å–å“¨å…µæ¨¡å¼çŠ¶æ€
            response = requests.get(
                f"{self.backend_api_url}/api/sentry-mode",
                timeout=2.0  # çŸ­è¶…æ—¶ï¼Œé¿å…é˜»å¡æ¨ç†
            )
            
            if response.status_code == 200:
                data = response.json()
                if data.get('success') and 'data' in data:
                    new_enabled = data['data'].get('enabled', True)
                    
                    with self._sentry_mode_lock:
                        if self.sentry_mode_enabled != new_enabled:
                            self.sentry_mode_enabled = new_enabled
                            mode_text = "å¯ç”¨" if new_enabled else "ç¦ç”¨"
                            logger.info(f"ğŸ›¡ï¸ ä»åç«¯åŒæ­¥å“¨å…µæ¨¡å¼çŠ¶æ€: {mode_text}")
            else:
                logger.debug(f"è·å–å“¨å…µæ¨¡å¼çŠ¶æ€å¤±è´¥: HTTP {response.status_code}")
                
        except Exception as e:
            # é™é»˜å¤„ç†é”™è¯¯ï¼Œé¿å…å½±å“æ¨ç†æµç¨‹
            logger.debug(f"æ›´æ–°å“¨å…µæ¨¡å¼çŠ¶æ€å¤±è´¥: {str(e)}")
    
    def set_backend_api_url(self, url: str):
        """
        è®¾ç½®åç«¯API URL
        
        Args:
            url: åç«¯APIçš„URL
        """
        self.backend_api_url = url.rstrip('/')
        logger.info(f"è®¾ç½®åç«¯API URL: {self.backend_api_url}")
    
    def set_sync_inference_mode(self, enabled: bool):
        """
        è®¾ç½®åŒæ­¥æ¨ç†æ¨¡å¼
        
        Args:
            enabled: Trueå¯ç”¨åŒæ­¥æ¨ç†æ¨¡å¼ï¼ŒFalseç¦ç”¨ï¼ˆä½¿ç”¨å¼‚æ­¥æ¨¡å¼ï¼‰
        """
        with self.current_inference_lock:
            old_mode = self.sync_inference_mode
            self.sync_inference_mode = enabled
            
            if old_mode != enabled:
                mode_text = "åŒæ­¥" if enabled else "å¼‚æ­¥"
                logger.info(f"ğŸ”„ æ¨ç†æ¨¡å¼å·²åˆ‡æ¢ä¸º: {mode_text}æ¨¡å¼")
                
                # å¦‚æœåˆ‡æ¢åˆ°å¼‚æ­¥æ¨¡å¼ï¼Œæ¸…ç†åŒæ­¥æ¨¡å¼çŠ¶æ€
                if not enabled:
                    self.current_inference_active = False
                    self.current_inference_details = None
                    with self.pending_frame_lock:
                        if self.pending_frame_data:
                            logger.info("åˆ‡æ¢åˆ°å¼‚æ­¥æ¨¡å¼ï¼Œå¤„ç†å¾…å¤„ç†å¸§")
                            try:
                                self.frame_queue.put(self.pending_frame_data, timeout=1)
                            except queue.Full:
                                logger.warning("å¸§é˜Ÿåˆ—å·²æ»¡ï¼Œä¸¢å¼ƒå¾…å¤„ç†å¸§")
                            self.pending_frame_data = None
    
    def get_sync_inference_mode(self) -> bool:
        """
        è·å–å½“å‰æ¨ç†æ¨¡å¼
        
        Returns:
            bool: Trueè¡¨ç¤ºåŒæ­¥æ¨¡å¼ï¼ŒFalseè¡¨ç¤ºå¼‚æ­¥æ¨¡å¼
        """
        return self.sync_inference_mode
    
    def get_inference_status(self) -> Dict[str, Any]:
        """
        è·å–æ¨ç†çŠ¶æ€ä¿¡æ¯
        
        Returns:
            åŒ…å«æ¨ç†çŠ¶æ€çš„å­—å…¸
        """
        with self.current_inference_lock:
            status = {
                'sync_mode': self.sync_inference_mode,
                'inference_active': self.current_inference_active,
                'active_tasks': len(self.active_inference_tasks),
                'max_concurrent': self.max_concurrent_inferences,
                'total_started': self.total_inferences_started,
                'total_completed': self.total_inferences_completed,
                'frames_skipped_sync': self.frames_skipped_sync_mode,
                'user_questions_processed': self.user_questions_processed
            }
            
            if self.current_inference_details:
                status['current_inference'] = {
                    'media_path': self.current_inference_details['media_path'],
                    'media_type': self.current_inference_details['media_type'],
                    'frame_number': self.current_inference_details['frame_number'],
                    'duration': time.time() - self.current_inference_details['start_time']
                }
        
        with self.pending_frame_lock:
            status['has_pending_frame'] = self.pending_frame_data is not None
            if self.pending_frame_data:
                status['pending_frame_number'] = self.pending_frame_data['frame_number']
        
        return status
    
    def _user_question_monitor_worker(self):
        """
        ç”¨æˆ·é—®é¢˜ä¸»åŠ¨ç›‘å¬å·¥ä½œçº¿ç¨‹
        
        ä¸»åŠ¨æ£€æµ‹ç”¨æˆ·é—®é¢˜çš„åˆ°è¾¾ï¼Œä¸ä¾èµ–äºæ–°å¸§çš„è¾“å…¥
        å½“æ£€æµ‹åˆ°ç”¨æˆ·é—®é¢˜æ—¶ï¼Œç«‹å³å¤„ç†pending_frameæˆ–è§¦å‘æ¨ç†ä¸­æ–­
        """
        logger.info("ç”¨æˆ·é—®é¢˜ç›‘å¬çº¿ç¨‹å¯åŠ¨")
        
        try:
            while not self.stop_event.is_set():
                try:
                    current_time = time.time()
                    
                    # æ£€æŸ¥æ˜¯å¦éœ€è¦æ£€æŸ¥ç”¨æˆ·é—®é¢˜
                    if current_time - self.last_question_check_time >= self.question_check_interval:
                        self.last_question_check_time = current_time
                        
                        # æ£€æŸ¥æ˜¯å¦æœ‰ç”¨æˆ·é—®é¢˜
                        has_user_question = False
                        if self.question_manager:
                            has_user_question = self.question_manager.has_available_question()
                        
                        if has_user_question:
                            logger.info("ğŸš¨ ç”¨æˆ·é—®é¢˜ç›‘å¬å™¨æ£€æµ‹åˆ°æ–°é—®é¢˜ï¼Œç«‹å³å¤„ç†")
                            
                            # ğŸ”§ åŸå­æ€§è·å–ç”¨æˆ·é—®é¢˜ï¼Œé¿å…é‡å¤å¤„ç†
                            if not self.question_manager:
                                logger.warning("ç”¨æˆ·é—®é¢˜ç®¡ç†å™¨ä¸å­˜åœ¨ï¼Œè·³è¿‡å¤„ç†")
                                continue
                                
                            user_question, task_id = self.question_manager.acquire_question()
                            if not user_question or not task_id:
                                logger.debug("ç”¨æˆ·é—®é¢˜å·²è¢«å…¶ä»–ä»»åŠ¡è·å–ï¼Œè·³è¿‡")
                                continue
                            
                            logger.info(f"ğŸš¨ ç”¨æˆ·é—®é¢˜ç›‘å¬å™¨è·å–åˆ°é—®é¢˜: {user_question} (ä»»åŠ¡ID: {task_id})")
                            
                            # ğŸ”§ ç”¨æˆ·é—®é¢˜å¼ºåˆ¶ä¸­æ–­ï¼šå¦‚æœæœ‰æ¨ç†åœ¨è¿›è¡Œï¼Œå¼ºåˆ¶é‡ç½®æ¨ç†çŠ¶æ€
                            with self.current_inference_lock:
                                if self.current_inference_active:
                                    logger.warning("ğŸš¨ ç”¨æˆ·é—®é¢˜ç›‘å¬å™¨å¼ºåˆ¶ä¸­æ–­å½“å‰æ¨ç†ï¼Œé‡ç½®æ¨ç†çŠ¶æ€")
                                    self.current_inference_active = False
                                    self.current_inference_details = None
                            
                            # ğŸ”§ æ£€æŸ¥æ˜¯å¦æœ‰pending_frameå¯ä»¥ç«‹å³å¤„ç†
                            with self.pending_frame_lock:
                                if self.pending_frame_data is not None:
                                    # æœ‰pending_frameï¼Œç«‹å³å¤„ç†
                                    pending_frame = self.pending_frame_data
                                    self.pending_frame_data = None  # æ¸…ç©ºpending_frame
                                    
                                    logger.info(f"ğŸš¨ ç”¨æˆ·é—®é¢˜ç›‘å¬å™¨ä½¿ç”¨pendingå¸§ {pending_frame['frame_number']} ç«‹å³å¤„ç†ç”¨æˆ·é—®é¢˜")
                                    
                                    # ç›´æ¥å°†pending_frameæ”¾å…¥é˜Ÿåˆ—å¤„ç†
                                    try:
                                        self.frame_queue.put(pending_frame, timeout=1)
                                        self.user_questions_processed += 1
                                        logger.info("âœ… ç”¨æˆ·é—®é¢˜å·²é€šè¿‡ç›‘å¬å™¨ç«‹å³å¤„ç†")
                                    except queue.Full:
                                        logger.warning("å¸§é˜Ÿåˆ—å·²æ»¡ï¼Œç”¨æˆ·é—®é¢˜å¤„ç†å¤±è´¥")
                                        # å¦‚æœé˜Ÿåˆ—æ»¡äº†ï¼Œé‡æ–°æ”¾å›pending_frameï¼Œå¹¶é‡Šæ”¾é—®é¢˜
                                        self.pending_frame_data = pending_frame
                                        if self.question_manager:
                                            self.question_manager.release_question(task_id, success=False)
                                            logger.warning(f"é˜Ÿåˆ—æ»¡ï¼Œå·²é‡Šæ”¾é—®é¢˜: {user_question}")
                                else:
                                    # æ²¡æœ‰pending_frameï¼Œé‡Šæ”¾é—®é¢˜å¹¶ç­‰å¾…ä¸‹ä¸€ä¸ªå¸§
                                    if self.question_manager:
                                        self.question_manager.release_question(task_id, success=False)
                                    logger.info("ğŸš¨ ç”¨æˆ·é—®é¢˜ç›‘å¬å™¨æ£€æµ‹åˆ°é—®é¢˜ï¼Œä½†æ— pendingå¸§ï¼Œå·²é‡Šæ”¾é—®é¢˜ç­‰å¾…ä¸‹ä¸€ä¸ªå¸§")
                    
                    # çŸ­æš‚ä¼‘çœ 
                    time.sleep(0.1)
                    
                except Exception as e:
                    logger.error(f"ç”¨æˆ·é—®é¢˜ç›‘å¬å™¨é”™è¯¯: {str(e)}")
                    time.sleep(1)  # å‡ºé”™æ—¶ç­‰å¾…æ›´é•¿æ—¶é—´
                    
        except Exception as e:
            logger.error(f"ç”¨æˆ·é—®é¢˜ç›‘å¬çº¿ç¨‹å¼‚å¸¸: {str(e)}")
        finally:
            logger.info("ç”¨æˆ·é—®é¢˜ç›‘å¬çº¿ç¨‹ç»“æŸ") 